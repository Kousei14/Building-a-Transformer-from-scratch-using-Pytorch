{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "465f0840",
   "metadata": {},
   "source": [
    "# **get_config()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a10b40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 8,\n",
       " 'num_epochs': 20,\n",
       " 'lr': 0.0001,\n",
       " 'seq_len': 350,\n",
       " 'd_model': 512,\n",
       " 'datasource': 'opus_books',\n",
       " 'lang_src': 'en',\n",
       " 'lang_tgt': 'it',\n",
       " 'model_folder': 'weights',\n",
       " 'model_basename': 'tmodel_',\n",
       " 'preload': 'latest',\n",
       " 'tokenizer_file': 'assets/tokenizer_{0}.json',\n",
       " 'experiment_name': 'runs/tmodel'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.config import get_config\n",
    "\n",
    "config = get_config()\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7050c1",
   "metadata": {},
   "source": [
    "# **get_all_sentences()**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c317ff",
   "metadata": {},
   "source": [
    "## eng-to-it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "02cf66f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '0',\n",
       "  'translation': {'en': 'Source: Project Gutenberg',\n",
       "   'it': 'Source: www.liberliber.it/Audiobook available here'}},\n",
       " {'id': '1', 'translation': {'en': 'Jane Eyre', 'it': 'Jane Eyre'}},\n",
       " {'id': '2',\n",
       "  'translation': {'en': 'Charlotte Bronte', 'it': 'Charlotte Brontë'}},\n",
       " {'id': '3', 'translation': {'en': 'CHAPTER I', 'it': 'PARTE PRIMA'}},\n",
       " {'id': '4',\n",
       "  'translation': {'en': 'There was no possibility of taking a walk that day.',\n",
       "   'it': 'I. In quel giorno era impossibile passeggiare.'}},\n",
       " {'id': '5',\n",
       "  'translation': {'en': 'We had been wandering, indeed, in the leafless shrubbery an hour in the morning; but since dinner (Mrs. Reed, when there was no company, dined early) the cold winter wind had brought with it clouds so sombre, and a rain so penetrating, that further out-door exercise was now out of the question.',\n",
       "   'it': \"La mattina avevamo errato per un'ora nel boschetto spogliato di foglie, ma dopo pranzo (quando non vi erano invitati, la signora Reed desinava presto), il vento gelato d'inverno aveva portato seco nubi così scure e una pioggia così penetrante, che non si poteva pensare a nessuna escursione.\"}},\n",
       " {'id': '6',\n",
       "  'translation': {'en': 'I was glad of it: I never liked long walks, especially on chilly afternoons: dreadful to me was the coming home in the raw twilight, with nipped fingers and toes, and a heart saddened by the chidings of Bessie, the nurse, and humbled by the consciousness of my physical inferiority to Eliza, John, and Georgiana Reed.',\n",
       "   'it': 'Ne ero contenta. Non mi sono mai piaciute le lunghe passeggiate, sopra tutto col freddo, ed era cosa penosa per me di tornar di notte con le mani e i piedi gelati, col cuore amareggiato dalle sgridate di Bessie, la bambinaia, e con lo spirito abbattuto dalla coscienza della mia inferiorità fisica di fronte a Eliza, a John e a Georgiana Reed.'}},\n",
       " {'id': '7',\n",
       "  'translation': {'en': 'The said Eliza, John, and Georgiana were now clustered round their mama in the drawing-room: she lay reclined on a sofa by the fireside, and with her darlings about her (for the time neither quarrelling nor crying) looked perfectly happy.',\n",
       "   'it': 'Eliza, John e Georgiana erano aggruppati in salotto attorno alla loro mamma; questa, sdraiata sul sofà accanto al fuoco e circondata dai suoi bambini, che in quel momento non questionavano fra loro né piangevano, pareva perfettamente felice.'}},\n",
       " {'id': '8',\n",
       "  'translation': {'en': 'Me, she had dispensed from joining the group; saying, \"She regretted to be under the necessity of keeping me at a distance; but that until she heard from Bessie, and could discover by her own observation, that I was endeavouring in good earnest to acquire a more sociable and childlike disposition, a more attractive and sprightly manner--something lighter, franker, more natural, as it were--she really must exclude me from privileges intended only for contented, happy, little children.\"',\n",
       "   'it': 'Ella mi aveva proibito di unirmi al loro gruppo, dicendo che deplorava la necessità in cui trovavasi di tenermi così lontana, ma che fino al momento in cui Bessie non guarentirebbe che mi studiavo di acquistare un carattere più socievole e più infantile, maniere più cortesi e qualcosa di più radioso, di più aperto, di più sincero, non poteva concedermi gli stessi privilegi che ai bambini allegri e soddisfatti.'}},\n",
       " {'id': '9',\n",
       "  'translation': {'en': '\"What does Bessie say I have done?\" I asked.',\n",
       "   'it': '— Che cosa vi ha detto Bessie di nuovo sul conto mio? — domandai.'}},\n",
       " {'id': '10',\n",
       "  'translation': {'en': '\"Jane, I don\\'t like cavillers or questioners; besides, there is something truly forbidding in a child taking up her elders in that manner.',\n",
       "   'it': '— Jane, non mi piace di essere interrogata. Sta male, del resto, che una bimba tratti così i suoi superiori.'}},\n",
       " {'id': '11',\n",
       "  'translation': {'en': 'Be seated somewhere; and until you can speak pleasantly, remain silent.\"',\n",
       "   'it': 'Sedetevi in qualche posto e state buona fino a quando non saprete parlare ragionevolmente.'}},\n",
       " {'id': '12',\n",
       "  'translation': {'en': 'A breakfast-room adjoined the drawing-room, I slipped in there.',\n",
       "   'it': 'Una piccola sala da pranzo metteva nel salotto, andai in quella pian piano.'}},\n",
       " {'id': '13',\n",
       "  'translation': {'en': 'It contained a bookcase: I soon possessed myself of a volume, taking care that it should be one stored with pictures.',\n",
       "   'it': \"Vi era una biblioteca e io m'impossessai di un libro, cercando che fosse ornato d'incisioni.\"}},\n",
       " {'id': '14',\n",
       "  'translation': {'en': 'I mounted into the window- seat: gathering up my feet, I sat cross-legged, like a Turk; and, having drawn the red moreen curtain nearly close, I was shrined in double retirement.',\n",
       "   'it': 'Mi collocai allora nel vano di una finestra, sedendomi sui piedi come i turchi, e tirando la tenda di damasco rosso, mi trovai rinchiusa in un doppio ritiro.'}},\n",
       " {'id': '15',\n",
       "  'translation': {'en': 'Folds of scarlet drapery shut in my view to the right hand; to the left were the clear panes of glass, protecting, but not separating me from the drear November day.',\n",
       "   'it': 'Le larghe pieghe della cortina scarlatta mi nascondevano tutto ciò che era alla mia destra: alla mia sinistra una invetriata mi proteggeva, ma non mi separava da una triste giornata di novembre.'}},\n",
       " {'id': '16',\n",
       "  'translation': {'en': 'At intervals, while turning over the leaves of my book, I studied the aspect of that winter afternoon. Afar, it offered a pale blank of mist and cloud; near a scene of wet lawn and storm-beat shrub, with ceaseless rain sweeping away wildly before a long and lamentable blast.',\n",
       "   'it': \"Di tanto in tanto, sfogliando il libro, gettavo un'occhiata al difuori e studiavo l'aspetto di quella serata d'inverno; in lontananza si scorgeva una pallida striscia di nebbia con nuvole, più vicino alberi bagnati, piante sradicate dal temporale e, infine, una pioggia incessante, che lunghe e lamentevoli ventate respingevano sibilando.\"}},\n",
       " {'id': '17',\n",
       "  'translation': {'en': \"I returned to my book--Bewick's History of British Birds: the letterpress thereof I cared little for, generally speaking; and yet there were certain introductory pages that, child as I was, I could not pass quite as a blank.\",\n",
       "   'it': \"Tornavo allora al mio libro; era La storia degli uccelli dell'Inghilterra, scritta da Berwich. In generale non mi occupavo del testo, nondimeno c'erano delle pagine d'introduzione che non potevo lasciar passare inosservate, malgrado la mia gioventù.\"}},\n",
       " {'id': '18',\n",
       "  'translation': {'en': 'They were those which treat of the haunts of sea-fowl; of \"the solitary rocks and promontories\" by them only inhabited; of the coast of Norway, studded with isles from its southern extremity, the Lindeness, or Naze, to the North Cape-- \"Where the Northern Ocean, in vast whirls, Boils round the naked, melancholy isles Of farthest Thule; and the Atlantic surge Pours in among the stormy Hebrides.\"',\n",
       "   'it': 'Esse parlavano di quei rifugi degli uccelli marini, di quei promontori, di quelle rocce deserte abitate da essi soli, di quelle coste della Norvegia sparse d\\'isole dalla più meridionale punta al capo più nordico, là dove \"l\\'Oceano Polare mugge in vasti turbini attorno all\\'isola arida e malinconica di Tule, là ove il mare Atlantico si precipita in mezzo alle Ebridi tempestose.\"'}},\n",
       " {'id': '19',\n",
       "  'translation': {'en': 'Nor could I pass unnoticed the suggestion of the bleak shores of Lapland, Siberia, Spitzbergen, Nova Zembla, Iceland, Greenland, with \"the vast sweep of the Arctic Zone, and those forlorn regions of dreary space,--that reservoir of frost and snow, where firm fields of ice, the accumulation of centuries of winters, glazed in Alpine heights above heights, surround the pole, and concentre the multiplied rigours of extreme cold.\"',\n",
       "   'it': \"Non potevo neppure saltare la descrizione di quei pallidi paesaggi della Siberia, dello Spitzberg, della Nuova-Zembla, dell'Islanda, della verde Finlandia! Ero assorta nel pensiero di quella solitudine della zona artica, di quelle immense regioni abbandonate, di quei serbatoi di ghiaccio, ove i campi di neve accumulati durante gli inverni di molti secoli, ammucchiano montagne su montagne per circondare il polo e vi concentrano tutti i rigori del freddo più intenso.\"}},\n",
       " {'id': '20',\n",
       "  'translation': {'en': \"Of these death-white realms I formed an idea of my own: shadowy, like all the half-comprehended notions that float dim through children's brains, but strangely impressive.\",\n",
       "   'it': \"Mi ero formata un'idea tutta mia di quei regni pallidi come la morte, idea vaga, come sono tutte le cose capite per metà, che fluttuano nella testa dei bimbi; ma quella che mi figuravo produceva in me uno strano effetto.\"}},\n",
       " {'id': '21',\n",
       "  'translation': {'en': 'The words in these introductory pages connected themselves with the succeeding vignettes, and gave significance to the rock standing up alone in a sea of billow and spray; to the broken boat stranded on a desolate coast; to the cold and ghastly moon glancing through bars of cloud at a wreck just sinking.',\n",
       "   'it': \"In quella introduzione il testo, accordandosi con le figure, dava un significato allo scoglio isolato in mezzo a un mare di onde e di spuma, alla nave gettata su una costa desolata, alla fredda e fantastica luna, che, spingendo i suoi raggi luminosi attraverso un cumulo di nubi, illuminava appunto un'altra scena di naufragio.\"}},\n",
       " {'id': '22',\n",
       "  'translation': {'en': 'I cannot tell what sentiment haunted the quite solitary churchyard, with its inscribed headstone; its gate, its two trees, its low horizon, girdled by a broken wall, and its newly-risen crescent, attesting the hour of eventide.',\n",
       "   'it': \"Io non potrei dire quale sentimento animasse il tranquillo e solitario cimitero, con le sue lapidi, le sue cancellate, i due alberi e l'orizzonte limitato dal muro rotto e la luna crescente che indicava l'ora della sera.\"}},\n",
       " {'id': '23',\n",
       "  'translation': {'en': 'The two ships becalmed on a torpid sea, I believed to be marine phantoms.',\n",
       "   'it': 'Le due navi, in quel mare immobili, mi parevano due fantasmi marini.'}},\n",
       " {'id': '24',\n",
       "  'translation': {'en': \"The fiend pinning down the thief's pack behind him, I passed over quickly: it was an object of terror. So was the black horned thing seated aloof on a rock, surveying a distant crowd surrounding a gallows.\",\n",
       "   'it': 'Sfogliai sollecitamente la figura che rappresenta il mortale nemico, inchiodando il fardello sulla schiena del ladro; era per me un soggetto di terrore, come quella creatura con le corna, seduta sullo scoglio, che spiava la lontana turba che circondava la forca.'}},\n",
       " {'id': '25',\n",
       "  'translation': {'en': \"Each picture told a story; mysterious often to my undeveloped understanding and imperfect feelings, yet ever profoundly interesting: as interesting as the tales Bessie sometimes narrated on winter evenings, when she chanced to be in good humour; and when, having brought her ironing-table to the nursery hearth, she allowed us to sit about it, and while she got up Mrs. Reed's lace frills, and crimped her nightcap borders, fed our eager attention with passages of love and adventure taken from old fairy tales and other ballads; or (as at a later period I discovered) from the pages of Pamela, and Henry, Earl of Moreland.\",\n",
       "   'it': 'Ogni incisione mi narrava una storia, spesso misteriosa per la mia intelligenza poco sviluppata e per il mio incompleto sentimento, ma sempre interessantissima; così interessante come i racconti che ci faceva Bessie nelle serate invernali quando era di buon umore e quando, dopo aver portato la tavola da stirare nella stanza dei bambini, ci permetteva di sedersi vicino a lei. Allora, pieghettando le sciarpe di trina della signora Reed e le cuffie da notte, ci riscaldava la fantasia con narrazioni di amore e di avventure, tolte dai vecchi racconti di fate e dalle antiche ballate, o, come mi accorsi più tardi, da Pamela e da Enrico, conte di Mareland.'}},\n",
       " {'id': '26',\n",
       "  'translation': {'en': 'With Bewick on my knee, I was then happy: happy at least in my way.',\n",
       "   'it': 'Così, avendo Borwick sulle ginocchia, ero felice, felice a modo mio.'}},\n",
       " {'id': '27',\n",
       "  'translation': {'en': 'I feared nothing but interruption, and that came too soon.',\n",
       "   'it': 'Temevo soltanto una interruzione, che non tardò.'}},\n",
       " {'id': '28',\n",
       "  'translation': {'en': 'The breakfast- room door opened.',\n",
       "   'it': 'La porta della stanza da pranzo fu vivamente aperta.'}},\n",
       " {'id': '29',\n",
       "  'translation': {'en': '\"Boh! Madam Mope!\" cried the voice of John Reed; then he paused: he found the room apparently empty.',\n",
       "   'it': '— Oh! signora scontrosa, — gridò John Reed.'}},\n",
       " {'id': '30',\n",
       "  'translation': {'en': '\"Where the dickens is she!\" he continued. \"Lizzy!',\n",
       "   'it': \"Poi tacque, perché gli parve che la stanza fosse deserta. — Per bacco, dov'è?\"}},\n",
       " {'id': '31',\n",
       "  'translation': {'en': 'Georgy! (calling to his sisters) Joan is not here: tell mama she is run out into the rain--bad animal!\"',\n",
       "   'it': 'Liszy, Giorgy, — continuò egli volgendosi alle sorelle, — dite alla mamma che la cattiva bestia è andata a correre in giardino con questa pioggia!'}},\n",
       " {'id': '32',\n",
       "  'translation': {'en': '\"It is well I drew the curtain,\" thought I; and I wished fervently he might not discover my hiding-place: nor would John Reed have found it out himself; he was not quick either of vision or conception; but Eliza just put her head in at the door, and said at once--',\n",
       "   'it': \"— Ho fatto bene a tirare la tenda, — pensavo fra me; e mi auguravo sinceramente che non scoprissero il mio nascondiglio. John non lo avrebbe mai trovato da sè stesso: non aveva lo sguardo pronto; ma Eliza, avendo sporto la testa dall'uscio, esclamò:\"}},\n",
       " {'id': '33',\n",
       "  'translation': {'en': '\"She is in the window-seat, to be sure, Jack.\"',\n",
       "   'it': '— Ella è certamente nel vano della finestra!'}},\n",
       " {'id': '34',\n",
       "  'translation': {'en': 'And I came out immediately, for I trembled at the idea of being dragged forth by the said Jack.',\n",
       "   'it': 'Uscii subito, perché mi sgomentavo al pensiero di esser condotta fuori dal mio nascondiglio da John.'}},\n",
       " {'id': '35',\n",
       "  'translation': {'en': '\"What do you want?\" I asked, with awkward diffidence.',\n",
       "   'it': '— Che cosa volete? — gli domandai con timidezza rispettosa.'}},\n",
       " {'id': '36',\n",
       "  'translation': {'en': '\"Say, \\'What do you want, Master Reed?\\'\" was the answer.',\n",
       "   'it': '— Dite: Che cosa volete, signor Reed?'}},\n",
       " {'id': '37',\n",
       "  'translation': {'en': '\"I want you to come here;\" and seating himself in an arm-chair, he intimated by a gesture that I was to approach and stand before him.',\n",
       "   'it': 'Mi rispose. — Voglio che veniate qui! — e collocandosi nella poltrona, mi fece cenno di accostarmi e di star ritta dinanzi a lui.'}},\n",
       " {'id': '38',\n",
       "  'translation': {'en': 'John Reed was a schoolboy of fourteen years old; four years older than I, for I was but ten: large and stout for his age, with a dingy and unwholesome skin; thick lineaments in a spacious visage, heavy limbs and large extremities.',\n",
       "   'it': 'Era alto e forte per la sua età, ma aveva una carnagione scura e malsana. I lineamenti del volto grossolani, le membra pesanti e le estremità molto sviluppate.'}},\n",
       " {'id': '39',\n",
       "  'translation': {'en': 'He gorged himself habitually at table, which made him bilious, and gave him a dim and bleared eye and flabby cheeks.',\n",
       "   'it': 'Soleva mangiare avidamente, e ciò avevagli prodotta quella tinta biliosa, quello sguardo turbato e quelle guancie flosce.'}},\n",
       " {'id': '40',\n",
       "  'translation': {'en': 'He ought now to have been at school; but his mama had taken him home for a month or two, \"on account of his delicate health.\"',\n",
       "   'it': 'In quel tempo avrebbe dovuto trovarsi in collegio, ma sua madre avevalo tolto per un mese o due col pretesto della sua delicata salute.'}},\n",
       " {'id': '41',\n",
       "  'translation': {'en': \"Mr. Miles, the master, affirmed that he would do very well if he had fewer cakes and sweetmeats sent him from home; but the mother's heart turned from an opinion so harsh, and inclined rather to the more refined idea that John's sallowness was owing to over-application and, perhaps, to pining after home.\",\n",
       "   'it': \"Il signor Miles, direttore del collegio, assicurava che sarebbe stato benissimo se da casa gli avessero mandate meno dolci e meno ghiottonerie, ma il cuore della madre si era ribellato contro questa severità e aveva preferito di accoglier l'idea più gentile che il malessere di John dipendesse dal soverchio studio e dal dolore di esser separato dai suoi.\"}},\n",
       " {'id': '42',\n",
       "  'translation': {'en': 'John had not much affection for his mother and sisters, and an antipathy to me.',\n",
       "   'it': 'John non voleva molto bene né alla madre né alle sorelle.'}},\n",
       " {'id': '43',\n",
       "  'translation': {'en': 'He bullied and punished me; not two or three times in the week, nor once or twice in the day, but continually: every nerve I had feared him, and every morsel of flesh in my bones shrank when he came near.',\n",
       "   'it': 'Io poi gli ero antipatica; mi maltrattava e mi puniva, non due o tre volte la settimana, non due o tre volte al giorno, ma sempre; ognuno dei miei nervi aveva paura di lui, ogni brano della mia carne e delle mie ossa fremeva allorché egli si accostava a me.'}},\n",
       " {'id': '44',\n",
       "  'translation': {'en': 'There were moments when I was bewildered by the terror he inspired, because I had no appeal whatever against either his menaces or his inflictions; the servants did not like to offend their young master by taking my part against him, and Mrs. Reed was blind and deaf on the subject: she never saw him strike or heard him abuse me, though he did both now and then in her very presence, more frequently, however, behind her back.',\n",
       "   'it': \"Vi erano momenti in cui divenivo selvaggia per il terrore che mi ispirava, perché non sapevo a chi ricorrere contro le sue minaccie e le sue punizioni. I servi non avrebbero voluto prendere le mie difese per non offendere il loro giovine padrone, e la signora Reed su quell'argomento era cieca e sorda, ella fingeva di non accorgersi quando mi picchiava o m'insultava, benché egli ciò facesse spesso in presenza di lei, ma più spesso quando non c'era.\"}},\n",
       " {'id': '45',\n",
       "  'translation': {'en': 'Habitually obedient to John, I came up to his chair: he spent some three minutes in thrusting out his tongue at me as far as he could without damaging the roots: I knew he would soon strike, and while dreading the blow, I mused on the disgusting and ugly appearance of him who would presently deal it.',\n",
       "   'it': 'Essendo assuefatta ad ubbidire a John, mi accostai alla seggiola sua. Egli stette tre minuti a mostrarmi la lingua, allungandola quanto più poteva, sapevo che stava per picchiarmi e spiavo sulla sua brutta faccia il momento in cui la collera avrebbegli fatto allungare la mano.'}},\n",
       " {'id': '46',\n",
       "  'translation': {'en': 'I wonder if he read that notion in my face; for, all at once, without speaking, he struck suddenly and strongly.',\n",
       "   'it': \"Credo che s'accorgesse del mio pensiero, perché a un tratto si alzò senza dir parola, e mi colpì duramente.\"}},\n",
       " {'id': '47',\n",
       "  'translation': {'en': 'I tottered, and on regaining my equilibrium retired back a step or two from his chair.',\n",
       "   'it': 'Barcollai e poi rimettendomi in equilibrio, mi allontanai di un passo o due dalla sua sedia.'}},\n",
       " {'id': '48',\n",
       "  'translation': {'en': '\"That is for your impudence in answering mama awhile since,\" said he, \"and for your sneaking way of getting behind curtains, and for the look you had in your eyes two minutes since, you rat!\"',\n",
       "   'it': \"— Questo è per l'impudenza con cui avete risposto alla mamma, — mi disse, — e per esservi nascosta dietro la tenda e per lo sguardo che avevate negli occhi poco fa, talpa!\"}},\n",
       " {'id': '49',\n",
       "  'translation': {'en': \"Accustomed to John Reed's abuse, I never had an idea of replying to it; my care was how to endure the blow which would certainly follow the insult.\",\n",
       "   'it': \"— Assuefatta com'ero agli insulti di John, non mi venne neppur l'idea di rispondergli; ponevo ogni cura invece nel sopportare coraggiosamente il colpo, che avrebbe tenuto dietro all'insulto.\"}},\n",
       " {'id': '50',\n",
       "  'translation': {'en': '\"What were you doing behind the curtain?\" he asked.',\n",
       "   'it': '— Che cosa facevate dietro la tenda? — mi domandò.'}},\n",
       " {'id': '51', 'translation': {'en': '\"I was reading.\"', 'it': '— Leggevo.'}},\n",
       " {'id': '52',\n",
       "  'translation': {'en': '\"Show the book.\"',\n",
       "   'it': '— Fatemi vedere il libro.'}},\n",
       " {'id': '53',\n",
       "  'translation': {'en': 'I returned to the window and fetched it thence.',\n",
       "   'it': '— Mi diressi verso la finestra per prenderlo.'}},\n",
       " {'id': '54',\n",
       "  'translation': {'en': '\"You have no business to take our books; you are a dependent, mama says; you have no money; your father left you none; you ought to beg, and not to live here with gentlemen\\'s children like us, and eat the same meals we do, and wear clothes at our mama\\'s expense.',\n",
       "   'it': \"— Non c'è bisogno che prendiate i nostri libri; dipendete da noi, dice la mamma; non avete quattrini, vostro padre non vi lasciò nulla; dovreste andare ad accattare invece di star qui con noi, che siamo figli di signori, di mangiare i medesimi cibi che mangiamo e di esser vestita alle spese della mamma.\"}},\n",
       " {'id': '55',\n",
       "  'translation': {'en': \"Now, I'll teach you to rummage my bookshelves: for they _are_ mine; all the house belongs to me, or will do in a few years.\",\n",
       "   'it': \"Ora v'insegnerò a frugar nella mia biblioteca, perché questi libri sono miei, tutto mi appartiene in casa, o mi apparterrà fra pochi anni.\"}},\n",
       " {'id': '56',\n",
       "  'translation': {'en': 'Go and stand by the door, out of the way of the mirror and the windows.\"',\n",
       "   'it': 'Andate vicino alla porta, lontano dallo specchio e dalla finestra.'}},\n",
       " {'id': '57',\n",
       "  'translation': {'en': 'I did so, not at first aware what was his intention; but when I saw him lift and poise the book and stand in act to hurl it, I instinctively started aside with a cry of alarm: not soon enough, however; the volume was flung, it hit me, and I fell, striking my head against the door and cutting it.',\n",
       "   'it': \"Ubbidii senza sapere che intenzione avesse; ma quando vidi che alzava il libro e far atto di gettarmelo contro, mi tirai istintivamente da parte, mandando un grido d'allarme. Non fui però abbastanza pronta; il volume volò per aria e mi colpì nella testa; io caddi e battendo nello spigolo della porta mi ferii.\"}},\n",
       " {'id': '58',\n",
       "  'translation': {'en': 'The cut bled, the pain was sharp: my terror had passed its climax; other feelings succeeded.',\n",
       "   'it': 'La ferita sanguinava ed io provai un gran dolore: ma il terrore era svanito per dar luogo ad altri sentimenti.'}},\n",
       " {'id': '59',\n",
       "  'translation': {'en': '\"Wicked and cruel boy!\" I said. \"You are like a murderer--you are like a slave-driver--you are like the Roman emperors!\"',\n",
       "   'it': '— Perfido e crudele ragazzo! — dissi, — siete simile a un assassino, a un guardiano di schiavi, a un imperatore romano!'}},\n",
       " {'id': '60',\n",
       "  'translation': {'en': \"I had read Goldsmith's History of Rome, and had formed my opinion of Nero, Caligula, &c. Also I had drawn parallels in silence, which I never thought thus to have declared aloud.\",\n",
       "   'it': 'Avevo appunto letto la storia di Roma di Goldsmith e mi ero fatta un concetto di Nerone, di Caligola, che non credevo di dover esporre mai a voce alta.'}},\n",
       " {'id': '61',\n",
       "  'translation': {'en': '\"What! what!\" he cried.', 'it': '— Come!'}},\n",
       " {'id': '62',\n",
       "  'translation': {'en': '\"Did she say that to me?',\n",
       "   'it': 'Come! — esclamò. — Dice a me forse?'}},\n",
       " {'id': '63',\n",
       "  'translation': {'en': 'Did you hear her, Eliza and Georgiana?',\n",
       "   'it': \"L'avete sentita, Eliza, Georgiana?\"}},\n",
       " {'id': '64',\n",
       "  'translation': {'en': 'Won\\'t I tell mama? but first--\" He ran headlong at me: I felt him grasp my hair and my shoulder: he had closed with a desperate thing.',\n",
       "   'it': 'Vado a dirlo a mamma, ma prima.... Egli si slanciò contro di me, e mi sentii afferrare per i capelli e per le spalle con disperato furore.'}},\n",
       " {'id': '65',\n",
       "  'translation': {'en': 'I really saw in him a tyrant, a murderer.',\n",
       "   'it': 'Io vedevo realmente in lui un assassino, un tiranno.'}},\n",
       " {'id': '66',\n",
       "  'translation': {'en': 'I felt a drop or two of blood from my head trickle down my neck, and was sensible of somewhat pungent suffering: these sensations for the time predominated over fear, and I received him in frantic sort.',\n",
       "   'it': \"Sentii scendermi dalla testa e cadere sul collo una o due gocce di sangue e provai un'acuta sofferenza; queste sensazioni per un momento dominarono la paura e mi resero furente.\"}},\n",
       " {'id': '67',\n",
       "  'translation': {'en': 'I don\\'t very well know what I did with my hands, but he called me \"Rat!',\n",
       "   'it': 'Non so dire quello che io facessi con le mani, ma John mi chiamava: \"Talpa!'}},\n",
       " {'id': '68',\n",
       "  'translation': {'en': 'Rat!\" and bellowed out aloud.',\n",
       "   'it': 'Talpa!\" e continuava a insultarmi.'}},\n",
       " {'id': '69',\n",
       "  'translation': {'en': 'Aid was near him: Eliza and Georgiana had run for Mrs. Reed, who was gone upstairs: she now came upon the scene, followed by Bessie and her maid Abbot.',\n",
       "   'it': 'Eliza e Georgiana erano corse a chiamar la mamma, che era salita al piano superiore. La signora Reed entrò durante quella scena, seguita da Bessie e da Abbot, la cameriera.'}},\n",
       " {'id': '70',\n",
       "  'translation': {'en': 'We were parted: I heard the words-- \"Dear! dear!',\n",
       "   'it': '— Dio mio, che orrore!'}},\n",
       " {'id': '71',\n",
       "  'translation': {'en': 'What a fury to fly at Master John!\"',\n",
       "   'it': 'Percuotere il signorino John!'}},\n",
       " {'id': '72',\n",
       "  'translation': {'en': '\"Did ever anybody see such a picture of passion!\"',\n",
       "   'it': '— Avete mai visto una rabbiosa come questa?'}},\n",
       " {'id': '73',\n",
       "  'translation': {'en': 'Then Mrs. Reed subjoined--',\n",
       "   'it': 'Allora la signora Reed soggiunse:'}},\n",
       " {'id': '74',\n",
       "  'translation': {'en': '\"Take her away to the red-room, and lock her in there.\"',\n",
       "   'it': '— Portatela nella camera rossa e chiudetevela dentro.'}},\n",
       " {'id': '75',\n",
       "  'translation': {'en': 'Four hands were immediately laid upon me, and I was borne upstairs.',\n",
       "   'it': 'Quattro mani mi afferrarono e io fui trascinata su per le scale.'}},\n",
       " {'id': '76', 'translation': {'en': 'CHAPTER II', 'it': 'II.'}},\n",
       " {'id': '77',\n",
       "  'translation': {'en': 'I resisted all the way: a new thing for me, and a circumstance which greatly strengthened the bad opinion Bessie and Miss Abbot were disposed to entertain of me.',\n",
       "   'it': 'Opposi resistenza per tutto il percorso, così che accrebbi grandemente la cattiva opinione che Bessie e Abbot avevano di me.'}},\n",
       " {'id': '78',\n",
       "  'translation': {'en': \"The fact is, I was a trifle beside myself; or rather _out_ of myself, as the French would say: I was conscious that a moment's mutiny had already rendered me liable to strange penalties, and, like any other rebel slave, I felt resolved, in my desperation, to go all lengths.\",\n",
       "   'it': 'È un fatto che non ero più io, o meglio ero fuori di me, come direbbero i francesi. Sapevo che quella ribellione momentanea mi avrebbe valso delle strane punizioni, e, pari a ogni schiavo ribelle, ero spinta agli estremi dalla disperazione stessa.'}},\n",
       " {'id': '79',\n",
       "  'translation': {'en': '\"Hold her arms, Miss Abbot: she\\'s like a mad cat.\"',\n",
       "   'it': '— Reggetele le mani, signorina Abbot; è come un gatto infuriato. — Vergogna!'}},\n",
       " {'id': '80',\n",
       "  'translation': {'en': '\"For shame! for shame!\" cried the lady\\'s-maid.',\n",
       "   'it': 'Vergogna! — esclamò la cameriera. — Che gatto arrabbiato!'}},\n",
       " {'id': '81',\n",
       "  'translation': {'en': '\"What shocking conduct, Miss Eyre, to strike a young gentleman, your benefactress\\'s son!',\n",
       "   'it': 'Che scandalosa condotta, signorina Eyre!'}},\n",
       " {'id': '82',\n",
       "  'translation': {'en': 'Your young master.\"',\n",
       "   'it': 'Percuotere il signorino, il figlio della vostra benefattrice, il vostro padroncino!'}},\n",
       " {'id': '83',\n",
       "  'translation': {'en': '\"Master!', 'it': '— Chi è il mio padrone?'}},\n",
       " {'id': '84',\n",
       "  'translation': {'en': 'How is he my master? Am I a servant?\"',\n",
       "   'it': 'Sono forse una serva?'}},\n",
       " {'id': '85',\n",
       "  'translation': {'en': '\"No; you are less than a servant, for you do nothing for your keep.',\n",
       "   'it': '— No, siete meno che una serva, perché non vi guadagnate il pane.'}},\n",
       " {'id': '86',\n",
       "  'translation': {'en': 'There, sit down, and think over your wickedness.\"',\n",
       "   'it': 'Sedetevi qui e pensate alla vostra perfidia.'}},\n",
       " {'id': '87',\n",
       "  'translation': {'en': 'They had got me by this time into the apartment indicated by Mrs. Reed, and had thrust me upon a stool: my impulse was to rise from it like a spring; their two pair of hands arrested me instantly.',\n",
       "   'it': \"Intanto mi avevano condotta nell'appartamento indicato dalla signora Reed e mi avevano gettata su una sedia. Io mi sentii spinta ad alzarmi di botto; quattro mani mi trattennero subito.\"}},\n",
       " {'id': '88',\n",
       "  'translation': {'en': '\"If you don\\'t sit still, you must be tied down,\" said Bessie.',\n",
       "   'it': '— Se non state ferma costì a sedere, vi legheremo, — disse Bessie.'}},\n",
       " {'id': '89',\n",
       "  'translation': {'en': '\"Miss Abbot, lend me your garters; she would break mine directly.\"',\n",
       "   'it': '— Signorina Abbot, prestatemi le vostre legaccie delle calze, perché presto avrò rotto le mie.'}},\n",
       " {'id': '90',\n",
       "  'translation': {'en': 'Miss Abbot turned to divest a stout leg of the necessary ligature.',\n",
       "   'it': 'La signorina Abbot si affrettò a sciogliersi le calze.'}},\n",
       " {'id': '91',\n",
       "  'translation': {'en': 'This preparation for bonds, and the additional ignominy it inferred, took a little of the excitement out of me.',\n",
       "   'it': 'Questo preparativo di legatura e la vergogna che per me ne derivava, calmarono la mia agitazione.'}},\n",
       " {'id': '92',\n",
       "  'translation': {'en': '\"Don\\'t take them off,\" I cried; \"I will not stir.\"',\n",
       "   'it': '— Non vi sciogliete le calze, non mi muoverò.'}},\n",
       " {'id': '93',\n",
       "  'translation': {'en': 'In guarantee whereof, I attached myself to my seat by my hands.',\n",
       "   'it': 'E per dare una prova di ciò che asserivo, mi avviticchiai alla sedia.'}},\n",
       " {'id': '94',\n",
       "  'translation': {'en': '\"Mind you don\\'t,\" said Bessie; and when she had ascertained that I was really subsiding, she loosened her hold of me; then she and Miss Abbot stood with folded arms, looking darkly and doubtfully on my face, as incredulous of my sanity.',\n",
       "   'it': 'Quando fu sicura che avevo veramente intenzione di obbedirla, mi lasciò andare. Allora lei e Abbot incrociarono le braccia e mi guardarono severamente, come se avessero dubitato dello stato della mia mente.'}},\n",
       " {'id': '95',\n",
       "  'translation': {'en': '\"She never did so before,\" at last said Bessie, turning to the Abigail.',\n",
       "   'it': '— Non era mai giunta a tanto, — disse Bessie alla fine, volgendosi verso Abigail Abbot.'}},\n",
       " {'id': '96',\n",
       "  'translation': {'en': '\"But it was always in her,\" was the reply. \"I\\'ve told Missis often my opinion about the child, and Missis agreed with me. She\\'s an underhand little thing: I never saw a girl of her age with so much cover.\"',\n",
       "   'it': '— Ma però si vedeva che sarebbe giunta a questo, — rispose Abbot. — Ho spesso palesato alla signora la mia opinione su questa bambina, e la signora ha convenuto che avevo ragione; è una creatura subdola; non ho mai veduto una bimba della sua età che sapesse finger così bene.'}},\n",
       " {'id': '97',\n",
       "  'translation': {'en': 'Bessie answered not; but ere long, addressing me, she said--\"You ought to be aware, Miss, that you are under obligations to Mrs. Reed: she keeps you: if she were to turn you off, you would have to go to the poorhouse.\"',\n",
       "   'it': 'Bessie non rispose, ma poco dopo, rivolgendosi a me, disse: — Non sapete, signorina, che dovete tutto alla signora Reed? Vi tiene presso di sé, ma se vi mandasse via, dovreste andare in un ricovero di mendicità.'}},\n",
       " {'id': '98',\n",
       "  'translation': {'en': 'I had nothing to say to these words: they were not new to me: my very first recollections of existence included hints of the same kind.',\n",
       "   'it': 'Non avevo nulla da rispondere a quelle parole, che non sonavano nuove al mio orecchio; i più antichi ricordi della mia esistenza si riferivano a parole simili.'}},\n",
       " {'id': '99',\n",
       "  'translation': {'en': 'This reproach of my dependence had become a vague sing-song in my ear: very painful and crushing, but only half intelligible.',\n",
       "   'it': 'Il rimprovero per il mio stato di dipendenza era divenuto per i miei orecchi un sono vago, penoso e opprimente, ma a metà inintelligibile.'}},\n",
       " {'id': '100',\n",
       "  'translation': {'en': 'Miss Abbot joined in-- \"And you ought not to think yourself on an equality with the Misses Reed and Master Reed, because Missis kindly allows you to be brought up with them.',\n",
       "   'it': 'La signorina Abbot soggiunse: — Spero che non vi crederete eguale alle signorine e al signor Reed, perché la signora è così buona da farvi educare insieme con loro.'}},\n",
       " {'id': '101',\n",
       "  'translation': {'en': 'They will have a great deal of money, and you will have none: it is your place to be humble, and to try to make yourself agreeable to them.\"',\n",
       "   'it': 'Essi avranno molto danaro e voi non ne avrete punto; dovreste cercare di studiare di esser umile e di rendervi gradita a loro.'}},\n",
       " {'id': '102',\n",
       "  'translation': {'en': '\"What we tell you is for your good,\" added Bessie, in no harsh voice, \"you should try to be useful and pleasant, then, perhaps, you would have a home here; but if you become passionate and rude, Missis will send you away, I am sure.\"',\n",
       "   'it': '— Quello che vi diciamo, è per il vostro bene, — aggiunse Bessie con voce che non era aspra; — dovreste cercare di rendervi utile e di farvi piacevole e allora forse potreste rimaner qui; ma se divenite violenta e brutale, la signora vi manderà via, ne son certa.'}},\n",
       " {'id': '103',\n",
       "  'translation': {'en': '\"Besides,\" said Miss Abbot, \"God will punish her: He might strike her dead in the midst of her tantrums, and then where would she go?',\n",
       "   'it': '— Inoltre, — continuò Abbot, — Iddio la punirà. Potrebbe colpirla con la morte mentre è in peccato, e allora dove andrà?'}},\n",
       " {'id': '104',\n",
       "  'translation': {'en': \"Come, Bessie, we will leave her: I wouldn't have her heart for anything.\",\n",
       "   'it': 'Venite, Bessie, lasciamola. Non vorrei davvero avere un cuore come il suo.'}},\n",
       " {'id': '105',\n",
       "  'translation': {'en': 'Say your prayers, Miss Eyre, when you are by yourself; for if you don\\'t repent, something bad might be permitted to come down the chimney and fetch you away.\"',\n",
       "   'it': 'Dite le vostre preghiere, signorina Eyre; se non vi pentite, Iddio potrà concedere a qualche spirito malvagio di scendere dalla cappa del camino, e di portarvi via.'}},\n",
       " {'id': '106',\n",
       "  'translation': {'en': 'They went, shutting the door, and locking it behind them.',\n",
       "   'it': 'Le due donne se ne andarono sbatacchiando la porta e poi la chiusero a chiave.'}},\n",
       " {'id': '107',\n",
       "  'translation': {'en': 'The red-room was a square chamber, very seldom slept in, I might say never, indeed, unless when a chance influx of visitors at Gateshead Hall rendered it necessary to turn to account all the accommodation it contained: yet it was one of the largest and stateliest chambers in the mansion.',\n",
       "   'it': \"La camera rossa era una camera riservata, dove raramente qualcuno dormiva. Non l'aveva mai veduta abitata altro che quando vi era molta affluenza di ospiti nella villa di Gateshead e occorreva trar partito da ogni stanza; era una delle camere più grandi e più eleganti della casa.\"}},\n",
       " {'id': '108',\n",
       "  'translation': {'en': 'A bed supported on massive pillars of mahogany, hung with curtains of deep red damask, stood out like a tabernacle in the centre; the two large windows, with their blinds always drawn down, were half shrouded in festoons and falls of similar drapery; the carpet was red; the table at the foot of the bed was covered with a crimson cloth; the walls were a soft fawn colour with a blush of pink in it; the wardrobe, the toilet-table, the chairs were of darkly polished old mahogany.',\n",
       "   'it': \"Le due grandi finestre, con le persiane chiuse, erano ornate di drappeggiamenti della stessa stoffa. Il tappeto era rosso, la tavola, collocata a piè del letto, era coperta con un panno rosso; i muri erano coperti di carta giallastra a rose; l'armadio, la toilette, le seggiole, erano di vecchio mogano ben lustro.\"}},\n",
       " {'id': '109',\n",
       "  'translation': {'en': 'Out of these deep surrounding shades rose high, and glared white, the piled- up mattresses and pillows of the bed, spread with a snowy Marseilles counterpane.',\n",
       "   'it': \"In mezzo a questo cupo arredamento, s'inalzava sul letto e si staccava in bianco, un mucchio di materasse abballinate e di guanciali, nascosti da una coperta di Marsiglia.\"}},\n",
       " {'id': '110',\n",
       "  'translation': {'en': 'Scarcely less prominent was an ample cushioned easy-chair near the head of the bed, also white, with a footstool before it; and looking, as I thought, like a pale throne.',\n",
       "   'it': \"A capo al letto vi era un'ampia e comoda poltrona, pure bianca, con uno sgabellino davanti; pareva un trono.\"}},\n",
       " {'id': '111',\n",
       "  'translation': {'en': 'This room was chill, because it seldom had a fire; it was silent, because remote from the nursery and kitchen; solemn, because it was known to be so seldom entered.',\n",
       "   'it': 'Quella camera era fredda, perché raramente vi si accendeva il fuoco; era silenziosa, perché lontana dalla stanza dei bambini e dalla cucina; era solenne perché raramente vi entrava qualcuno.'}},\n",
       " {'id': '112',\n",
       "  'translation': {'en': \"The house-maid alone came here on Saturdays, to wipe from the mirrors and the furniture a week's quiet dust: and Mrs. Reed herself, at far intervals, visited it to review the contents of a certain secret drawer in the wardrobe, where were stored divers parchments, her jewel-casket, and a miniature of her deceased husband; and in those last words lies the secret of the red-room--the spell which kept it so lonely in spite of its grandeur.\",\n",
       "   'it': \"La cameriera vi andava il sabato per spolverare i mobili e gli specchi dalla polvere di tutta la settimana. La signora Reed pure la visitava a lunghi intervalli per esaminare certi cassetti segreti dell'armadio, dove erano custodite carte di famiglia, la cassetta dei suoi gioielli e la miniatura del suo defunto marito; in queste ultime parole è contenuto il segreto della camera rossa: l'incanto che la rendeva solitaria nonostante la sua bellezza.\"}},\n",
       " {'id': '113',\n",
       "  'translation': {'en': \"Mr. Reed had been dead nine years: it was in this chamber he breathed his last; here he lay in state; hence his coffin was borne by the undertaker's men; and, since that day, a sense of dreary consecration had guarded it from frequent intrusion.\",\n",
       "   'it': \"Il signor Reed era morto da nove anni, e in quella stanza aveva esalato l'ultimo respiro, di là era stata portata via la sua bara, e da quel giorno una specie di culto solenne avevala preservata da frequenti visite.\"}},\n",
       " {'id': '114',\n",
       "  'translation': {'en': 'My seat, to which Bessie and the bitter Miss Abbot had left me riveted, was a low ottoman near the marble chimney-piece; the bed rose before me; to my right hand there was the high, dark wardrobe, with subdued, broken reflections varying the gloss of its panels; to my left were the muffled windows; a great looking-glass between them repeated the vacant majesty of the bed and room.',\n",
       "   'it': \"Il sedile su cui Bessie e l'aspra signorina Abbot mi avevano lasciata, era un'ottomana bassa collocata vicino al caminetto di marmo. Il letto mi stava dinanzi; a diritta il grande e cupo armadio; a sinistra due finestre chiuse con uno specchio nel mezzo, che rifletteva la tetra maestà della camera e del letto.\"}},\n",
       " {'id': '115',\n",
       "  'translation': {'en': 'I was not quite sure whether they had locked the door; and when I dared move, I got up and went to see.',\n",
       "   'it': 'Non ero sicura se la porta fosse stata chiusa, e appena osai muovermi, andai a vedere.'}},\n",
       " {'id': '116',\n",
       "  'translation': {'en': 'Alas! yes: no jail was ever more secure.',\n",
       "   'it': 'Ohimè! sì; nessun prigioniero era stato mai meglio rinchiuso.'}},\n",
       " {'id': '117',\n",
       "  'translation': {'en': 'Returning, I had to cross before the looking- glass; my fascinated glance involuntarily explored the depth it revealed.',\n",
       "   'it': 'Nel ripassare davanti allo specchio, il mio sguardo affascinato su quello involontariamente si posò esplorandone la profondità.'}},\n",
       " {'id': '118',\n",
       "  'translation': {'en': \"All looked colder and darker in that visionary hollow than in reality: and the strange little figure there gazing at me, with a white face and arms specking the gloom, and glittering eyes of fear moving where all else was still, had the effect of a real spirit: I thought it like one of the tiny phantoms, half fairy, half imp, Bessie's evening stories represented as coming out of lone, ferny dells in moors, and appearing before the eyes of belated travellers.\",\n",
       "   'it': \"Ogni cosa riflessa nello specchio pareva più fredda, più trista che nella realtà, e la strana creaturina che mi fissava col viso bianco, le braccia che si staccavano nell'ombra, gli occhi scintillanti e che movevasi timorosamente in quella camera silente, mi parve uno spirito, una di quelle sottili fantasime, metà fate, metà folletti, di cui Bessie parlava nelle novelle narrate la sera accanto al fuoco e che essa ci descriveva uscente dalle valli abbandonate, ove crescono le eriche per apparire dinanzi ai viaggiatori.\"}},\n",
       " {'id': '119',\n",
       "  'translation': {'en': 'I returned to my stool.',\n",
       "   'it': \"Tornai all'ottomana.\"}},\n",
       " {'id': '120',\n",
       "  'translation': {'en': 'Superstition was with me at that moment; but it was not yet her hour for complete victory: my blood was still warm; the mood of the revolted slave was still bracing me with its bitter vigour; I had to stem a rapid rush of retrospective thought before I quailed to the dismal present.',\n",
       "   'it': \"La superstizione si era insinuata nell'anima mia in quel momento; ma essa non trionfava ancora; il sangue mi correva ancora caldo nelle vene; la rabbia della schiava ribelle mi animava ancora con il suo amaro vigore; dovevo trattenere la rapida corsa del pensiero verso il passato prima di lasciarmi abbattere dallo sgomento del presente.\"}},\n",
       " {'id': '121',\n",
       "  'translation': {'en': \"All John Reed's violent tyrannies, all his sisters' proud indifference, all his mother's aversion, all the servants' partiality, turned up in my disturbed mind like a dark deposit in a turbid well.\",\n",
       "   'it': \"Tutte le violente tirannie di John Reed, tutta l'altera indifferenza delle sorelle di lui, l'avversione della loro madre, tutte le parzialità dei servi turbinavano nella mia mente come un deposito nero in una sorgente torbida.\"}},\n",
       " {'id': '122',\n",
       "  'translation': {'en': 'Why was I always suffering, always browbeaten, always accused, for ever condemned?',\n",
       "   'it': 'Perché dovevo sempre soffrire? Perché ero sempre maltrattata, sempre condannata, sempre punita?'}},\n",
       " {'id': '123',\n",
       "  'translation': {'en': 'Why could I never please?',\n",
       "   'it': 'Perché non piacevo a nessuno?'}},\n",
       " {'id': '124',\n",
       "  'translation': {'en': \"Why was it useless to try to win any one's favour?\",\n",
       "   'it': 'Perché ogni tentativo di amicarmi un cuore era un tentativo inutile?'}},\n",
       " {'id': '125',\n",
       "  'translation': {'en': 'Eliza, who was headstrong and selfish, was respected. Georgiana, who had a spoiled temper, a very acrid spite, a captious and insolent carriage, was universally indulged.',\n",
       "   'it': 'Eliza, caparbia ed egoista, era rispettata; Georgiana, che aveva un carattere invidioso, insolente e acre, trovava indulgenza presso tutti.'}},\n",
       " {'id': '126',\n",
       "  'translation': {'en': 'Her beauty, her pink cheeks and golden curls, seemed to give delight to all who looked at her, and to purchase indemnity for every fault.',\n",
       "   'it': \"La sua bellezza, le sue guance rosee e i suoi ricci d'oro, pareva che riempissero di gioia quanti la vedevano e facessero dimenticarne i difetti.\"}},\n",
       " {'id': '127',\n",
       "  'translation': {'en': 'John no one thwarted, much less punished; though he twisted the necks of the pigeons, killed the little pea-chicks, set the dogs at the sheep, stripped the hothouse vines of their fruit, and broke the buds off the choicest plants in the conservatory: he called his mother \"old girl,\" too; sometimes reviled her for her dark skin, similar to his own; bluntly disregarded her wishes; not unfrequently tore and spoiled her silk attire; and he was still \"her own darling.\"',\n",
       "   'it': 'John non era né sgridato né punito, benché torcesse il collo ai piccioni, uccidesse i pavoncelli, aizzasse i cani contro le pecore, devastasse l\\'uva nelle serre, rompesse i rami delle piante esotiche e chiamasse la mamma \"zitellona\". Spesso egli la beffeggiava perché aveva la pelle nera come la sua, la contrariava e le macchiava e le strappava i vestiti di seta, eppure lo chiamava sempre \"amor mio\".'}},\n",
       " {'id': '128',\n",
       "  'translation': {'en': 'I dared commit no fault: I strove to fulfil every duty; and I was termed naughty and tiresome, sullen and sneaking, from morning to noon, and from noon to night.',\n",
       "   'it': 'Io invece non osavo commettere nessuna mancanza, mi sforzavo di compiere i miei doveri, e dalla mattina alla sera sentivo dirmi che ero svogliata e pigra, perfida e intrattabile.'}},\n",
       " {'id': '129',\n",
       "  'translation': {'en': 'My head still ached and bled with the blow and fall I had received: no one had reproved John for wantonly striking me; and because I had turned against him to avert farther irrational violence, I was loaded with general opprobrium.',\n",
       "   'it': 'La testa mi doleva e continuava a sanguinarmi per il colpo ricevuto; nessuno aveva rimproverato John per avermi percossa, e tutti mi avevano biasimata per essermi rivoltata contro di lui onde evitare nuove violenze. — Ingiustizia!'}},\n",
       " {'id': '130',\n",
       "  'translation': {'en': '\"Unjust!--unjust!\" said my reason, forced by the agonising stimulus into precocious though transitory power: and Resolve, equally wrought up, instigated some strange expedient to achieve escape from insupportable oppression--as running away, or, if that could not be effected, never eating or drinking more, and letting myself die.',\n",
       "   'it': 'Ingiustizia! — gridava la mia ragione eccitata dal doloroso stimolo di una precoce energia. Tutto ciò che vi era in me di risoluzione, mi faceva pensare ai mezzi più disperati per togliermi a quella oppressione; pensavo a fuggire, o, se non mi riusciva, a ricusare cibi e bevande per morir di fame.'}},\n",
       " {'id': '131',\n",
       "  'translation': {'en': 'What a consternation of soul was mine that dreary afternoon!',\n",
       "   'it': \"Quale costernazione erasi insinuata nell'anima mia in quel triste pomeriggio!\"}},\n",
       " {'id': '132',\n",
       "  'translation': {'en': 'How all my brain was in tumult, and all my heart in insurrection!',\n",
       "   'it': 'Il sangue tumultuava e il cuore era in piena ribellione.'}},\n",
       " {'id': '133',\n",
       "  'translation': {'en': 'Yet in what darkness, what dense ignorance, was the mental battle fought!',\n",
       "   'it': 'E in quale oscurità, in mezzo a quale densa ignoranza combattevasi quella battaglia mentale!'}},\n",
       " {'id': '134',\n",
       "  'translation': {'en': 'I could not answer the ceaseless inward question--_why_ I thus suffered; now, at the distance of--I will not say how many years, I see it clearly.',\n",
       "   'it': 'Non sapevo rispondere alla incessante domanda del cuore: \"Perché devo soffrir tanto?\". Ora, dopo trascorsi molti anni, tutte quelle ragioni mi appariscono chiaramente.'}},\n",
       " {'id': '135',\n",
       "  'translation': {'en': 'I was a discord in Gateshead Hall: I was like nobody there; I had nothing in harmony with Mrs. Reed or her children, or her chosen vassalage.',\n",
       "   'it': 'Ero causa di discordia alla villa di Gateshead; là non somigliavo a nessuno; non vi era nulla in me che armonizzasse con la signora Reed, con i suoi figli o con i sottoposti, che ella preferiva.'}},\n",
       " {'id': '136',\n",
       "  'translation': {'en': 'If they did not love me, in fact, as little did I love them.',\n",
       "   'it': 'Se però non mi volevano bene, è equo dire che neppur io ne voleva a loro.'}},\n",
       " {'id': '137',\n",
       "  'translation': {'en': 'They were not bound to regard with affection a thing that could not sympathise with one amongst them; a heterogeneous thing, opposed to them in temperament, in capacity, in propensities; a useless thing, incapable of serving their interest, or adding to their pleasure; a noxious thing, cherishing the germs of indignation at their treatment, of contempt of their judgment.',\n",
       "   'it': 'Non erano obbligati a dimostrare affezione a un essere che non poteva simpatizzare con alcuno di essi, con un essere eterogeneo, opposto a loro per temperamento, per capacità e per inclinazioni, un essere inutile, incapace di servire i loro interessi o di associarsi ai loro piaceri, un essere nocivo che sviluppava in sé i germi di indignazione per i loro trattamenti di disprezzo per i loro giudizii.'}},\n",
       " {'id': '138',\n",
       "  'translation': {'en': 'I know that had I been a sanguine, brilliant, careless, exacting, handsome, romping child--though equally dependent and friendless--Mrs. Reed would have endured my presence more complacently; her children would have entertained for me more of the cordiality of fellow-feeling; the servants would have been less prone to make me the scapegoat of the nursery.',\n",
       "   'it': 'Se fossi stata una bimba allegra, senza cure, esigente e sventata, la signora Reed avrebbe sopportata con pazienza la mia presenza, i suoi figli mi avrebbero trattata con quella cordialità che si stabilisce fra coetanii, e i servi sarebbero stati meno propensi a far di me il loro capro espiatorio.'}},\n",
       " {'id': '139',\n",
       "  'translation': {'en': \"Daylight began to forsake the red-room; it was past four o'clock, and the beclouded afternoon was tending to drear twilight.\",\n",
       "   'it': 'La luce del giorno incominciava a disertare la stanza rossa; erano le quattro passate; le nubi che coprivano il cielo dovevano ben presto condurre la tanto temuta oscurità.'}},\n",
       " {'id': '140',\n",
       "  'translation': {'en': 'I heard the rain still beating continuously on the staircase window, and the wind howling in the grove behind the hall; I grew by degrees cold as a stone, and then my courage sank.',\n",
       "   'it': 'Sentivo la pioggia battere contro i vetri delle scale, e il vento mugolare; a poco a poco mi sentii gelare e perdetti ogni coraggio.'}},\n",
       " {'id': '141',\n",
       "  'translation': {'en': 'My habitual mood of humiliation, self-doubt, forlorn depression, fell damp on the embers of my decaying ire.',\n",
       "   'it': 'La consuetudine che avevo presa di essere umile, di dubitare di me stessa, di essere repressa smorzò la mia collera morente.'}},\n",
       " {'id': '142',\n",
       "  'translation': {'en': 'All said I was wicked, and perhaps I might be so; what thought had I been but just conceiving of starving myself to death?',\n",
       "   'it': \"Tutti erano cattivi e forse ero cattiva anch'io: non avevo forse concepita l'idea di lasciarmi morir di fame?\"}},\n",
       " {'id': '143',\n",
       "  'translation': {'en': 'That certainly was a crime: and was I fit to die?',\n",
       "   'it': 'Quello era certo un crimine; ero forse atta a morire?'}},\n",
       " {'id': '144',\n",
       "  'translation': {'en': 'Or was the vault under the chancel of Gateshead Church an inviting bourne?',\n",
       "   'it': 'Oppure la volta sotto la cappella di Gateshead era un soggiorno attraente?'}},\n",
       " {'id': '145',\n",
       "  'translation': {'en': 'In such vault I had been told did Mr. Reed lie buried; and led by this thought to recall his idea, I dwelt on it with gathering dread.',\n",
       "   'it': \"Mi era stato detto che sotto quella vòlta riposava il signor Reed; questo pensiero mi ricondusse e m'ispirò riflessioni spaventose.\"}},\n",
       " {'id': '146',\n",
       "  'translation': {'en': \"I could not remember him; but I knew that he was my own uncle--my mother's brother--that he had taken me when a parentless infant to his house; and that in his last moments he had required a promise of Mrs. Reed that she would rear and maintain me as one of her own children.\",\n",
       "   'it': 'Non potevo rammentarmi di lui, ma sapevo che era mio zio, il fratello di mia madre, che mi aveva presa in casa sua quando ero rimasta orfana e che nei suoi ultimi momenti aveva voluto dalla moglie la promessa che avrebbe continuato a tenermi in casa e a trattarmi come se fossi figlia sua.'}},\n",
       " {'id': '147',\n",
       "  'translation': {'en': \"Mrs. Reed probably considered she had kept this promise; and so she had, I dare say, as well as her nature would permit her; but how could she really like an interloper not of her race, and unconnected with her, after her husband's death, by any tie?\",\n",
       "   'it': \"La signora Reed credeva senza dubbio di aver mantenuto la parola, e ora posso dire che l'aveva infatti mantenuta per quanto glielo permetteva il suo naturale; ma come poteva ella voler bene a un'intrusa che, dopo la morte del marito, non aveva con lei più nessun legame di parentela?\"}},\n",
       " {'id': '148',\n",
       "  'translation': {'en': 'It must have been most irksome to find herself bound by a hard-wrung pledge to stand in the stead of a parent to a strange child she could not love, and to see an uncongenial alien permanently intruded on her own family group.',\n",
       "   'it': \"Era pentita di essersi impegnata con una promessa solenne a far da madre a una bambina cui non poteva voler bene e di vedere un'estranea mescolata al gruppo della sua famiglia.\"}},\n",
       " {'id': '149',\n",
       "  'translation': {'en': 'A singular notion dawned upon me.',\n",
       "   'it': \"Un'idea singolare s'impossessò di me.\"}},\n",
       " {'id': '150',\n",
       "  'translation': {'en': \"I doubted not--never doubted--that if Mr. Reed had been alive he would have treated me kindly; and now, as I sat looking at the white bed and overshadowed walls--occasionally also turning a fascinated eye towards the dimly gleaning mirror--I began to recall what I had heard of dead men, troubled in their graves by the violation of their last wishes, revisiting the earth to punish the perjured and avenge the oppressed; and I thought Mr. Reed's spirit, harassed by the wrongs of his sister's child, might quit its abode--whether in the church vault or in the unknown world of the departed--and rise before me in this chamber.\",\n",
       "   'it': \"Non dubitavo, non avevo mai dubitato, che se il signor Reed fosse vissuto, non mi avrebbe trattata con bontà, e ora mentre guardavo il letto bianco, le pareti scure e che il mio occhio era attratto di tanto in tanto verso lo specchio, che non mandava altro che cupi riflessi, mi tornava alla mente ciò che avevo udito dire sui morti, turbati nel riposo della tomba dalla violazione delle loro ultime volontà, che ritornano sulla terra per punire lo spergiuro e vendicare l'oppresso. Pensavo che lo spirito del signor Reed, oppresso dalle sofferenze imposte alla figlia della sorella, poteva lasciare la sua dimora, fosse questa sotto la vòlta della cappella o nell'ignoto mondo dei trapassati, e apparirmi in quella camera.\"}},\n",
       " {'id': '151',\n",
       "  'translation': {'en': 'I wiped my tears and hushed my sobs, fearful lest any sign of violent grief might waken a preternatural voice to comfort me, or elicit from the gloom some haloed face, bending over me with strange pity. This idea, consolatory in theory, I felt would be terrible if realised: with all my might I endeavoured to stifle it--I endeavoured to be firm.',\n",
       "   'it': \"Mi asciugai le lagrime, repressi i singhiozzi, temendo che la manifestazione troppo violenta del dolore non destasse qualche voce soprannaturale e consolatrice, e non facesse uscire dall'oscurità qualche figura, circondata da un'aureola, che si chinasse su di me esprimendomi la sua strana compassione; perché sentivo che questa idea, confortante in teoria, doveva essere terribile nella realtà e mi studiavo di scacciare quel pensiero e di esser forte.\"}},\n",
       " {'id': '152',\n",
       "  'translation': {'en': 'Shaking my hair from my eyes, I lifted my head and tried to look boldly round the dark room; at this moment a light gleamed on the wall.',\n",
       "   'it': 'Rialzando i capelli che mi cadevano sugli occhi, gettai uno sguardo risoluto intorno a me, nella camera buia; in quel momento un lume scintillò sulla parete.'}},\n",
       " {'id': '153',\n",
       "  'translation': {'en': 'Was it, I asked myself, a ray from the moon penetrating some aperture in the blind?',\n",
       "   'it': 'Non è forse, domandai a me stessa, un raggio di luna che traversa le persiane?'}},\n",
       " {'id': '154',\n",
       "  'translation': {'en': 'No; moonlight was still, and this stirred; while I gazed, it glided up to the ceiling and quivered over my head.',\n",
       "   'it': 'No, la luna è immobile e quella luce vacillava, e mentre io la fissava scorse sul soffitto e si fermò sulla mia testa.'}},\n",
       " {'id': '155',\n",
       "  'translation': {'en': 'I can now conjecture readily that this streak of light was, in all likelihood, a gleam from a lantern carried by some one across the lawn: but then, prepared as my mind was for horror, shaken as my nerves were by agitation, I thought the swift darting beam was a herald of some coming vision from another world.',\n",
       "   'it': \"Suppongo che fosse il riflesso di una lanterna portata da qualcuno che traversava il prato, ma la mia fantasia, predisposta com'era alla paura, i miei nervi, scossi com'erano dall'agitazione, mi fecero rilevare che quel timido raggio di luce fosse l'araldo di una visione del mondo di là.\"}},\n",
       " {'id': '156',\n",
       "  'translation': {'en': 'My heart beat thick, my head grew hot; a sound filled my ears, which I deemed the rushing of wings; something seemed near me; I was oppressed, suffocated: endurance broke down; I rushed to the door and shook the lock in desperate effort.',\n",
       "   'it': 'Il cuore mi batteva con violenza, la mia testa ardeva; un suono mi colpì gli orecchi; pareva un agitarsi di ale; ero oppressa, mi sentivo soffocare. Allora corsi alla porta e feci sforzi inauditi per aprirla.'}},\n",
       " {'id': '157',\n",
       "  'translation': {'en': 'Steps came running along the outer passage; the key turned, Bessie and Abbot entered.',\n",
       "   'it': 'Sentii un rumore di passi, la chiave girò nella toppa; Bessie e la signorina Abbot entrarono.'}},\n",
       " {'id': '158',\n",
       "  'translation': {'en': '\"Miss Eyre, are you ill?\" said Bessie.',\n",
       "   'it': '— Signorina Eyre, vi sentite male? — domandò Bessie.'}},\n",
       " {'id': '159',\n",
       "  'translation': {'en': '\"What a dreadful noise! it went quite through me!\" exclaimed Abbot.',\n",
       "   'it': '— Che rumore indiavolato! Son tutta spaventata, — aggiunse Abbot.'}},\n",
       " {'id': '160',\n",
       "  'translation': {'en': '\"Take me out! Let me go into the nursery!\" was my cry.',\n",
       "   'it': '— Conducetemi via, lasciatemi andare nella camera dei bambini, — gridai.'}},\n",
       " {'id': '161', 'translation': {'en': '\"What for?', 'it': '— Perché?'}},\n",
       " {'id': '162', 'translation': {'en': 'Are you hurt?', 'it': 'Siete malata?'}},\n",
       " {'id': '163',\n",
       "  'translation': {'en': 'Have you seen something?\" again demanded Bessie.',\n",
       "   'it': 'Avete veduto qualcosa? — chiese di nuovo Bessie.'}},\n",
       " {'id': '164',\n",
       "  'translation': {'en': '\"Oh! I saw a light, and I thought a ghost would come.\"',\n",
       "   'it': '— Ho veduto un lume e ho creduto che giungesse uno spirito.'}},\n",
       " {'id': '165',\n",
       "  'translation': {'en': \"I had now got hold of Bessie's hand, and she did not snatch it from me.\",\n",
       "   'it': 'Mi ero impossessata della mano di Bessie ed ella non poteva liberarsi della mia stretta.'}},\n",
       " {'id': '166',\n",
       "  'translation': {'en': '\"She has screamed out on purpose,\" declared Abbot, in some disgust. \"And what a scream!',\n",
       "   'it': \"— S'è messa a gridare senza ragione, — disse Abbot irritata. — Sarebbe scusabile se si fosse sentita male, ma lo ha fatto soltanto per farci accorrere.\"}},\n",
       " {'id': '167',\n",
       "  'translation': {'en': 'If she had been in great pain one would have excused it, but she only wanted to bring us all here: I know her naughty tricks.\"',\n",
       "   'it': 'Conosco le sue perfide malizie.'}},\n",
       " {'id': '168',\n",
       "  'translation': {'en': '\"What is all this?\" demanded another voice peremptorily; and Mrs. Reed came along the corridor, her cap flying wide, her gown rustling stormily.',\n",
       "   'it': \"— Che cosa c'è? — domandò una voce imperiosa, e la signora Reed comparve nel corridoio con la cuffia per aria e il vestito svolazzante per la corsa.\"}},\n",
       " {'id': '169',\n",
       "  'translation': {'en': '\"Abbot and Bessie, I believe I gave orders that Jane Eyre should be left in the red-room till I came to her myself.\"',\n",
       "   'it': '— Abbot, Bessie, credo di aver ordinato che Jane Eyre fosse lasciata nella camera rossa, perché non era tornata in sé.'}},\n",
       " {'id': '170',\n",
       "  'translation': {'en': '\"Miss Jane screamed so loud, ma\\'am,\" pleaded Bessie.',\n",
       "   'it': '— Signora, la signorina Jane gridava tanto forte! — si arrischiò ad osservare Bessie.'}},\n",
       " {'id': '171',\n",
       "  'translation': {'en': '\"Let her go,\" was the only answer.',\n",
       "   'it': '— Lasciatela stare, — rispose ella.'}},\n",
       " {'id': '172',\n",
       "  'translation': {'en': '\"Loose Bessie\\'s hand, child: you cannot succeed in getting out by these means, be assured.',\n",
       "   'it': '— Bambina, lasciate andare la mano di Bessie; con questi espedienti non otterrete nulla.'}},\n",
       " {'id': '173',\n",
       "  'translation': {'en': 'I abhor artifice, particularly in children; it is my duty to show you that tricks will not answer: you will now stay here an hour longer, and it is only on condition of perfect submission and stillness that I shall liberate you then.\" \"O aunt! have pity!',\n",
       "   'it': \"Odio l'ipocrisia, specialmente nei bambini, ed è mio dovere il mostrarvi che con l'inganno non otterrete mai nulla; starete qui un'ora di più e non sarete liberata altro che alla condizione di mostrarvi assolutamente tranquilla e sottomessa.\"}},\n",
       " {'id': '174',\n",
       "  'translation': {'en': 'Forgive me!',\n",
       "   'it': '— Oh! zia, abbiate pietà di me!'}},\n",
       " {'id': '175',\n",
       "  'translation': {'en': 'I cannot endure it--let me be punished some other way! I shall be killed if--\"',\n",
       "   'it': \"Perdonatemi, punitemi in un'altra maniera, ma qui mi sento morire!\"}},\n",
       " {'id': '176', 'translation': {'en': '\"Silence!', 'it': '— Silenzio!'}},\n",
       " {'id': '177',\n",
       "  'translation': {'en': 'This violence is all most repulsive:\" and so, no doubt, she felt it.',\n",
       "   'it': 'Questa violenza mi fa orrore, — e, senza dubbio, ella provava ciò che diceva.'}},\n",
       " {'id': '178',\n",
       "  'translation': {'en': 'I was a precocious actress in her eyes; she sincerely looked on me as a compound of virulent passions, mean spirit, and dangerous duplicity.',\n",
       "   'it': \"Ai suoi occhi ero una commediante precoce e vedeva sinceramente in me un complesso di passioni violente, d'ipocrisia e di doppiezza.\"}},\n",
       " {'id': '179',\n",
       "  'translation': {'en': 'Bessie and Abbot having retreated, Mrs. Reed, impatient of my now frantic anguish and wild sobs, abruptly thrust me back and locked me in, without farther parley.',\n",
       "   'it': 'Bessie e Abbot erano uscite; la signora Reed, esasperata dalle mie paure e dai miei singhiozzi, mi spinse brutalmente nella camera senza profferir parola.'}},\n",
       " {'id': '180',\n",
       "  'translation': {'en': 'I heard her sweeping away; and soon after she was gone, I suppose I had a species of fit: unconsciousness closed the scene.',\n",
       "   'it': 'La sentii allontanarsi. Suppongo di essere stata subito colpita da un deliquio, perché non ho coscienza di ciò che avvenne dopo.'}},\n",
       " {'id': '181', 'translation': {'en': 'CHAPTER III', 'it': 'III.'}},\n",
       " {'id': '182',\n",
       "  'translation': {'en': 'The next thing I remember is, waking up with a feeling as if I had had a frightful nightmare, and seeing before me a terrible red glare, crossed with thick black bars.',\n",
       "   'it': 'Appena tornai in me pervenni ad uscire da un incubo spaventoso e di veder dinanzi agli occhi una luce rossastra a strisce nere e fitte.'}},\n",
       " {'id': '183',\n",
       "  'translation': {'en': 'I heard voices, too, speaking with a hollow sound, and as if muffled by a rush of wind or water: agitation, uncertainty, and an all-predominating sense of terror confused my faculties.',\n",
       "   'it': \"Sentii alcune voci sommesse coperte dal rumore dell'acqua e del vento. L'agitazione, l'incertezza e un senso di terrore avevano gettata una grande confusione nella mia mente.\"}},\n",
       " {'id': '184',\n",
       "  'translation': {'en': 'Ere long, I became aware that some one was handling me; lifting me up and supporting me in a sitting posture, and that more tenderly than I had ever been raised or upheld before.',\n",
       "   'it': 'Dopo poco mi accorsi che qualcuno si avvicinava a me, mi sollevava collocandomi in una posizione più comoda; nessuno mi aveva mai trattato fino a quel momento con tanta sollecitudine affettuosa.'}},\n",
       " {'id': '185',\n",
       "  'translation': {'en': 'I rested my head against a pillow or an arm, and felt easy.',\n",
       "   'it': 'Sentii appoggiarmi la testa su un guanciale o su un braccio, e provai un senso di benessere.'}},\n",
       " {'id': '186',\n",
       "  'translation': {'en': 'In five minutes more the cloud of bewilderment dissolved: I knew quite well that I was in my own bed, and that the red glare was the nursery fire.',\n",
       "   'it': 'In cinque minuti lo smarrimento era scomparso; mi accorsi di esser coricata nel mio letto e che la luce rossastra era quella del fuoco.'}},\n",
       " {'id': '187',\n",
       "  'translation': {'en': 'It was night: a candle burnt on the table; Bessie stood at the bed- foot with a basin in her hand, and a gentleman sat in a chair near my pillow, leaning over me.',\n",
       "   'it': 'Era notte; una candela ardeva sulla tavola; Bessie stava ritta a piè del letto con una catinella in mano, e un signore, seduto al mio capezzale, si chinava su di me.'}},\n",
       " {'id': '188',\n",
       "  'translation': {'en': 'I felt an inexpressible relief, a soothing conviction of protection and security, when I knew that there was a stranger in the room, an individual not belonging to Gateshead, and not related to Mrs. Reed.',\n",
       "   'it': 'Provai un indicibile sollievo, un senso di protezione e di sicurezza, quando mi accorsi che un estraneo era in camera mia, un individuo che non apparteneva a Gateshead nè alla famiglia della signora Reed.'}},\n",
       " {'id': '189',\n",
       "  'translation': {'en': 'Turning from Bessie (though her presence was far less obnoxious to me than that of Abbot, for instance, would have been), I scrutinised the face of the gentleman: I knew him; it was Mr. Lloyd, an apothecary, sometimes called in by Mrs. Reed when the servants were ailing: for herself and the children she employed a physician.',\n",
       "   'it': \"Volgendo lo sguardo da Bessie, benché la sua presenza mi fosse molto meno incresciosa che quella di Abbot, esaminai il volto dell'estraneo. Lo conoscevo, era il signor Lloyd, un farmacista chiamato qualche volta dalla signora Reed quando i servi erano malati, perché per sé e per i figli ricorreva al medico.\"}},\n",
       " {'id': '190',\n",
       "  'translation': {'en': '\"Well, who am I?\" he asked.',\n",
       "   'it': '— Chi sono? — domandò egli.'}},\n",
       " {'id': '191',\n",
       "  'translation': {'en': 'I pronounced his name, offering him at the same time my hand: he took it, smiling and saying, \"We shall do very well by-and-by.\"',\n",
       "   'it': 'Pronunziai il suo nome, stendendogli la mano. Egli la prese e disse sorridendo: — Tutto andrà bene fra poco.'}},\n",
       " {'id': '192',\n",
       "  'translation': {'en': 'Then he laid me down, and addressing Bessie, charged her to be very careful that I was not disturbed during the night.',\n",
       "   'it': 'Poi mi distese con cura, raccomandando a Bessie che nessuno mi disturbasse durante la notte; e dopo aver fatto altre prescrizioni e assicurato che sarebbe tornato il giorno dopo, uscì, con mio gran dispiacere.'}},\n",
       " {'id': '193',\n",
       "  'translation': {'en': 'Having given some further directions, and intimates that he should call again the next day, he departed; to my grief: I felt so sheltered and befriended while he sat in the chair near my pillow; and as he closed the door after him, all the room darkened and my heart again sank: inexpressible sadness weighed it down.',\n",
       "   'it': 'Mi sentivo così ben protetta e così curata mentre egli stava seduto al mio capezzale! Così, quando la porta si chiuse dietro a lui, mi parve che tutto si oscurasse; il mio cuore fu depresso di nuovo da una inesprimibile tristezza.'}},\n",
       " {'id': '194',\n",
       "  'translation': {'en': '\"Do you feel as if you should sleep, Miss?\" asked Bessie, rather softly.',\n",
       "   'it': '— Avete bisogno di dormire, signorina? — domandò Bessie con una certa dolcezza nella voce.'}},\n",
       " {'id': '195',\n",
       "  'translation': {'en': 'Scarcely dared I answer her; for I feared the next sentence might be rough. \"I will try.\"',\n",
       "   'it': 'Non osavo rispondere per timore di sentir quella voce rifarsi aspra. — Proverò. — dissi.'}},\n",
       " {'id': '196',\n",
       "  'translation': {'en': '\"Would you like to drink, or could you eat anything?\"',\n",
       "   'it': '— Volete bere o desiderate mangiare qualche cosa?'}},\n",
       " {'id': '197',\n",
       "  'translation': {'en': '\"No, thank you, Bessie.\"',\n",
       "   'it': '— No, Bessie, vi ringrazio.'}},\n",
       " {'id': '198',\n",
       "  'translation': {'en': '\"Then I think I shall go to bed, for it is past twelve o\\'clock; but you may call me if you want anything in the night.\"',\n",
       "   'it': '— Allora vado a letto, perché è mezzanotte passata; ma potete chiamarmi, se avete bisogno di qualche cosa.'}},\n",
       " {'id': '199',\n",
       "  'translation': {'en': 'Wonderful civility this!',\n",
       "   'it': 'Che gentilezza sorprendente!'}},\n",
       " {'id': '200',\n",
       "  'translation': {'en': 'It emboldened me to ask a question.',\n",
       "   'it': 'Essa mi dette animo a rivolgerle una domanda:'}},\n",
       " {'id': '201',\n",
       "  'translation': {'en': '\"Bessie, what is the matter with me?',\n",
       "   'it': '— Bessie, che cosa mi è accaduto?'}},\n",
       " {'id': '202',\n",
       "  'translation': {'en': 'Am I ill?\"', 'it': 'Sono forse ammalata?'}},\n",
       " {'id': '203',\n",
       "  'translation': {'en': '\"You fell sick, I suppose, in the red-room with crying; you\\'ll be better soon, no doubt.\"',\n",
       "   'it': '— Credo che a forza di piangere siate svenuta nella camera rossa.'}},\n",
       " {'id': '204',\n",
       "  'translation': {'en': \"Bessie went into the housemaid's apartment, which was near. I heard her say--\",\n",
       "   'it': 'Bessie andò nella stanza attigua, destinata alla servitù, e udii che diceva:'}},\n",
       " {'id': '205',\n",
       "  'translation': {'en': '\"Sarah, come and sleep with me in the nursery; I daren\\'t for my life be alone with that poor child to-night: she might die; it\\'s such a strange thing she should have that fit: I wonder if she saw anything.',\n",
       "   'it': \"— Sara, venite a dormir con me nella camera dei bambini; non vorrei stare sola con quella povera piccina, che potrebbe morire. L'accesso che ha avuto è così strano!\"}},\n",
       " {'id': '206',\n",
       "  'translation': {'en': 'Missis was rather too hard.\"',\n",
       "   'it': 'Davvero che la signora è stata troppo dura con lei!'}},\n",
       " {'id': '207',\n",
       "  'translation': {'en': 'Sarah came back with her; they both went to bed; they were whispering together for half-an-hour before they fell asleep.',\n",
       "   'it': \"Sara tornò insieme con Bessie e tutt'e due andarono a letto.\"}},\n",
       " {'id': '208',\n",
       "  'translation': {'en': 'I caught scraps of their conversation, from which I was able only too distinctly to infer the main subject discussed.',\n",
       "   'it': \"Le sentii parlare a voce bassa per una mezz'ora prima di addormentarsi, e afferrai qualche frase della loro conversazione di cui indovinai l'argomento.\"}},\n",
       " {'id': '209',\n",
       "  'translation': {'en': '\"Something passed her, all dressed in white, and vanished\"--\"A great black dog behind him\"--\"Three loud raps on the chamber door\"--\"A light in the churchyard just over his grave,\" &c. &c.',\n",
       "   'it': '— Una forma tutta strana le è passata davanti ed è sparita. – Un grosso cane nero la inseguiva. – Tre violenti colpi alla porta della camera. – Un lume nel cimitero, proprio sopra la tomba.... Questo e altro dicevano le due donne.'}},\n",
       " {'id': '210',\n",
       "  'translation': {'en': 'At last both slept: the fire and the candle went out.',\n",
       "   'it': 'Alla fine si addormentarono e la candela continuò a bruciare.'}},\n",
       " {'id': '211',\n",
       "  'translation': {'en': 'For me, the watches of that long night passed in ghastly wakefulness; strained by dread: such dread as children only can feel.',\n",
       "   'it': 'Passai la notte vegliando angosciosamente; i miei occhi, i miei orecchi, il mio spirito erano tesi per la paura, una di quelle paure di cui i bimbi soltanto sono capaci.'}},\n",
       " {'id': '212',\n",
       "  'translation': {'en': 'No severe or prolonged bodily illness followed this incident of the red- room; it only gave my nerves a shock of which I feel the reverberation to this day.',\n",
       "   'it': \"Nessuna malattia lunga e seria tenne dietro a quell'incidente della camera rossa, esso dette soltanto una scossa tale ai miei nervi che la risento tuttora.\"}},\n",
       " {'id': '213',\n",
       "  'translation': {'en': 'Yes, Mrs. Reed, to you I owe some fearful pangs of mental suffering, but I ought to forgive you, for you knew not what you did: while rending my heart-strings, you thought you were only uprooting my bad propensities.',\n",
       "   'it': '— Sì, signora Reed, grazie a voi, ho sofferto le dolorose angosce della sofferenza mentale. Ma devo perdonarvi, perché ignara di quello che facevate; perché, credendo di sradicare le mie cattive tendenze, mi spezzavate il cuore.'}},\n",
       " {'id': '214',\n",
       "  'translation': {'en': 'Next day, by noon, I was up and dressed, and sat wrapped in a shawl by the nursery hearth.',\n",
       "   'it': 'La mattina dopo, verso mezzogiorno, ero alzata e vestita, e, dopo essermi rinvoltata in uno scialle, mi ero seduta accanto al fuoco.'}},\n",
       " {'id': '215',\n",
       "  'translation': {'en': 'I felt physically weak and broken down: but my worse ailment was an unutterable wretchedness of mind: a wretchedness which kept drawing from me silent tears; no sooner had I wiped one salt drop from my cheek than another followed. Yet, I thought, I ought to have been happy, for none of the Reeds were there, they were all gone out in the carriage with their mama. Abbot, too, was sewing in another room, and Bessie, as she moved hither and thither, putting away toys and arranging drawers, addressed to me every now and then a word of unwonted kindness.',\n",
       "   'it': \"Mi sentivo debole e affranta, ma la mia maggior sofferenza proveniva da un grande abbattimento di spirito, che mi strappava lagrime mute; appena ne aveva rasciugata una, un'altra mi scendeva sulle guancie; eppure avrei dovuto esser felice, perché nessuno dei Reed era in casa; erano tutti usciti in carrozza con la loro mamma; anche Abbot cuciva in un'altra stanza e Bessie, che andava e veniva per riordinare i cassetti, mi rivolgeva di tanto in tanto una parola straordinariamente dolce.\"}},\n",
       " {'id': '216',\n",
       "  'translation': {'en': 'This state of things should have been to me a paradise of peace, accustomed as I was to a life of ceaseless reprimand and thankless fagging; but, in fact, my racked nerves were now in such a state that no calm could soothe, and no pleasure excite them agreeably.',\n",
       "   'it': 'Avrei dovuto credermi in paradiso, assuefatta come ero a continui rimproveri e a sforzi incompresi; ma i miei nervi erano così scossi, che la calma non poteva più calmarli, e il piacere non poteva più eccitarli piacevolmente. Bessie scese in cucina e mi portò una piccola torta, su un bel piatto cinese coperto di uccelli del paradiso, posati su convolvoli e bocci di rose.'}},\n",
       " {'id': '217',\n",
       "  'translation': {'en': 'Bessie had been down into the kitchen, and she brought up with her a tart on a certain brightly painted china plate, whose bird of paradise, nestling in a wreath of convolvuli and rosebuds, had been wont to stir in me a most enthusiastic sense of admiration; and which plate I had often petitioned to be allowed to take in my hand in order to examine it more closely, but had always hitherto been deemed unworthy of such a privilege. This precious vessel was now placed on my knee, and I was cordially invited to eat the circlet of delicate pastry upon it.',\n",
       "   'it': 'Quel piatto aveva sempre suscitato in me una viva ammirazione; avevo spesso chiesto il permesso di prenderlo in mano per guardarlo con agio, ma fino allora ero stata riputata indegna di quel favore, e ora quella preziosa porcellana era posata sulle mie ginocchia e mi invitava amichevolmente a mangiare il dolce che conteneva. Vano favore!'}},\n",
       " {'id': '218',\n",
       "  'translation': {'en': 'Vain favour! coming, like most other favours long deferred and often wished for, too late!',\n",
       "   'it': 'Esso giungeva troppo tardi, come quasi tutti i favori lungamente desiderati e spesso negati.'}},\n",
       " {'id': '219',\n",
       "  'translation': {'en': 'I could not eat the tart; and the plumage of the bird, the tints of the flowers, seemed strangely faded: I put both plate and tart away.',\n",
       "   'it': 'Non potei mangiare la torta, e le piume degli uccelli e le tinte dei fiori mi parvero sbiaditi. Misi da parte il piatto e la torta.'}},\n",
       " {'id': '220',\n",
       "  'translation': {'en': \"Bessie asked if I would have a book: the word _book_ acted as a transient stimulus, and I begged her to fetch Gulliver's Travels from the library.\",\n",
       "   'it': 'Quella parola libro mi produsse una puntura momentanea. Peraltro le chiesi di portarmi Il viaggio di Gulliver, che era nella biblioteca.'}},\n",
       " {'id': '221',\n",
       "  'translation': {'en': 'This book I had again and again perused with delight.',\n",
       "   'it': 'Avevo letto e riletto quel libro sempre con nuovo piacere.'}},\n",
       " {'id': '222',\n",
       "  'translation': {'en': \"I considered it a narrative of facts, and discovered in it a vein of interest deeper than what I found in fairy tales: for as to the elves, having sought them in vain among foxglove leaves and bells, under mushrooms and beneath the ground-ivy mantling old wall-nooks, I had at length made up my mind to the sad truth, that they were all gone out of England to some savage country where the woods were wilder and thicker, and the population more scant; whereas, Lilliput and Brobdignag being, in my creed, solid parts of the earth's surface, I doubted not that I might one day, by taking a long voyage, see with my own eyes the little fields, houses, and trees, the diminutive people, the tiny cows, sheep, and birds of the one realm; and the corn-fields forest-high, the mighty mastiffs, the monster cats, the tower-like men and women, of the other.\",\n",
       "   'it': \"Prendevo quei racconti come fatti veri e vi trovavo più soddisfazione che nei racconti delle fate, perché dopo aver cercato invano le silfidi fra le campanule, i muschi, le foglie e le edere che coprivano i vecchi muri, mi ero alfine rassegnata pensando che esse avessero abbandonato l'Inghilterra per rifugiarsi in qualche paese, ove i boschi fossero più incolti, più folti, dove gli uomini avessero maggior bisogno di loro, mentre che Lilliput e Brobdignag erano collocati per me in qualche angolo della terra, e non dubitavo che un giorno, potendo fare un lungo viaggio, avrei veduto i piccoli alberi, i piccoli campi, le piccole case di quel popolo minuscolo; le vacche, le pecore, gli uccelli di uno dei regni, o le alte foreste, i cani enormi, i mostruosi gatti, gli uomini immensi dell'altro impero.\"}},\n",
       " {'id': '223',\n",
       "  'translation': {'en': 'Yet, when this cherished volume was now placed in my hand--when I turned over its leaves, and sought in its marvellous pictures the charm I had, till now, never failed to find--all was eerie and dreary; the giants were gaunt goblins, the pigmies malevolent and fearful imps, Gulliver a most desolate wanderer in most dread and dangerous regions.',\n",
       "   'it': \"Pure quando quel caro libro fu posto fra le mie mani, quando mi misi a sfogliarne le pagine, cercando nelle vignette l'attrattiva che vi avevo sempre trovata, tutto mi parve cupo e nudo. I giganti non erano più altro che spettri scarni, i pigmei, altro che genietti perfidi; Gulliver, un viaggiatore disperato errante in regioni pericolose e spaventose.\"}},\n",
       " {'id': '224',\n",
       "  'translation': {'en': 'I closed the book, which I dared no longer peruse, and put it on the table, beside the untasted tart.',\n",
       "   'it': 'Chiusi il libro e lo posai sulla tavola, accanto alla torta, che non avevo assaggiata.'}},\n",
       " {'id': '225',\n",
       "  'translation': {'en': \"Bessie had now finished dusting and tidying the room, and having washed her hands, she opened a certain little drawer, full of splendid shreds of silk and satin, and began making a new bonnet for Georgiana's doll.\",\n",
       "   'it': 'Bessie aveva terminato di mettere in ordine la camera, e, dopo essersi lavate le mani, aprì un cassetto, e ne cavò alcuni pezzi di seta scintillante per fare un cappello nuovo alla bambola di Georgiana.'}},\n",
       " {'id': '226',\n",
       "  'translation': {'en': 'Meantime she sang: her song was--',\n",
       "   'it': 'Ella incominciò a cantare:'}},\n",
       " {'id': '227',\n",
       "  'translation': {'en': '\"In the days when we went gipsying, A long time ago.\"',\n",
       "   'it': '\"C\\'era una volta, tanto tanto tempo fa, quando vivevamo come zingari....\"'}},\n",
       " {'id': '228',\n",
       "  'translation': {'en': 'I had often heard the song before, and always with lively delight; for Bessie had a sweet voice,--at least, I thought so. But now, though her voice was still sweet, I found in its melody an indescribable sadness.',\n",
       "   'it': \"Avevo spesso udito quel canto e mi rendeva spesso allegra, perché Bessie aveva una voce dolce, almeno mi pareva tale; ma in quel momento, nonostante che la sua voce fosse sempre la stessa, pure i suoi accenti mi parevano impregnati d'immensa tristezza.\"}},\n",
       " {'id': '229',\n",
       "  'translation': {'en': 'Sometimes, preoccupied with her work, she sang the refrain very low, very lingeringly; \"A long time ago\" came out like the saddest cadence of a funeral hymn.',\n",
       "   'it': 'Qualche volta, occupata dal lavoro, ripeteva il ritornello a voce bassissima, e queste parole: \"C\\'era una volta, tanto tanto tempo fa\" mi facevano l\\'impressione di un inno funebre.'}},\n",
       " {'id': '230',\n",
       "  'translation': {'en': 'She passed into another ballad, this time a really doleful one.',\n",
       "   'it': \"Ella intonò un'altra ballata, veramente malinconica, che diceva:\"}},\n",
       " {'id': '231',\n",
       "  'translation': {'en': '\"My feet they are sore, and my limbs they are weary; Long is the way, and the mountains are wild; Soon will the twilight close moonless and dreary Over the path of the poor orphan child.',\n",
       "   'it': '\"I miei piedi sono feriti, le mie membra sono stanche. La via lunga, la montagna è selvaggia; ben presto il triste crepuscolo che la luna non rischiarerà più con i suoi raggi, spanderà le tenebre sul cammino del povero orfanello.'}},\n",
       " {'id': '232',\n",
       "  'translation': {'en': 'Why did they send me so far and so lonely, Up where the moors spread and grey rocks are piled?',\n",
       "   'it': '\"Perché mi hanno mandato così solo e così lontano, là ove si stendono le paludi, là ove sono ammonticchiate le cupe roccie?'}},\n",
       " {'id': '233',\n",
       "  'translation': {'en': \"Men are hard-hearted, and kind angels only Watch o'er the steps of a poor orphan child.\",\n",
       "   'it': \"Il cuore dell'uomo è duro e i buoni angioli solamente vegliano i passi del povero orfanello.\"}},\n",
       " {'id': '234',\n",
       "  'translation': {'en': 'Yet distant and soft the night breeze is blowing, Clouds there are none, and clear stars beam mild, God, in His mercy, protection is showing, Comfort and hope to the poor orphan child.',\n",
       "   'it': '\"Però la brezza della sera soffia dolcemente; il cielo è senza nubi e le stelle scintillanti spandono i loro puri raggi. Iddio, nella sua bontà, concede protezione, sostegno e speranza al povero orfanello.'}},\n",
       " {'id': '235',\n",
       "  'translation': {'en': \"Ev'n should I fall o'er the broken bridge passing, Or stray in the marshes, by false lights beguiled, Still will my Father, with promise and blessing, Take to His bosom the poor orphan child.\",\n",
       "   'it': '\"Anche se cadessi passando sul ponte in rovina, anche se dovessi errare, attratto da fuochi fatui, nelle paludi, mio Padre, che è in Cielo, mormorerebbe nel mio orecchio promesse e benedizioni e stringerebbe sul suo cuore l\\'orfanello.'}},\n",
       " {'id': '236',\n",
       "  'translation': {'en': 'There is a thought that for strength should avail me, Though both of shelter and kindred despoiled; Heaven is a home, and a rest will not fail me; God is a friend to the poor orphan child.\"',\n",
       "   'it': '\"Questo pensiero deve infondermi coraggio, benché non abbia né ricovero né genitori. Il cielo è la mia casa, e lassù non mi mancherà il riposo.'}},\n",
       " {'id': '237',\n",
       "  'translation': {'en': '\"Come, Miss Jane, don\\'t cry,\" said Bessie as she finished.',\n",
       "   'it': '— Venga, signorina Jane, non pianga! — esclamò Bessie quando ebbe terminato.'}},\n",
       " {'id': '238',\n",
       "  'translation': {'en': 'She might as well have said to the fire, \"don\\'t burn!\" but how could she divine the morbid suffering to which I was a prey?',\n",
       "   'it': 'Tanto valeva dire al fuoco di non bruciare; ma come avrebbe fatto ella a indovinare le sofferenze alle quali ero in preda?'}},\n",
       " {'id': '239',\n",
       "  'translation': {'en': 'In the course of the morning Mr. Lloyd came again.',\n",
       "   'it': 'Il signor Lloyd tornò a vedermi.'}},\n",
       " {'id': '240',\n",
       "  'translation': {'en': '\"What, already up!\" said he, as he entered the nursery.',\n",
       "   'it': '— Come, già alzata? — disse entrando.'}},\n",
       " {'id': '241',\n",
       "  'translation': {'en': '\"Well, nurse, how is she?\"',\n",
       "   'it': '— Ebbene, Bessie, come sta la piccina?'}},\n",
       " {'id': '242',\n",
       "  'translation': {'en': 'Bessie answered that I was doing very well.',\n",
       "   'it': 'Bessie rispose che stavo bene.'}},\n",
       " {'id': '243',\n",
       "  'translation': {'en': '\"Then she ought to look more cheerful.',\n",
       "   'it': '— Allora dovrebbe essere più allegra....'}},\n",
       " {'id': '244',\n",
       "  'translation': {'en': 'Come here, Miss Jane: your name is Jane, is it not?\"',\n",
       "   'it': 'Venite qui, signorina Jane.... vi chiamate Jane, non è vero?'}},\n",
       " {'id': '245',\n",
       "  'translation': {'en': '\"Yes, sir, Jane Eyre.\"',\n",
       "   'it': '— Sì, signore, Jane Eyre.'}},\n",
       " {'id': '246',\n",
       "  'translation': {'en': '\"Well, you have been crying, Miss Jane Eyre; can you tell me what about?',\n",
       "   'it': '— Ebbene, avete pianto, signorina Jane Eyre; mi potrebbe dire per chi?'}},\n",
       " {'id': '247',\n",
       "  'translation': {'en': 'Have you any pain?\"',\n",
       "   'it': 'Avete qualche dispiacere?'}},\n",
       " {'id': '248',\n",
       "  'translation': {'en': '\"No, sir.\" \"Oh!', 'it': '— No, signore.'}},\n",
       " {'id': '249',\n",
       "  'translation': {'en': 'I daresay she is crying because she could not go out with Missis in the carriage,\" interposed Bessie.',\n",
       "   'it': '— Piange, certo, perché non ha potuto andare in carrozza con la signora, — disse Bessie.'}},\n",
       " {'id': '250',\n",
       "  'translation': {'en': '\"Surely not! why, she is too old for such pettishness.\"',\n",
       "   'it': '— Oh! no; è troppo grande per piangere per una sciocchezza simile.'}},\n",
       " {'id': '251',\n",
       "  'translation': {'en': 'I thought so too; and my self-esteem being wounded by the false charge, I answered promptly, \"I never cried for such a thing in my life: I hate going out in the carriage.',\n",
       "   'it': 'Io la pensavo pure così, e sentendo offeso il mio amor proprio, risposi prontamente: — Non ho pianto mai per una inezia di quel genere.'}},\n",
       " {'id': '252',\n",
       "  'translation': {'en': 'I cry because I am miserable.\"',\n",
       "   'it': 'Detesto di uscire in carrozza; ho pianto perché sono infelice.'}},\n",
       " {'id': '253',\n",
       "  'translation': {'en': '\"Oh fie, Miss!\" said Bessie.',\n",
       "   'it': '— Vergogna, signorina, — disse Bessie.'}},\n",
       " {'id': '254',\n",
       "  'translation': {'en': 'The good apothecary appeared a little puzzled.',\n",
       "   'it': 'Il buon farmacista rimase impacciato.'}},\n",
       " {'id': '255',\n",
       "  'translation': {'en': 'I was standing before him; he fixed his eyes on me very steadily: his eyes were small and grey; not very bright, but I dare say I should think them shrewd now: he had a hard-featured yet good-natured looking face.',\n",
       "   'it': \"Ero ritta davanti a lui, ed egli fissò su di me i suoi occhi scrutatori. Erano grigi, piccoli e mancavano di splendore; ora mi pare che li giudicherei penetranti: era brutto, ma aveva l'aspetto buono.\"}},\n",
       " {'id': '256',\n",
       "  'translation': {'en': 'Having considered me at leisure, he said--',\n",
       "   'it': 'Dopo avermi considerata con agio, mi disse:'}},\n",
       " {'id': '257',\n",
       "  'translation': {'en': '\"What made you ill yesterday?\"',\n",
       "   'it': '— Che cosa vi fece ammalare ieri?'}},\n",
       " {'id': '258',\n",
       "  'translation': {'en': '\"She had a fall,\" said Bessie, again putting in her word.',\n",
       "   'it': '— Cadde, — disse Bessie, prendendo di nuovo la parola.'}},\n",
       " {'id': '259',\n",
       "  'translation': {'en': '\"Fall! why, that is like a baby again!',\n",
       "   'it': '— Cadde! È forse una bimba piccina?'}},\n",
       " {'id': '260',\n",
       "  'translation': {'en': \"Can't she manage to walk at her age?\",\n",
       "   'it': 'Non sa camminare alla sua età?'}},\n",
       " {'id': '261',\n",
       "  'translation': {'en': 'She must be eight or nine years old.\"',\n",
       "   'it': 'Deve avere otto o nove anni.'}},\n",
       " {'id': '262',\n",
       "  'translation': {'en': '\"I was knocked down,\" was the blunt explanation, jerked out of me by another pang of mortified pride; \"but that did not make me ill,\" I added; while Mr. Lloyd helped himself to a pinch of snuff.',\n",
       "   'it': '— Mi hanno buttata in terra, — risposi vivamente, sentendo di nuovo una ribellione di amor proprio, — ma non per quello mi sono ammalata, — aggiunsi mentre il signor Lloyd si consolava con una presa di tabacco.'}},\n",
       " {'id': '263',\n",
       "  'translation': {'en': \"As he was returning the box to his waistcoat pocket, a loud bell rang for the servants' dinner; he knew what it was.\",\n",
       "   'it': 'Mentre egli riponeva in tasca la tabacchiera, si sentì la campana che annunciava il pranzo della servitù.'}},\n",
       " {'id': '264',\n",
       "  'translation': {'en': '\"That\\'s for you, nurse,\" said he; \"you can go down; I\\'ll give Miss Jane a lecture till you come back.\"',\n",
       "   'it': '— Vi chiamano, Bessie, — disse il farmacista volgendosi verso la bambinaia. — Potete scendere; io leggerò qualche cosa alla signorina Jane, finché non tornerete.'}},\n",
       " {'id': '265',\n",
       "  'translation': {'en': 'Bessie would rather have stayed, but she was obliged to go, because punctuality at meals was rigidly enforced at Gateshead Hall.',\n",
       "   'it': \"Bessie avrebbe preferito di rimanere, ma fu costretta a scendere, perché sapeva che l'esattezza era un dovere che occorreva compiere a Gateshead.\"}},\n",
       " {'id': '266',\n",
       "  'translation': {'en': '\"The fall did not make you ill; what did, then?\" pursued Mr. Lloyd when Bessie was gone.',\n",
       "   'it': '— Se non è la caduta che vi ha fatto ammalare, che cosa è stato dunque? — continuò il signor Lloyd quando Bessie se ne fu andata.'}},\n",
       " {'id': '267',\n",
       "  'translation': {'en': '\"I was shut up in a room where there is a ghost till after dark.\"',\n",
       "   'it': '— Mi hanno rinchiusa sola nella camera rossa che è visitata la notte da uno spirito.'}},\n",
       " {'id': '268',\n",
       "  'translation': {'en': 'I saw Mr. Lloyd smile and frown at the same time.',\n",
       "   'it': 'Vidi il signor Lloyd sorridere e aggrottare lo sopracciglia.'}},\n",
       " {'id': '269', 'translation': {'en': '\"Ghost!', 'it': '— Uno spirito!'}},\n",
       " {'id': '270',\n",
       "  'translation': {'en': 'What, you are a baby after all! You are afraid of ghosts?\"',\n",
       "   'it': 'Siete davvero una piccinuccia se avete paura degli spiriti!'}},\n",
       " {'id': '271',\n",
       "  'translation': {'en': '\"Of Mr. Reed\\'s ghost I am: he died in that room, and was laid out there.',\n",
       "   'it': \"— Sì, ho paura dell'ombra del signor Reed, che morì in quella camera, e di là fu portato a sotterrare.\"}},\n",
       " {'id': '272',\n",
       "  'translation': {'en': 'Neither Bessie nor any one else will go into it at night, if they can help it; and it was cruel to shut me up alone without a candle,--so cruel that I think I shall never forget it.\"',\n",
       "   'it': 'Né Bessie né altri entrano la sera in quella stanza, se ne possono fare a meno, ed è stata una crudeltà di rinchiudermici sola senza lume, tanta crudeltà che mi pare di non potermene scordar mai più.'}},\n",
       " {'id': '273', 'translation': {'en': '\"Nonsense!', 'it': '— Sciocchezze!'}},\n",
       " {'id': '274',\n",
       "  'translation': {'en': 'And is it that makes you so miserable?',\n",
       "   'it': 'E fu quello che vi rese infelice?'}},\n",
       " {'id': '275',\n",
       "  'translation': {'en': 'Are you afraid now in daylight?\"',\n",
       "   'it': 'Avete paura anche di giorno?'}},\n",
       " {'id': '276',\n",
       "  'translation': {'en': '\"No: but night will come again before long: and besides,--I am unhappy,--very unhappy, for other things.\"',\n",
       "   'it': '— No, ma la notte tornerà fra poco; del resto, sono infelice per altre ragioni.'}},\n",
       " {'id': '277', 'translation': {'en': '\"What other things?', 'it': '— Quali?'}},\n",
       " {'id': '278',\n",
       "  'translation': {'en': 'Can you tell me some of them?\"',\n",
       "   'it': 'Ditene qualcuna.'}},\n",
       " {'id': '279',\n",
       "  'translation': {'en': 'How much I wished to reply fully to this question! How difficult it was to frame any answer!',\n",
       "   'it': 'Come avrei desiderato di rispondere sinceramente a quella domanda! ma come era difficile il farlo!'}},\n",
       " {'id': '280',\n",
       "  'translation': {'en': 'Children can feel, but they cannot analyse their feelings; and if the analysis is partially effected in thought, they know not how to express the result of the process in words.',\n",
       "   'it': \"I bimbi sentono, ma non analizzano i loro sentimenti, e se col pensiero riescono a far parzialmente quell'analisi, non sanno tradurla in parole.\"}},\n",
       " {'id': '281',\n",
       "  'translation': {'en': 'Fearful, however, of losing this first and only opportunity of relieving my grief by imparting it, I, after a disturbed pause, contrived to frame a meagre, though, as far as it went, true response.',\n",
       "   'it': \"Però, siccome temevo di perdere la prima e farne l'unica occasione di mitigare il mio dolore sfogandolo con altri, feci, dopo un istante di turbamento, questa breve, ma sincera risposta:\"}},\n",
       " {'id': '282',\n",
       "  'translation': {'en': '\"For one thing, I have no father or mother, brothers or sisters.\"',\n",
       "   'it': '— Prima di tutto non ho né padre né madre, né fratelli né sorelle.'}},\n",
       " {'id': '283',\n",
       "  'translation': {'en': '\"You have a kind aunt and cousins.\"',\n",
       "   'it': '— Avete però una buona zia e dei buoni cugini....'}},\n",
       " {'id': '284',\n",
       "  'translation': {'en': 'Again I paused; then bunglingly enounced--',\n",
       "   'it': 'Feci una pausa e poi risposi francamente:'}},\n",
       " {'id': '285',\n",
       "  'translation': {'en': '\"But John Reed knocked me down, and my aunt shut me up in the red-room.\"',\n",
       "   'it': '— John Reed mi buttò in terra e la zia mi rinchiuse nella sala rossa.'}},\n",
       " {'id': '286',\n",
       "  'translation': {'en': 'Mr. Lloyd a second time produced his snuff-box.',\n",
       "   'it': 'II signor Lloyd per la seconda volta ricorse alla sua tabacchiera.'}},\n",
       " {'id': '287',\n",
       "  'translation': {'en': '\"Don\\'t you think Gateshead Hall a very beautiful house?\" asked he. \"Are you not very thankful to have such a fine place to live at?\"',\n",
       "   'it': '— La villa di Gateshead non vi par bella? non siete riconoscente di vivere in una casa così bella?'}},\n",
       " {'id': '288',\n",
       "  'translation': {'en': '\"It is not my house, sir; and Abbot says I have less right to be here than a servant.\"',\n",
       "   'it': '— Non è la mia casa, signore, e Abbot dice che ho meno diritto che una serva di abitarvi.'}},\n",
       " {'id': '289',\n",
       "  'translation': {'en': '\"Pooh! you can\\'t be silly enough to wish to leave such a splendid place?\"',\n",
       "   'it': '— Non siete, spero, tanto stupida da desiderare di andarvene.'}},\n",
       " {'id': '290',\n",
       "  'translation': {'en': '\"If I had anywhere else to go, I should be glad to leave it; but I can never get away from Gateshead till I am a woman.\"',\n",
       "   'it': '— Se potessi andare altrove, sarei ben contenta di lasciarla, ma non posso farlo finché sono piccina.'}},\n",
       " {'id': '291',\n",
       "  'translation': {'en': '\"Perhaps you may--who knows?',\n",
       "   'it': '— Forse potreste.... chi sa?'}},\n",
       " {'id': '292',\n",
       "  'translation': {'en': 'Have you any relations besides Mrs. Reed?\"',\n",
       "   'it': 'Avete altri parenti oltre la signora Reed?'}},\n",
       " {'id': '293',\n",
       "  'translation': {'en': '\"I think not, sir.\"', 'it': '— Non credo, signore.'}},\n",
       " {'id': '294',\n",
       "  'translation': {'en': '\"None belonging to your father?\"',\n",
       "   'it': '— Nessuno dal lato paterno?'}},\n",
       " {'id': '295',\n",
       "  'translation': {'en': '\"I don\\'t know. I asked Aunt Reed once, and she said possibly I might have some poor, low relations called Eyre, but she knew nothing about them.\"',\n",
       "   'it': '— Non so; lo domandai una volta alla signora Reed; ella mi disse che potevo avere qualche parente povero che portasse il cognome di Eyre, ma che non sapeva nulla di loro.'}},\n",
       " {'id': '296',\n",
       "  'translation': {'en': '\"If you had such, would you like to go to them?\"',\n",
       "   'it': '— Se ne aveste, vorreste andare con essi?'}},\n",
       " {'id': '297', 'translation': {'en': 'I reflected.', 'it': 'Riflettei.'}},\n",
       " {'id': '298',\n",
       "  'translation': {'en': 'Poverty looks grim to grown people; still more so to children: they have not much idea of industrious, working, respectable poverty; they think of the word only as connected with ragged clothes, scanty food, fireless grates, rude manners, and debasing vices: poverty for me was synonymous with degradation.',\n",
       "   'it': \"La povertà sgomenta gli uomini e più ancora i bambini. Essi non hanno idea di una povertà industre, operosa e rispettabile; la parola evoca nella loro mente l'immagine di vesti stracciate, di scarso cibo, di focolare spento, di cattive maniere e di vizii degradanti; per me povertà era sinonima di degradazione.\"}},\n",
       " {'id': '299',\n",
       "  'translation': {'en': '\"No; I should not like to belong to poor people,\" was my reply.',\n",
       "   'it': '— No, — risposi, — non vorrei appartenere a povera gente.'}},\n",
       " {'id': '300',\n",
       "  'translation': {'en': '\"Not even if they were kind to you?\"',\n",
       "   'it': '— Nemmeno se fosse buona per voi?'}},\n",
       " {'id': '301',\n",
       "  'translation': {'en': 'I shook my head: I could not see how poor people had the means of being kind; and then to learn to speak like them, to adopt their manners, to be uneducated, to grow up like one of the poor women I saw sometimes nursing their children or washing their clothes at the cottage doors of the village of Gateshead: no, I was not heroic enough to purchase liberty at the price of caste.',\n",
       "   'it': 'Scrollai la testa; non potevo capire come avrebbe potuto esser buona quella gente se era povera; e poi imparare a parlar come i poveri, acquistare le loro maniere, non avere educazione, crescere come quelle misere donne, che vedevo allattare i bimbi e lavare il bucato sulla porta delle casupole del villaggio; no, non ero abbastanza eroica per acquistare la libertà col suo corteo di miserie.'}},\n",
       " {'id': '302',\n",
       "  'translation': {'en': '\"But are your relatives so very poor?',\n",
       "   'it': '— Ma i vostri parenti sono dunque tanto poveri?'}},\n",
       " {'id': '303',\n",
       "  'translation': {'en': 'Are they working people?\"',\n",
       "   'it': 'Sono forse operai?'}},\n",
       " {'id': '304',\n",
       "  'translation': {'en': '\"I cannot tell; Aunt Reed says if I have any, they must be a beggarly set: I should not like to go a begging.\"',\n",
       "   'it': \"— Non saprei dirlo; mia zia assicura che, se ne ho, debbono appartenere alla classe dei mendicanti, e io non vorrei chiedere l'elemosina.\"}},\n",
       " {'id': '305',\n",
       "  'translation': {'en': '\"Would you like to go to school?\"',\n",
       "   'it': '— Vorreste andare in pensione?'}},\n",
       " {'id': '306',\n",
       "  'translation': {'en': \"Again I reflected: I scarcely knew what school was: Bessie sometimes spoke of it as a place where young ladies sat in the stocks, wore backboards, and were expected to be exceedingly genteel and precise: John Reed hated his school, and abused his master; but John Reed's tastes were no rule for mine, and if Bessie's accounts of school-discipline (gathered from the young ladies of a family where she had lived before coming to Gateshead) were somewhat appalling, her details of certain accomplishments attained by these same young ladies were, I thought, equally attractive.\",\n",
       "   'it': 'John Reed odiava la sua pensione e si burlava dei maestri; ma i gusti di John non potevano esser di norma ai miei. Se i particolari che mi aveva dati Bessie, particolari che aveva appresi dalle ragazze di una casa dove aveva vissuto prima, mi sgomentavano un poco, ero però attratta dalle cognizioni che quelle stesse ragazze avevano acquistate.'}},\n",
       " {'id': '307',\n",
       "  'translation': {'en': 'She boasted of beautiful paintings of landscapes and flowers by them executed; of songs they could sing and pieces they could play, of purses they could net, of French books they could translate; till my spirit was moved to emulation as I listened.',\n",
       "   'it': \"Bessie mi vantava i bei paesaggi, i fiori graziosi dipinti da loro; poi sapevan cantare romanze, recitare e tradurre libri francesi. Ascoltando Bessie, il mio spirito era stato colpito, e sentivo destarsi in me l'emulazione.\"}},\n",
       " {'id': '308',\n",
       "  'translation': {'en': 'Besides, school would be a complete change: it implied a long journey, an entire separation from Gateshead, an entrance into a new life.',\n",
       "   'it': 'Del resto la pensione condurrebbe seco un cambiamento di vita, riempirebbe una lunga giornata, mi allontanerebbe dagli abitanti della villa, sarebbe infine il principio di una nuova esistenza.'}},\n",
       " {'id': '309',\n",
       "  'translation': {'en': '\"I should indeed like to go to school,\" was the audible conclusion of my musings.',\n",
       "   'it': '— Come sarei contenta di andare in pensione! — risposi senza più esitare.'}},\n",
       " {'id': '310',\n",
       "  'translation': {'en': '\"Well, well! who knows what may happen?\" said Mr. Lloyd, as he got up.',\n",
       "   'it': '— Ebbene, chi sa che cosa può accadere! — mi disse il signor Lloyd alzandosi.'}},\n",
       " {'id': '311',\n",
       "  'translation': {'en': '\"The child ought to have change of air and scene,\" he added, speaking to himself; \"nerves not in a good state.\"',\n",
       "   'it': \"— Per questa bimba ci vorrebbe un cambiamento d'aria e di luogo — aggiunse come se parlasse a sè stesso. I suoi nervi non sono in buono stato.\"}},\n",
       " {'id': '312',\n",
       "  'translation': {'en': 'Bessie now returned; at the same moment the carriage was heard rolling up the gravel-walk.',\n",
       "   'it': 'In quel momento entrò Bessie e si senti il rumore della carrozza della signora Reed nel cortile.'}},\n",
       " {'id': '313',\n",
       "  'translation': {'en': '\"Is that your mistress, nurse?\" asked Mr. Lloyd.',\n",
       "   'it': '— È la vostra padrona, Bessie? — domandò il signor Lloyd.'}},\n",
       " {'id': '314',\n",
       "  'translation': {'en': '\"I should like to speak to her before I go.\"',\n",
       "   'it': '— Vorrei parlarle avanti di andarmene.'}},\n",
       " {'id': '315',\n",
       "  'translation': {'en': 'Bessie invited him to walk into the breakfast-room, and led the way out.',\n",
       "   'it': 'Bessie lo invitò ad entrare nella stanza da pranzo, e camminò davanti a lui per insegnargli la via.'}},\n",
       " {'id': '316',\n",
       "  'translation': {'en': 'In the interview which followed between him and Mrs. Reed, I presume, from after-occurrences, that the apothecary ventured to recommend my being sent to school; and the recommendation was no doubt readily enough adopted; for as Abbot said, in discussing the subject with Bessie when both sat sewing in the nursery one night, after I was in bed, and, as they thought, asleep, \"Missis was, she dared say, glad enough to get rid of such a tiresome, ill-conditioned child, who always looked as if she were watching everybody, and scheming plots underhand.\"',\n",
       "   'it': \"Nel colloquio fra il farmacista e la signora Reed, suppongo che egli la spingesse a mettermi in pensione. Questo consiglio fu certo accettato subito, perché la sera stessa Abbot e Bessie vennero nella camera dei bambini, e credendomi addormentata, si misero a parlare su quell'argomento. — La signora, — diceva Abbot, — è molto contenta di sbarazzarsi di quella noiosa bambina, che pare sorvegli sempre tutti e mediti qualche complotto.\"}},\n",
       " {'id': '317',\n",
       "  'translation': {'en': 'Abbot, I think, gave me credit for being a sort of infantine Guy Fawkes.',\n",
       "   'it': \"Suppongo che Abbot mi credesse un'altra Guy Jaukes bambina.\"}},\n",
       " {'id': '318',\n",
       "  'translation': {'en': \"On that same occasion I learned, for the first time, from Miss Abbot's communications to Bessie, that my father had been a poor clergyman; that my mother had married him against the wishes of her friends, who considered the match beneath her; that my grandfather Reed was so irritated at her disobedience, he cut her off without a shilling; that after my mother and father had been married a year, the latter caught the typhus fever while visiting among the poor of a large manufacturing town where his curacy was situated, and where that disease was then prevalent: that my mother took the infection from him, and both died within a month of each other.\",\n",
       "   'it': 'Allora seppi per la prima volta, dai discorsi che Abbot fece a Bessie, che mio padre era un povero pastore, che mia madre lo aveva sposato contro il volere dei suoi, che consideravano quel matrimonio inferiore alla sua condizione. Il nonno Reed, irritato da quella disubbidienza, aveva diseredato la mamma.'}},\n",
       " {'id': '319',\n",
       "  'translation': {'en': 'Bessie, when she heard this narrative, sighed and said, \"Poor Miss Jane is to be pitied, too, Abbot.\"',\n",
       "   'it': 'Bessie, dopo avere ascoltato questo, sospirò dicendo: — Povera signorina Jane; merita davvero compassione!'}},\n",
       " {'id': '320',\n",
       "  'translation': {'en': '\"Yes,\" responded Abbot; \"if she were a nice, pretty child, one might compassionate her forlornness; but one really cannot care for such a little toad as that.\"',\n",
       "   'it': '— Sì, — rispose Abbot, — se fosse una bella creatura si potrebbe aver pietà del suo abbandono, ma chi può guardare un rospetto simile?'}},\n",
       " {'id': '321',\n",
       "  'translation': {'en': '\"Not a great deal, to be sure,\" agreed Bessie: \"at any rate, a beauty like Miss Georgiana would be more moving in the same condition.\" \"Yes, I doat on Miss Georgiana!\" cried the fervent Abbot.',\n",
       "   'it': \"— È vero, — rispose Bessie esitando, — è certo che una bellezza come la signorina Georgiana vi commoverebbe più, se fosse nella stessa posizione. — Sì, — esclamò l'ardente Abbot, — tengo per la signorina Georgiana!\"}},\n",
       " {'id': '322',\n",
       "  'translation': {'en': '\"Little darling!--with her long curls and her blue eyes, and such a sweet colour as she has; just as if she were painted!--Bessie, I could fancy a Welsh rabbit for supper.\"',\n",
       "   'it': \"Cara piccina, con i suoi lunghi riccioli, con quegli occhi azzurri e quella dolce carnagione; pare dipinta; Bessie, avrei voglia di un po' di coniglio per cena.\"}},\n",
       " {'id': '323',\n",
       "  'translation': {'en': '\"So could I--with a roast onion.',\n",
       "   'it': \"— Anch'io, con le cipolle arrostite.\"}},\n",
       " {'id': '324',\n",
       "  'translation': {'en': 'Come, we\\'ll go down.\"',\n",
       "   'it': 'Venite, andiamo giù.'}},\n",
       " {'id': '325', 'translation': {'en': 'They went.', 'it': '— E uscirono.'}},\n",
       " {'id': '326', 'translation': {'en': 'CHAPTER IV', 'it': 'IV.'}},\n",
       " {'id': '327',\n",
       "  'translation': {'en': 'From my discourse with Mr. Lloyd, and from the above reported conference between Bessie and Abbot, I gathered enough of hope to suffice as a motive for wishing to get well: a change seemed near,--I desired and waited it in silence.',\n",
       "   'it': 'Dopo il mio colloquio col signor Lloyd e i discorsi che avevano scambiati Bessie e Abbot, nutrivo speranza che un cambiamento si operasse nella mia situazione, ed ero impaziente di star meglio. Desideravo e speravo in silenzio.'}},\n",
       " {'id': '328',\n",
       "  'translation': {'en': 'It tarried, however: days and weeks passed: I had regained my normal state of health, but no new allusion was made to the subject over which I brooded.',\n",
       "   'it': 'Ma intanto i giorni e le settimane passavano senza che avvenisse nulla di nuovo. Avevo ricuperato la salute, ma non si parlava punto della cosa che stavami tanto a cuore.'}},\n",
       " {'id': '329',\n",
       "  'translation': {'en': 'Mrs. Reed surveyed me at times with a severe eye, but seldom addressed me: since my illness, she had drawn a more marked line of separation than ever between me and her own children; appointing me a small closet to sleep in by myself, condemning me to take my meals alone, and pass all my time in the nursery, while my cousins were constantly in the drawing-room.',\n",
       "   'it': 'Dopo la mia malattia era stata tirata una linea più profonda di demarcazione fra me e i suoi figli. Mi era stato assegnato uno stanzino per dormirvi sola, ero stata condannata a non mangiare più alla tavola di famiglia ed a rimanere nella camera dei bambini, mentre i miei cugini stavano in salotto.'}},\n",
       " {'id': '330',\n",
       "  'translation': {'en': 'Not a hint, however, did she drop about sending me to school: still I felt an instinctive certainty that she would not long endure me under the same roof with her; for her glance, now more than ever, when turned on me, expressed an insuperable and rooted aversion.',\n",
       "   'it': 'Mia zia non parlava mai di mandarmi in pensione, ma io sentivo istintivamente che ella non mi avrebbe tollerata a lungo sotto il suo tetto, perché lo sguardo, che ogni tanto fissava su me, rivelava una avversione insormontabile.'}},\n",
       " {'id': '331',\n",
       "  'translation': {'en': 'Eliza and Georgiana, evidently acting according to orders, spoke to me as little as possible: John thrust his tongue in his cheek whenever he saw me, and once attempted chastisement; but as I instantly turned against him, roused by the same sentiment of deep ire and desperate revolt which had stirred my corruption before, he thought it better to desist, and ran from me tittering execrations, and vowing I had burst his nose.',\n",
       "   'it': \"Eliza e Georgiana ubbidivano evidentemente agli ordini che erano stati dati loro, e mi parlavano il meno possibile; John mi faceva le boccaccie ogni volta che m'incontrava. Un giorno tentò di percuotermi, ma vedendo che io mi volgeva contro di lui animata dallo stesso sentimento d'ira profonda e di disperata ribellione, che una volta si era impossessata di me, rinunziò al tentativo e corse via, lanciandomi improperi e urlando che gli avevo rotto il naso.\"}},\n",
       " {'id': '332',\n",
       "  'translation': {'en': 'I had indeed levelled at that prominent feature as hard a blow as my knuckles could inflict; and when I saw that either that or my look daunted him, I had the greatest inclination to follow up my advantage to purpose; but he was already with his mama. I heard him in a blubbering tone commence the tale of how \"that nasty Jane Eyre\" had flown at him like a mad cat: he was stopped rather harshly--',\n",
       "   'it': 'È vero che avevo percosso con tutta la forza del pugno quella parte sporgente del volto di lui, e quando mi accorsi che la percossa e la potenza del mio sguardo lo avevano domato, volli trarre da quel trionfo tutti i vantaggi possibili, ma egli aveva già raggiunto sua madre e sentii che le raccontava, con voce piagnucolosa, che quella cattiva Jane lo aveva assalito come un gatto infuriato. Sua madre lo interruppe bruscamente.'}},\n",
       " {'id': '333',\n",
       "  'translation': {'en': '\"Don\\'t talk to me about her, John: I told you not to go near her; she is not worthy of notice; I do not choose that either you or your sisters should associate with her.\"',\n",
       "   'it': \"— Non mi parlate più di quella bambina, John, — diss'ella, — non merita che si badi a quello che fa; non voglio che voi né le vostre sorelle vi associate con lei per giuocare.\"}},\n",
       " {'id': '334',\n",
       "  'translation': {'en': 'Here, leaning over the banister, I cried out suddenly, and without at all deliberating on my words--',\n",
       "   'it': 'Sporgendomi allora dalla balaustra della scala, mi misi a gridare, senza riflettere alle mie parole:'}},\n",
       " {'id': '335',\n",
       "  'translation': {'en': '\"They are not fit to associate with me.\"',\n",
       "   'it': '— Vuoi dire che non sono degni di giuocare con me.'}},\n",
       " {'id': '336',\n",
       "  'translation': {'en': 'Mrs. Reed was rather a stout woman; but, on hearing this strange and audacious declaration, she ran nimbly up the stair, swept me like a whirlwind into the nursery, and crushing me down on the edge of my crib, dared me in an emphatic voice to rise from that place, or utter one syllable during the remainder of the day.',\n",
       "   'it': \"La signora Reed era una donna forte e robusta, e nel sentire quella strana e audace dichiarazione, salì di corsa le scale, e, più pronta del turbine, mi trascinò nella camera dei bambini, e spingendomi contro il mio letto, m'ingiunse, in tono enfatico, di non muovermi di lì e di non pronunziar parola in tutto il giorno.\"}},\n",
       " {'id': '337',\n",
       "  'translation': {'en': '\"What would Uncle Reed say to you, if he were alive?\" was my scarcely voluntary demand.',\n",
       "   'it': '— Che cosa vi direbbe lo zio Reed, se fosse vivo? — le domandai quasi involontariamente, perché la lingua pronunziò queste parole senza il consenso della mente.'}},\n",
       " {'id': '338',\n",
       "  'translation': {'en': 'I say scarcely voluntary, for it seemed as if my tongue pronounced words without my will consenting to their utterance: something spoke out of me over which I had no control.',\n",
       "   'it': 'Vi era in me una forza che mi spingeva a parlare, nonostante la volontà di tacere.'}},\n",
       " {'id': '339',\n",
       "  'translation': {'en': '\"What?\" said Mrs. Reed under her breath: her usually cold composed grey eye became troubled with a look like fear; she took her hand from my arm, and gazed at me as if she really did not know whether I were child or fiend.',\n",
       "   'it': '— Come! — esclamò la signora Reed, respirando appena. Gli occhi di lei, grigi e per consueto freddi e immobili, furono turbati da una espressione di terrore e lasciò di stringermi, incerta se fossi una bimba o un essere infernale.'}},\n",
       " {'id': '340',\n",
       "  'translation': {'en': 'I was now in for it.',\n",
       "   'it': 'Tale ero infatti in quel momento.'}},\n",
       " {'id': '341',\n",
       "  'translation': {'en': '\"My Uncle Reed is in heaven, and can see all you do and think; and so can papa and mama: they know how you shut me up all day long, and how you wish me dead.\"',\n",
       "   'it': '— Mio zio Reed è in cielo, — continuai, — e può vedere ciò che fate e pensate, e così pure il babbo e la mamma; essi sanno che mi rinchiudete per giornate intere e che vorreste vedermi morta.'}},\n",
       " {'id': '342',\n",
       "  'translation': {'en': 'Mrs. Reed soon rallied her spirits: she shook me most soundly, she boxed both my ears, and then left me without a word.',\n",
       "   'it': 'La signora Reed si rimise subito, mi scosse violentemente, mi dette due schiaffi e poi si allontanò da me senza aprir bocca.'}},\n",
       " {'id': '343',\n",
       "  'translation': {'en': \"Bessie supplied the hiatus by a homily of an hour's length, in which she proved beyond a doubt that I was the most wicked and abandoned child ever reared under a roof.\",\n",
       "   'it': \"Bessie supplì a quel silenzio facendomi una predica che durò un'ora, provandomi che ero la bimba più cattiva e più abbandonata che vi fosse al mondo.\"}},\n",
       " {'id': '344',\n",
       "  'translation': {'en': 'I half believed her; for I felt indeed only bad feelings surging in my breast.',\n",
       "   'it': 'Ero propensa a crederle, perché non sentivo sorgere dal cuore altro che cattive ispirazioni.'}},\n",
       " {'id': '345',\n",
       "  'translation': {'en': 'November, December, and half of January passed away.',\n",
       "   'it': 'Trascorsero novembre, dicembre e la metà di gennaio.'}},\n",
       " {'id': '346',\n",
       "  'translation': {'en': 'Christmas and the New Year had been celebrated at Gateshead with the usual festive cheer; presents had been interchanged, dinners and evening parties given.',\n",
       "   'it': 'Il Natale era stato celebrato a Gateshead con la consueta solennità, i doni erano stati scambiati e offerti pranzi e ricevimenti.'}},\n",
       " {'id': '347',\n",
       "  'translation': {'en': 'From every enjoyment I was, of course, excluded: my share of the gaiety consisted in witnessing the daily apparelling of Eliza and Georgiana, and seeing them descend to the drawing-room, dressed out in thin muslin frocks and scarlet sashes, with hair elaborately ringletted; and afterwards, in listening to the sound of the piano or the harp played below, to the passing to and fro of the butler and footman, to the jingling of glass and china as refreshments were handed, to the broken hum of conversation as the drawing-room door opened and closed.',\n",
       "   'it': \"Tutta la mia parte di gioia consisteva nell'assistere ogni giorno alla toilette d'Eliza e di Georgiana, nel vederle scendere in sala con i loro vestiti leggieri di mussolina, le loro cinture rosa, i loro capelli arricciati con cura. Poi spiavo il suono del pianoforte e dell'arpa, il passaggio del cameriere e del servitore che portavano i rinfreschi, il rumore dei bicchieri e delle porcellane, i brani di conversazione che uscivano dal salotto, allorquando si apriva e si chiudeva la porta.\"}},\n",
       " {'id': '348',\n",
       "  'translation': {'en': 'When tired of this occupation, I would retire from the stairhead to the solitary and silent nursery: there, though somewhat sad, I was not miserable. To speak truth, I had not the least wish to go into company, for in company I was very rarely noticed; and if Bessie had but been kind and companionable, I should have deemed it a treat to spend the evenings quietly with her, instead of passing them under the formidable eye of Mrs. Reed, in a room full of ladies and gentlemen.',\n",
       "   'it': \"Quando ero stanca di quella osservazione, lasciavo la scala per tornare nella camera solitaria dei bambini: benché quella stanza fosse un po' triste, non mi sentivo in essa infelice e non avevo alcun desiderio di scendere in salotto, ove raramente qualcuno avrebbemi rivolta la parola. Se Bessie fosse stata buona con me, avrei preferito di passar tranquillamente le serate accanto a lei, piuttosto che sotto lo sguardo severo della signora Reed, in una stanza piena di gente elegante.\"}},\n",
       " {'id': '349',\n",
       "  'translation': {'en': \"But Bessie, as soon as she had dressed her young ladies, used to take herself off to the lively regions of the kitchen and housekeeper's room, generally bearing the candle along with her.\",\n",
       "   'it': 'Ma appena Bessie aveva vestite le padroncine, soleva scendere nelle rumorose regioni della cucina e della dispensa e portava seco il lume.'}},\n",
       " {'id': '350',\n",
       "  'translation': {'en': 'I then sat with my doll on my knee till the fire got low, glancing round occasionally to make sure that nothing worse than myself haunted the shadowy room; and when the embers sank to a dull red, I undressed hastily, tugging at knots and strings as I best might, and sought shelter from cold and darkness in my crib.',\n",
       "   'it': \"E allora mi sedevo con la bambola sulle ginocchia accanto al fuoco, finché non si spengeva, gettando di tanto in tanto uno sguardo intorno a me per assicurarmi che nessun fantasma era entrato nella stanza quasi buia. Quando la brace incominciava a impallidire, mi spogliava in fretta, tirando i nastri o i cordoni come sapevo, e andavo a cercare nel mio lettino un riparo contro il freddo e l'oscurità.\"}},\n",
       " {'id': '351',\n",
       "  'translation': {'en': 'To this crib I always took my doll; human beings must love something, and, in the dearth of worthier objects of affection, I contrived to find a pleasure in loving and cherishing a faded graven image, shabby as a miniature scarecrow.',\n",
       "   'it': 'Nel letto io portavo la bambola, e la rinvolgeva con cura nella mia camicia da notte, e dopo averle fatte mille carezze, mi addormentavo relativamente contenta di poter amare e riscaldare quella puppatola sbiadita e cenciosa, che allora mi pareva viva e capace di sentire.'}},\n",
       " {'id': '352',\n",
       "  'translation': {'en': 'Long did the hours seem while I waited the departure of the company, and listened for the sound of Bessie\\'s step on the stairs: sometimes she would come up in the interval to seek her thimble or her scissors, or perhaps to bring me something by way of supper--a bun or a cheese-cake--then she would sit on the bed while I ate it, and when I had finished, she would tuck the clothes round me, and twice she kissed me, and said, \"Good night, Miss Jane.\"',\n",
       "   'it': 'Ella veniva talvolta a prendere il ditale e le forbici e a portarmi per cena qualche pezzo di pasticcio. Allora, mentre che io mangiavo, si sedeva accanto al letto, e quando avevo terminato mi copriva e dicevami, baciandomi due volte: \"Buona notte, signorina Jane.\"'}},\n",
       " {'id': '353',\n",
       "  'translation': {'en': 'When thus gentle, Bessie seemed to me the best, prettiest, kindest being in the world; and I wished most intensely that she would always be so pleasant and amiable, and never push me about, or scold, or task me unreasonably, as she was too often wont to do.',\n",
       "   'it': \"In quei momenti Bessie mi pareva la più bella, più dolce e la più buona creatura che fosse sulla terra, e desideravo di vederla sempre così e che non mi sgridasse più e cercasse d'impormi doveri irragionevoli, come faceva spesso.\"}},\n",
       " {'id': '354',\n",
       "  'translation': {'en': 'Bessie Lee must, I think, have been a girl of good natural capacity, for she was smart in all she did, and had a remarkable knack of narrative; so, at least, I judge from the impression made on me by her nursery tales.',\n",
       "   'it': 'Bessie Lee doveva essere una ragazza intelligente, perché le riusciva tutto quello che si metteva a fare e narrava benissimo; almeno i racconti suoi mi sono rimasti impressi nella mente.'}},\n",
       " {'id': '355',\n",
       "  'translation': {'en': 'She was pretty too, if my recollections of her face and person are correct.',\n",
       "   'it': 'Se rammento bene, doveva essere anche bellina.'}},\n",
       " {'id': '356',\n",
       "  'translation': {'en': 'I remember her as a slim young woman, with black hair, dark eyes, very nice features, and good, clear complexion; but she had a capricious and hasty temper, and indifferent ideas of principle or justice: still, such as she was, I preferred her to any one else at Gateshead Hall.',\n",
       "   'it': \"Era alta, con i capelli neri e gli occhi scuri, i tratti delicati e la carnagione bianca; ma aveva un carattere vivo e capriccioso e indifferente rispetto ai grandi principii di giustizia. Pure, così com'era, la preferivo a tutti, a Gateshead.\"}},\n",
       " {'id': '357',\n",
       "  'translation': {'en': \"It was the fifteenth of January, about nine o'clock in the morning: Bessie was gone down to breakfast; my cousins had not yet been summoned to their mama; Eliza was putting on her bonnet and warm garden-coat to go and feed her poultry, an occupation of which she was fond: and not less so of selling the eggs to the housekeeper and hoarding up the money she thus obtained.\",\n",
       "   'it': 'Bessie era scesa a colazione; le mie cugine non erano state ancora chiamate dalla loro mamma, Eliza si metteva il cappello e un mantello pesante per andar nel suo pollaio. Era quella la sua occupazione preferita, perché dal pollaio ricavava denari, vendendo le uova alla donna che dirigeva la casa.'}},\n",
       " {'id': '358',\n",
       "  'translation': {'en': 'She had a turn for traffic, and a marked propensity for saving; shown not only in the vending of eggs and chickens, but also in driving hard bargains with the gardener about flower-roots, seeds, and slips of plants; that functionary having orders from Mrs. Reed to buy of his young lady all the products of her parterre she wished to sell: and Eliza would have sold the hair off her head if she could have made a handsome profit thereby.',\n",
       "   'it': \"Ella aveva molta disposizione per il commercio e una singolare tendenza al risparmio, perchè, non contenta di trafficare sulle uova e sui polli, cercava di far denaro anche con la vendita dei fiori e dei semi. Il giardiniere aveva ordine di comprare dalla bambina tutti i prodotti del suo giardino ch'ella volesse vendere, ed Eliza avrebbe venduto anche i capelli del capo, se le avessero dato un utile.\"}},\n",
       " {'id': '359',\n",
       "  'translation': {'en': 'As to her money, she first secreted it in odd corners, wrapped in a rag or an old curl-paper; but some of these hoards having been discovered by the housemaid, Eliza, fearful of one day losing her valued treasure, consented to intrust it to her mother, at a usurious rate of interest--fifty or sixty per cent.; which interest she exacted every quarter, keeping her accounts in a little book with anxious accuracy.',\n",
       "   'it': \"Il danaro soleva da prima rimpiattarlo, dopo averlo ravvolto nella carta; ma essendo stati scoperti alcuni dei suoi nascondigli dalla cameriera, temè di perderlo, un giorno o l'altro, e lo affidò a sua madre, esigendo un interesse del 50 e anche del 60 per cento. Quest'interesse esorbitante lo ritirava ogni trimestre, e piena di ansiosa sollecitudine notava in un taccuino il conto dei suoi incassi.\"}},\n",
       " {'id': '360',\n",
       "  'translation': {'en': 'Georgiana sat on a high stool, dressing her hair at the glass, and interweaving her curls with artificial flowers and faded feathers, of which she had found a store in a drawer in the attic.',\n",
       "   'it': 'Georgiana era seduta su una sedia alta davanti allo specchio e intrecciava fiori artificiali e penne sbiadite, trovate in soffitta, ai suoi capelli.'}},\n",
       " {'id': '361',\n",
       "  'translation': {'en': 'I was making my bed, having received strict orders from Bessie to get it arranged before she returned (for Bessie now frequently employed me as a sort of under- nurserymaid, to tidy the room, dust the chairs, &c.).',\n",
       "   'it': \"Io intanto rifacevo il letto, avendo avuto ordine espresso da Bessie di sbrigarmi prima che tornasse, perché Bessie m'impiegava spesso a pulir la camera come se fossi stata una donna di faccende.\"}},\n",
       " {'id': '362',\n",
       "  'translation': {'en': \"Having spread the quilt and folded my night-dress, I went to the window-seat to put in order some picture-books and doll's house furniture scattered there; an abrupt command from Georgiana to let her playthings alone (for the tiny chairs and mirrors, the fairy plates and cups, were her property) stopped my proceedings; and then, for lack of other occupation, I fell to breathing on the frost-flowers with which the window was fretted, and thus clearing a space in the glass through which I might look out on the grounds, where all was still and petrified under the influence of a hard frost.\",\n",
       "   'it': 'Volli metterli in ordine, ma Georgiana mi ordinò duramente di non toccar la roba sua. Essendo disoccupata, accostai le labbra ai fiori di ghiaccio che appannavano i cristalli e presto riuscii a guardare fuori della finestra.'}},\n",
       " {'id': '363',\n",
       "  'translation': {'en': \"From this window were visible the porter's lodge and the carriage-road, and just as I had dissolved so much of the silver-white foliage veiling the panes as left room to look out, I saw the gates thrown open and a carriage roll through.\",\n",
       "   'it': 'Da quella finestra si vedeva la casetta del portinaio e il viale dal quale entravano le carrozze. Il mio respiro caldo aveva, come ho detto, sbarazzato il cristallo dallo strato di ghiaccio, e così potevo veder fuori.'}},\n",
       " {'id': '364',\n",
       "  'translation': {'en': 'I watched it ascending the drive with indifference; carriages often came to Gateshead, but none ever brought visitors in whom I was interested; it stopped in front of the house, the door-bell rang loudly, the new-comer was admitted.',\n",
       "   'it': 'Molte carrozze venivano a Gateshead, ma i visitatori che conducevano mi erano sempre indifferenti. La carrozza si fermò davanti alla casa, si udì una scampanellata e il visitatore entrò.'}},\n",
       " {'id': '365',\n",
       "  'translation': {'en': 'All this being nothing to me, my vacant attention soon found livelier attraction in the spectacle of a little hungry robin, which came and chirruped on the twigs of the leafless cherry-tree nailed against the wall near the casement.',\n",
       "   'it': \"Siccome non m'importava di quel fatto, concentrai tutta la mia attenzione su un pettirosso, che cantava sui rami nudi di un ciliegio, che cresceva sotto la finestra.\"}},\n",
       " {'id': '366',\n",
       "  'translation': {'en': 'The remains of my breakfast of bread and milk stood on the table, and having crumbled a morsel of roll, I was tugging at the sash to put out the crumbs on the window-sill, when Bessie came running upstairs into the nursery.',\n",
       "   'it': \"Avevo ancora un po' di pane della colazione e aprii la finestra per isminuzzarlo sul parapetto. In quel momento Bessie salì precipitosamente le scale ed entrò in camera dicendo:\"}},\n",
       " {'id': '367',\n",
       "  'translation': {'en': '\"Miss Jane, take off your pinafore; what are you doing there?',\n",
       "   'it': '— Signorina Jane, si levi il grembiule.'}},\n",
       " {'id': '368',\n",
       "  'translation': {'en': 'Have you washed your hands and face this morning?\"',\n",
       "   'it': \"Che cosa fa? S'è lavate le mani e il viso?\"}},\n",
       " {'id': '369',\n",
       "  'translation': {'en': 'I gave another tug before I answered, for I wanted the bird to be secure of its bread: the sash yielded; I scattered the crumbs, some on the stone sill, some on the cherry-tree bough, then, closing the window, I replied--',\n",
       "   'it': 'Avanti di rispondere, terminai di spargere il pane fuori della finestra, poi, richiudendola, risposi tranquillamente:'}},\n",
       " {'id': '370',\n",
       "  'translation': {'en': '\"No, Bessie; I have only just finished dusting.\"',\n",
       "   'it': '— No, Bessie, ho terminato di spolverare.'}},\n",
       " {'id': '371',\n",
       "  'translation': {'en': '\"Troublesome, careless child! and what are you doing now?',\n",
       "   'it': '— Che bimba sciolta e disordinata! Che cosa facevate?'}},\n",
       " {'id': '372',\n",
       "  'translation': {'en': 'You look quite red, as if you had been about some mischief: what were you opening the window for?\"',\n",
       "   'it': 'Siete rossa come una colpevole. Perché avete aperto la finestra?'}},\n",
       " {'id': '373',\n",
       "  'translation': {'en': 'I was spared the trouble of answering, for Bessie seemed in too great a hurry to listen to explanations; she hauled me to the washstand, inflicted a merciless, but happily brief scrub on my face and hands with soap, water, and a coarse towel; disciplined my head with a bristly brush, denuded me of my pinafore, and then hurrying me to the top of the stairs, bid me go down directly, as I was wanted in the breakfast-room.',\n",
       "   'it': \"Mi condusse al lavabo e con l'acqua e il sapone mi lavò ben bene le mani e il viso. Per fortuna fece presto, poi mi pettinò, mi tolse il grembiule e, spingendomi verso la scala, mi ordinò di scender presto nella sala da pranzo, dove ero attesa.\"}},\n",
       " {'id': '374',\n",
       "  'translation': {'en': 'I would have asked who wanted me: I would have demanded if Mrs. Reed was there; but Bessie was already gone, and had closed the nursery-door upon me.',\n",
       "   'it': 'Stavo per domandare se la zia era giù, ma Bessie era sparita, chiudendo dietro a sé la porta della camera.'}},\n",
       " {'id': '375',\n",
       "  'translation': {'en': 'I slowly descended.', 'it': 'Scesi lentamente.'}},\n",
       " {'id': '376',\n",
       "  'translation': {'en': \"For nearly three months, I had never been called to Mrs. Reed's presence; restricted so long to the nursery, the breakfast, dining, and drawing-rooms were become for me awful regions, on which it dismayed me to intrude.\",\n",
       "   'it': 'Da tre mesi non ero stata chiamata dalla signora Reed. Rinchiusa da tanto tempo nella camera del primo piano, il pianterreno era diventato ai miei occhi una regione imponente, nella quale entravo a malincuore.'}},\n",
       " {'id': '377',\n",
       "  'translation': {'en': 'I now stood in the empty hall; before me was the breakfast-room door, and I stopped, intimidated and trembling.',\n",
       "   'it': \"Giunsi nell'anticamera, davanti alla porta della sala da pranzo; là mi fermai timidamente.\"}},\n",
       " {'id': '378',\n",
       "  'translation': {'en': 'What a miserable little poltroon had fear, engendered of unjust punishment, made of me in those days!',\n",
       "   'it': 'Le ingiuste punizioni mi avevano resa vile.'}},\n",
       " {'id': '379',\n",
       "  'translation': {'en': 'I feared to return to the nursery, and feared to go forward to the parlour; ten minutes I stood in agitated hesitation; the vehement ringing of the breakfast-room bell decided me; I _must_ enter.',\n",
       "   'it': \"Non osavo tornare su in camera, non osavo entrare nel salotto; rimasi dieci minuti esitando, in preda all'agitazione. Una forte scampanellata mi rese coraggio: dovevo entrare.\"}},\n",
       " {'id': '380',\n",
       "  'translation': {'en': '\"Who could want me?\" I asked inwardly, as with both hands I turned the stiff door-handle, which, for a second or two, resisted my efforts.',\n",
       "   'it': '— Chi può aspettarmi? — dicevo fra me, mentre con tutte e due le mani giravo la maniglia, che resisteva ai miei sforzi.'}},\n",
       " {'id': '381',\n",
       "  'translation': {'en': '\"What should I see besides Aunt Reed in the apartment?--a man or a woman?\"',\n",
       "   'it': '— Chi troverò insieme con la zia?'}},\n",
       " {'id': '382',\n",
       "  'translation': {'en': 'The handle turned, the door unclosed, and passing through and curtseying low, I looked up at--a black pillar!--such, at least, appeared to me, at first sight, the straight, narrow, sable-clad shape standing erect on the rug: the grim face at the top was like a carved mask, placed above the shaft by way of capital.',\n",
       "   'it': \"La maniglia cedè; la porta si aprì; io m'inoltrai salutando profondamente e guardando intorno. I miei occhi si fermarono su qualcosa di lungo e di scuro, come una colonna nera.\"}},\n",
       " {'id': '383',\n",
       "  'translation': {'en': 'Mrs. Reed occupied her usual seat by the fireside; she made a signal to me to approach; I did so, and she introduced me to the stony stranger with the words: \"This is the little girl respecting whom I applied to you.\"',\n",
       "   'it': 'Ubbidii. E, guardando il visitatore immobile, mi presentò a lui, dicendo: — Ecco la bambina di cui vi ho parlato.'}},\n",
       " {'id': '384',\n",
       "  'translation': {'en': '_He_, for it was a man, turned his head slowly towards where I stood, and having examined me with the two inquisitive-looking grey eyes which twinkled under a pair of bushy brows, said solemnly, and in a bass voice, \"Her size is small: what is her age?\"',\n",
       "   'it': 'Egli volse lentamente la testa dal mio lato, e dopo avermi esaminato con uno sguardo inquisitore a traverso i cigli neri e folti, mi domandò in tono solenne e a voce bassissima quanti anni avevo.'}},\n",
       " {'id': '385',\n",
       "  'translation': {'en': '\"Ten years.\"', 'it': '— Dieci, — rispose la zia.'}},\n",
       " {'id': '386',\n",
       "  'translation': {'en': '\"So much?\" was the doubtful answer; and he prolonged his scrutiny for some minutes. Presently he addressed me--\"Your name, little girl?\"',\n",
       "   'it': '— Non pare che ne abbia tanti, — osservò in tono di dubbio, e prolungò per alcuni minuti il mio esame; poi, dirigendosi a me, disse: — Come vi chiamate, piccina?'}},\n",
       " {'id': '387',\n",
       "  'translation': {'en': '\"Jane Eyre, sir.\"', 'it': '— Jane Eyre, signore.'}},\n",
       " {'id': '388',\n",
       "  'translation': {'en': 'In uttering these words I looked up: he seemed to me a tall gentleman; but then I was very little; his features were large, and they and all the lines of his frame were equally harsh and prim.',\n",
       "   'it': \"Mi parve alto, ma mi ricordo che io allora ero molto piccola. I tratti di lui mi parvero molto marcati, e vi scorsi, come nelle linee di tutta la persona, una espressione di durezza e d'ipocrisia.\"}},\n",
       " {'id': '389',\n",
       "  'translation': {'en': '\"Well, Jane Eyre, and are you a good child?\"',\n",
       "   'it': '— Ebbene, Jane Eyre, siete una buona bambina?'}},\n",
       " {'id': '390',\n",
       "  'translation': {'en': 'Impossible to reply to this in the affirmative: my little world held a contrary opinion: I was silent.',\n",
       "   'it': \"Era impossibile rispondere affermativamente. Quelli che mi circondavano credevano l'opposto; così tacqui.\"}},\n",
       " {'id': '391',\n",
       "  'translation': {'en': 'Mrs. Reed answered for me by an expressive shake of the head, adding soon, \"Perhaps the less said on that subject the better, Mr. Brocklehurst.\"',\n",
       "   'it': 'La signora Reed parlò per me, e scuotendo la testa rispose rapidamente: — Meno parleremo di ciò e meglio faremo, signor Bockelhurst.'}},\n",
       " {'id': '392',\n",
       "  'translation': {'en': '\"Sorry indeed to hear it! she and I must have some talk;\" and bending from the perpendicular, he installed his person in the arm-chair opposite Mrs. Reed\\'s.',\n",
       "   'it': '— Sono dolente davvero; bisogna che parli un poco con lei. E rinunciando alla posizione perpendicolare, si sedè in una poltrona di fronte alla signora Reed, dicendomi di avvicinarmi.'}},\n",
       " {'id': '393',\n",
       "  'translation': {'en': 'I stepped across the rug; he placed me square and straight before him.',\n",
       "   'it': 'Poi battè leggermente il piede e mi ordinò di mettermi dinanzi a lui.'}},\n",
       " {'id': '394',\n",
       "  'translation': {'en': 'What a face he had, now that it was almost on a level with mine! what a great nose! and what a mouth! and what large prominent teeth!',\n",
       "   'it': 'Il suo volto mi produsse uno strano effetto, quando vidi il naso enorme e grossissimi denti.'}},\n",
       " {'id': '395',\n",
       "  'translation': {'en': '\"No sight so sad as that of a naughty child,\" he began, \"especially a naughty little girl.',\n",
       "   'it': '— Non vi è nulla di più triste che lo spettacolo che offre una bimba cattiva, — riprese egli.'}},\n",
       " {'id': '396',\n",
       "  'translation': {'en': 'Do you know where the wicked go after death?\"',\n",
       "   'it': '— Sapete dove vanno i peccatori dopo morti? La mia risposta fu rapida e ortodossa.'}},\n",
       " {'id': '397',\n",
       "  'translation': {'en': '\"They go to hell,\" was my ready and orthodox answer.',\n",
       "   'it': \"— All'inferno, — replicai.\"}},\n",
       " {'id': '398',\n",
       "  'translation': {'en': '\"And what is hell?',\n",
       "   'it': \"— E che cos'è l'inferno?\"}},\n",
       " {'id': '399',\n",
       "  'translation': {'en': 'Can you tell me that?\"', 'it': 'Potete dirmelo?'}},\n",
       " {'id': '400',\n",
       "  'translation': {'en': '\"A pit full of fire.\"',\n",
       "   'it': '— È un abisso di fiamme.'}},\n",
       " {'id': '401',\n",
       "  'translation': {'en': '\"And should you like to fall into that pit, and to be burning there for ever?\"',\n",
       "   'it': \"— Vorreste esser precipitata in quell'abisso e bruciarvi in eterno?\"}},\n",
       " {'id': '402', 'translation': {'en': '\"No, sir.\"', 'it': '— No, signore.'}},\n",
       " {'id': '403',\n",
       "  'translation': {'en': '\"What must you do to avoid it?\"',\n",
       "   'it': '— E che cosa dovete far dunque per evitare quella sorte?'}},\n",
       " {'id': '404',\n",
       "  'translation': {'en': 'I deliberated a moment; my answer, when it did come, was objectionable: \"I must keep in good health, and not die.\"',\n",
       "   'it': 'Riflettei un momento, e questa volta gli fu facile attaccare la mia risposta.'}},\n",
       " {'id': '405',\n",
       "  'translation': {'en': '\"How can you keep in good health?',\n",
       "   'it': '— Devo star sana, per non morire. — Come farete?'}},\n",
       " {'id': '406',\n",
       "  'translation': {'en': 'Children younger than you die daily.',\n",
       "   'it': 'I bimbi piccini come voi muoiono giornalmente.'}},\n",
       " {'id': '407',\n",
       "  'translation': {'en': 'I buried a little child of five years old only a day or two since,--a good little child, whose soul is now in heaven. It is to be feared the same could not be said of you were you to be called hence.\"',\n",
       "   'it': \"Non è molto che ho sotterrato una bimba di cinque anni, ma era buona, e la sua anima è volata in cielo; non si potrebbe dire lo stesso di voi, se foste chiamata nell'altro mondo.\"}},\n",
       " {'id': '408',\n",
       "  'translation': {'en': 'Not being in a condition to remove his doubt, I only cast my eyes down on the two large feet planted on the rug, and sighed, wishing myself far enough away.',\n",
       "   'it': \"Non potendo far svanire quei dubbi, fissai gli occhi sui piedoni di quel signore, e sospirai desiderando che quell'interrogatorio terminasse presto.\"}},\n",
       " {'id': '409',\n",
       "  'translation': {'en': '\"I hope that sigh is from the heart, and that you repent of ever having been the occasion of discomfort to your excellent benefactress.\"',\n",
       "   'it': '— Spero che codesto sospiro parta dal cuore, — riprese il signor Bockelhurst, — e che siate pentita di aver attristato sempre la vostra benefattrice.'}},\n",
       " {'id': '410',\n",
       "  'translation': {'en': '\"Do you say your prayers night and morning?\" continued my interrogator.',\n",
       "   'it': 'Dite le preghiere, mattina e sera? — continuò il mio interrogatore.'}},\n",
       " {'id': '411',\n",
       "  'translation': {'en': '\"Do you read your Bible?\"',\n",
       "   'it': '— Leggete la Bibbia?'}},\n",
       " {'id': '412',\n",
       "  'translation': {'en': '\"Sometimes.\"', 'it': '— Qualche volta.'}},\n",
       " {'id': '413',\n",
       "  'translation': {'en': '\"With pleasure?', 'it': '— Con piacere?'}},\n",
       " {'id': '414',\n",
       "  'translation': {'en': 'Are you fond of it?\"',\n",
       "   'it': 'Vi diletta quella lettura?'}},\n",
       " {'id': '415',\n",
       "  'translation': {'en': '\"I like Revelations, and the book of Daniel, and Genesis and Samuel, and a little bit of Exodus, and some parts of Kings and Chronicles, and Job and Jonah.\"',\n",
       "   'it': \"— Mi piacciono le Rivelazioni, il Libro di Daniele, la Genesi e Samuele e qualche brano dell'Esodo, dei Re, delle Cronache, e mi piace anche Giobbe e Gionata.\"}},\n",
       " {'id': '416',\n",
       "  'translation': {'en': '\"And the Psalms?', 'it': '— E i Salmi?'}},\n",
       " {'id': '417',\n",
       "  'translation': {'en': 'I hope you like them?\"',\n",
       "   'it': 'Spero che vi piaceranno?'}},\n",
       " {'id': '418', 'translation': {'en': '\"No, sir.\"', 'it': '— No, signore.'}},\n",
       " {'id': '419',\n",
       "  'translation': {'en': '\"No? oh, shocking!', 'it': '— Oh che vergogna!'}},\n",
       " {'id': '420',\n",
       "  'translation': {'en': 'I have a little boy, younger than you, who knows six Psalms by heart: and when you ask him which he would rather have, a gingerbread-nut to eat or a verse of a Psalm to learn, he says: \\'Oh! the verse of a Psalm! angels sing Psalms;\\' says he, \\'I wish to be a little angel here below;\\' he then gets two nuts in recompense for his infant piety.\"',\n",
       "   'it': 'Ho un bambino più piccolo di voi, che sa già sei Salmi a mente, e quando gli si domanda se preferisce mangiare il pan pepato o imparare un versetto, risponde: \"Preferisco imparare un versetto, perché gli angioli cantano i Salmi e voglio essere un angioletto sulla terra,\" e allora gli si danno due pezzi di pan pepato in ricompensa della sua devozione infantile.'}},\n",
       " {'id': '421',\n",
       "  'translation': {'en': '\"Psalms are not interesting,\" I remarked.',\n",
       "   'it': '— I Salmi non sono punto interessanti, — osservai.'}},\n",
       " {'id': '422',\n",
       "  'translation': {'en': '\"That proves you have a wicked heart; and you must pray to God to change it: to give you a new and clean one: to take away your heart of stone and give you a heart of flesh.\"',\n",
       "   'it': '— È una prova che avete il cuore cattivo. Bisogna chiedere a Dio di cambiarlo, di concedervene un altro più puro, di togliervi quel cuore di pietra, per darvene uno di carne.'}},\n",
       " {'id': '423',\n",
       "  'translation': {'en': 'I was about to propound a question, touching the manner in which that operation of changing my heart was to be performed, when Mrs. Reed interposed, telling me to sit down; she then proceeded to carry on the conversation herself.',\n",
       "   'it': 'Cercavo di capire per quale processo potrebbe effettuarsi quel cambiamento, quando la signora Reed mi disse di sedermi e prese lei a dirigere la conversazione.'}},\n",
       " {'id': '424',\n",
       "  'translation': {'en': '\"Mr. Brocklehurst, I believe I intimated in the letter which I wrote to you three weeks ago, that this little girl has not quite the character and disposition I could wish: should you admit her into Lowood school, I should be glad if the superintendent and teachers were requested to keep a strict eye on her, and, above all, to guard against her worst fault, a tendency to deceit.',\n",
       "   'it': \"— Credo, signor Bockelhurst, di avervi accennato nella mia lettera di tre settimane fa, che questa bimba non ha il carattere, nè le tendenze che avrei desiderato trovare in lei. Se dunque l'ammettete nella scuola di Lowood, domando che i capi e le maestre non la perdano d'occhio; la prego soprattutto di tenersi in guardia contro il suo più gran difetto; intendo parlare della sua tendenza alla menzogna.\"}},\n",
       " {'id': '425',\n",
       "  'translation': {'en': 'I mention this in your hearing, Jane, that you may not attempt to impose on Mr. Brocklehurst.\"',\n",
       "   'it': \"Dico tutte queste cose in presenza vostra, Jane, — aggiunse — per impedirvi d'ingannare il signor Bockelhurst.\"}},\n",
       " {'id': '426',\n",
       "  'translation': {'en': 'Well might I dread, well might I dislike Mrs. Reed; for it was her nature to wound me cruelly; never was I happy in her presence; however carefully I obeyed, however strenuously I strove to please her, my efforts were still repulsed and repaid by such sentences as the above.',\n",
       "   'it': 'Ero naturalmente inclinata a temere e a odiare la signora Reed, che pareva si studiasse di ferirmi sempre crudelmente. Non ero punto felice in presenza sua; qualunque sforzo che facessi per ubbidirle e per piacerle, non ricevevo in cambio altro che rimproveri come quello che ho riferito.'}},\n",
       " {'id': '427',\n",
       "  'translation': {'en': \"Now, uttered before a stranger, the accusation cut me to the heart; I dimly perceived that she was already obliterating hope from the new phase of existence which she destined me to enter; I felt, though I could not have expressed the feeling, that she was sowing aversion and unkindness along my future path; I saw myself transformed under Mr. Brocklehurst's eye into an artful, noxious child, and what could I do to remedy the injury?\",\n",
       "   'it': \"Vedeva vagamente che essa faceva svanire tutte le speranze, che riponeva in quella nuova esistenza che stavo per incominciare; sentivo confusamente, e senza rendermene conto, che ella seminava l'avversione e il malvolere sulla via che stavo per percorrere. Mi vedevo trasformata agli occhi del signor Bockelhurst in una bimba falsa e mentitrice; che cosa potevo fare per lavarmi da quell'accusa?\"}},\n",
       " {'id': '428',\n",
       "  'translation': {'en': '\"Nothing, indeed,\" thought I, as I struggled to repress a sob, and hastily wiped away some tears, the impotent evidences of my anguish.',\n",
       "   'it': '— Nulla! nulla! — pensavo fra me, — e mi sforzavo di reprimere un singhiozzo, e asciugavo rapidamente alcune lagrime, segno evidente di dolore.'}},\n",
       " {'id': '429',\n",
       "  'translation': {'en': '\"Deceit is, indeed, a sad fault in a child,\" said Mr. Brocklehurst; \"it is akin to falsehood, and all liars will have their portion in the lake burning with fire and brimstone; she shall, however, be watched, Mrs. Reed.',\n",
       "   'it': '— La menzogna è un brutto vizio in una bambina, — disse il signor Bockelhurst, — e chi avrà ingannato in vita, sarà condannato a patire in eterno in un abisso di fiamme e di zolfo.'}},\n",
       " {'id': '430',\n",
       "  'translation': {'en': 'I will speak to Miss Temple and the teachers.\"',\n",
       "   'it': 'Ma sarà sorvegliata; parlerò di lei alla signorina Temple e alle maestre.'}},\n",
       " {'id': '431',\n",
       "  'translation': {'en': '\"I should wish her to be brought up in a manner suiting her prospects,\" continued my benefactress; \"to be made useful, to be kept humble: as for the vacations, she will, with your permission, spend them always at Lowood.\"',\n",
       "   'it': '— Vorrei, — continuò la signora Reed, — che la sua educazione fosse adattata alla sua posizione, che la rendessero umile e operosa. Nelle vacanze vi chiedo il permesso di lasciarla a Lowood.'}},\n",
       " {'id': '432',\n",
       "  'translation': {'en': '\"Your decisions are perfectly judicious, madam,\" returned Mr. Brocklehurst. \"Humility is a Christian grace, and one peculiarly appropriate to the pupils of Lowood; I, therefore, direct that especial care shall be bestowed on its cultivation amongst them.',\n",
       "   'it': \"— Le vostre intenzioni sono molto sagge, signora, — riprese il signor Bockelhurst, — l'umiltà è virtù cristiana ed è necessaria sopratutto alle alunne di Lowood. Chiedo continuamente che si ponga ogni cura nell'ispirarla loro.\"}},\n",
       " {'id': '433',\n",
       "  'translation': {'en': 'I have studied how best to mortify in them the worldly sentiment of pride; and, only the other day, I had a pleasing proof of my success.',\n",
       "   'it': \"Ho lungamente cercato i migliori mezzi per mortificare in esso il sentimento mondano dell'orgoglio, e l'altro giorno ho avuto una prova del mio successo.\"}},\n",
       " {'id': '434',\n",
       "  'translation': {'en': 'My second daughter, Augusta, went with her mama to visit the school, and on her return she exclaimed: \\'Oh, dear papa, how quiet and plain all the girls at Lowood look, with their hair combed behind their ears, and their long pinafores, and those little holland pockets outside their frocks--they are almost like poor people\\'s children! and,\\' said she, \\'they looked at my dress and mama\\'s, as if they had never seen a silk gown before.\\'\"',\n",
       "   'it': '— La mia figlia secondogenita, — continuò dopo una pausa il signor Bockelhurst, — è andata insieme con sua madre a visitare l\\'Istituto, e tornando ha esclamato: \"Oh babbo! Quelle bimbe di Lowood, come paiono tranquille e semplici, con i capelli rialzati d\\'oltre l\\'orecchio, con i loro lunghi grembiuli, con i loro vestiti, con le tasche cucite di fuori!'}},\n",
       " {'id': '435',\n",
       "  'translation': {'en': '\"This is the state of things I quite approve,\" returned Mrs. Reed; \"had I sought all England over, I could scarcely have found a system more exactly fitting a child like Jane Eyre.',\n",
       "   'it': \"— Ecco una disciplina che approvo completamente, — continuò la signora Reed. — Se avessi cercato in tutta l'Inghilterra, non avrei trovato nulla di meglio per il carattere di Jane.\"}},\n",
       " {'id': '436',\n",
       "  'translation': {'en': 'Consistency, my dear Mr. Brocklehurst; I advocate consistency in all things.\"',\n",
       "   'it': \"Ma, mio caro signor Bockelhurst, chiedo l'uniformità su tutti i punti.\"}},\n",
       " {'id': '437',\n",
       "  'translation': {'en': '\"Consistency, madam, is the first of Christian duties; and it has been observed in every arrangement connected with the establishment of Lowood: plain fare, simple attire, unsophisticated accommodations, hardy and active habits; such is the order of the day in the house and its inhabitants.\"',\n",
       "   'it': \"— Certo, signora; è uno dei primi doveri cristiani, e a Lowood l'abbiamo osservato in tutto; cibo e abiti semplici, un'agiatezza che ci guardiamo bene dall'esagerare, vita dura e laboriosa; ecco la regola di quella casa.\"}},\n",
       " {'id': '438',\n",
       "  'translation': {'en': '\"Quite right, sir. I may then depend upon this child being received as a pupil at Lowood, and there being trained in conformity to her position and prospects?\"',\n",
       "   'it': '— Benissimo, signore, allora posso essere certa che questa bambina sarà accettata a Lowood, che vi sarà educata come richiede la sua posizione e in vista dei suoi doveri futuri.'}},\n",
       " {'id': '439',\n",
       "  'translation': {'en': '\"Madam, you may: she shall be placed in that nursery of chosen plants, and I trust she will show herself grateful for the inestimable privilege of her election.\"',\n",
       "   'it': \"— Potete esserlo, signora; ella sarà collocata in quell'asilo di piante scelte, e spero che l'inestimabile favore della sua ammissione la renderà riconoscente.\"}},\n",
       " {'id': '440',\n",
       "  'translation': {'en': '\"I will send her, then, as soon as possible, Mr. Brocklehurst; for, I assure you, I feel anxious to be relieved of a responsibility that was becoming too irksome.\"',\n",
       "   'it': '— Ve la manderò il più presto possibile, signor Bockelhurst, perché ho fretta, vi assicuro, di liberarmi di una responsabilità che diviene pesante.'}},\n",
       " {'id': '441',\n",
       "  'translation': {'en': '\"No doubt, no doubt, madam; and now I wish you good morning.',\n",
       "   'it': '— Senza dubbio, senza dubbio, signora.'}},\n",
       " {'id': '442',\n",
       "  'translation': {'en': 'I shall return to Brocklehurst Hall in the course of a week or two: my good friend, the Archdeacon, will not permit me to leave him sooner. I shall send Miss Temple notice that she is to expect a new girl, so that there will be no difficulty about receiving her.',\n",
       "   'it': \"Sono costretto a dirvi addio. Non ritornerò alla mia villa altro che fra un paio di settimane, perché il mio buon amico, l'arcidiacono, non vuole che la lasci prima; ma farò dire alla signora Temple di attendere una nuova alunna.\"}},\n",
       " {'id': '443', 'translation': {'en': 'Good-bye.\"', 'it': 'Addio, signora.'}},\n",
       " {'id': '444',\n",
       "  'translation': {'en': '\"Good-bye, Mr. Brocklehurst; remember me to Mrs. and Miss Brocklehurst, and to Augusta and Theodore, and Master Broughton Brocklehurst.\"',\n",
       "   'it': '— Addio, signore. Salutatemi la signora e la signorina Bockelhurst.'}},\n",
       " {'id': '445',\n",
       "  'translation': {'en': '\"I will, madam.', 'it': '— Non mancherò.'}},\n",
       " {'id': '446',\n",
       "  'translation': {'en': 'Little girl, here is a book entitled the \\'Child\\'s Guide,\\' read it with prayer, especially that part containing \\'An account of the awfully sudden death of Martha G---, a naughty child addicted to falsehood and deceit.\\'\"',\n",
       "   'it': 'Piccina, — disse volgendosi a me, — ecco un libro intitolato \"La guida dell\\'Infanzia\"; leggerete le preghiere che contiene, ma leggete sopratutto questa parte; vi vedrete narrata la morte della piccola Marta G...., bimba cattiva che, come voi, aveva il vizio di mentire.'}},\n",
       " {'id': '447',\n",
       "  'translation': {'en': 'With these words Mr. Brocklehurst put into my hand a thin pamphlet sewn in a cover, and having rung for his carriage, he departed.',\n",
       "   'it': 'Nel dir queste parole il signor Bockelhurst mi pose in mano un opuscolo ben avvolto nella carta, e, dopo aver chiesto la sua carrozza, ci lasciò.'}},\n",
       " {'id': '448',\n",
       "  'translation': {'en': 'Mrs. Reed and I were left alone: some minutes passed in silence; she was sewing, I was watching her.',\n",
       "   'it': 'Rimasi sola con la signora Reed, alcuni minuti trascorsero in silenzio; ella cuciva e io stavo a guardarla.'}},\n",
       " {'id': '449',\n",
       "  'translation': {'en': 'Mrs. Reed might be at that time some six or seven and thirty; she was a woman of robust frame, square-shouldered and strong-limbed, not tall, and, though stout, not obese: she had a somewhat large face, the under jaw being much developed and very solid; her brow was low, her chin large and prominent, mouth and nose sufficiently regular; under her light eyebrows glimmered an eye devoid of ruth; her skin was dark and opaque, her hair nearly flaxen; her constitution was sound as a bell--illness never came near her; she was an exact, clever manager; her household and tenantry were thoroughly under her control; her children only at times defied her authority and laughed it to scorn; she dressed well, and had a presence and port calculated to set off handsome attire.',\n",
       "   'it': \"Ella poteva avere trentasei anni; era una donna robusta, con le spalle quadre; non era grassa, benché fosse forte e piccola, e il volto pareva largo per l'eccessivo sviluppo del mento. Aveva la fronte bassa, la bocca ed il naso regolari; i suoi occhi, senza bontà, brillavano sotto le ciglia scolorate; era scura di carnagione e aveva i capelli biondi.\"}},\n",
       " {'id': '450',\n",
       "  'translation': {'en': 'What had just passed; what Mrs. Reed had said concerning me to Mr. Brocklehurst; the whole tenor of their conversation, was recent, raw, and stinging in my mind; I had felt every word as acutely as I had heard it plainly, and a passion of resentment fomented now within me.',\n",
       "   'it': 'Ciò che era avvenuto, ciò che la zia aveva detto al signor Bockelhurst, tutta la loro conversazione ancora recente e dolorosa mi restava in mente; ogni parola mi aveva ferita e stavo là, agitata da un vivo risentimento.'}},\n",
       " {'id': '451',\n",
       "  'translation': {'en': 'Mrs. Reed looked up from her work; her eye settled on mine, her fingers at the same time suspended their nimble movements.',\n",
       "   'it': 'La signora Reed alzò gli occhi dal lavoro, li fissò su di me e mi disse:'}},\n",
       " {'id': '452',\n",
       "  'translation': {'en': '\"Go out of the room; return to the nursery,\" was her mandate.',\n",
       "   'it': '— Uscite, tornate in camera.'}},\n",
       " {'id': '453',\n",
       "  'translation': {'en': 'My look or something else must have struck her as offensive, for she spoke with extreme though suppressed irritation.',\n",
       "   'it': \"Il mio sguardo o qualcos'altro forse l'aveva ferita, perché, nonostante che si contenesse, il suo accento era molto irritato.\"}},\n",
       " {'id': '454',\n",
       "  'translation': {'en': 'I got up, I went to the door; I came back again; I walked to the window, across the room, then close up to her.',\n",
       "   'it': 'Mi alzai e mi diressi verso la porta, ma tornai subito addietro, mi accostai alla finestra, poi andai nel mezzo della stanza e finalmente mi accostai a lei.'}},\n",
       " {'id': '455',\n",
       "  'translation': {'en': '\"I am not deceitful: if I were, I should say I loved you; but I declare I do not love you: I dislike you the worst of anybody in the world except John Reed; and this book about the liar, you may give to your girl, Georgiana, for it is she who tells lies, and not I.\"',\n",
       "   'it': \"— Non sono finta; se lo fossi stata, avrei detto che vi voleva bene; ma non vi voglio bene e lo dichiaro; vi odio più che ogni altro, eccettuato John Reed. Questo racconto di una bugiarda potete darlo alla vostra Georgiana, perché è lei che v'inganna e non io.\"}},\n",
       " {'id': '456',\n",
       "  'translation': {'en': \"Mrs. Reed's hands still lay on her work inactive: her eye of ice continued to dwell freezingly on mine.\",\n",
       "   'it': 'Le dita della signora Reed erano rimaste immobili, e con i suoi occhi di ghiaccio continuava a fissarmi.'}},\n",
       " {'id': '457',\n",
       "  'translation': {'en': '\"What more have you to say?\" she asked, rather in the tone in which a person might address an opponent of adult age than such as is ordinarily used to a child.',\n",
       "   'it': '— Che cosa avete da dirmi ancora? — mi domandò con un tono che sarebbe stato più adattato per parlare a una donna che a una bambina.'}},\n",
       " {'id': '458',\n",
       "  'translation': {'en': 'That eye of hers, that voice stirred every antipathy I had.',\n",
       "   'it': 'Quello sguardo, quella voce ridestarono tutte le mie antipatie.'}},\n",
       " {'id': '459',\n",
       "  'translation': {'en': 'Shaking from head to foot, thrilled with ungovernable excitement, I continued--',\n",
       "   'it': 'Commossa, aizzata da una invincibile irritazione, continuai:'}},\n",
       " {'id': '460',\n",
       "  'translation': {'en': '\"I am glad you are no relation of mine: I will never call you aunt again as long as I live. I will never come to see you when I am grown up; and if any one asks me how I liked you, and how you treated me, I will say the very thought of you makes me sick, and that you treated me with miserable cruelty.\"',\n",
       "   'it': '— Sono felice che non siate mia parente, e non vi chiamerò più zia, non verrò mai a trovarvi quando sarò grande, e quando qualcuno mi domanderà se vi voglio bene e come mi trattate, gli dirò che il vostro ricordo mi fa male e che siete stata crudele con me.'}},\n",
       " {'id': '461',\n",
       "  'translation': {'en': '\"How dare you affirm that, Jane Eyre?\"',\n",
       "   'it': '— Come, Jane, osereste affermare cose simili?'}},\n",
       " {'id': '462',\n",
       "  'translation': {'en': '\"How dare I, Mrs. Reed? How dare I? Because it is the _truth_.',\n",
       "   'it': '— Sì, oserei, signora Reed, oserei perché è la verità.'}},\n",
       " {'id': '463',\n",
       "  'translation': {'en': 'You think I have no feelings, and that I can do without one bit of love or kindness; but I cannot live so: and you have no pity.',\n",
       "   'it': 'Credete forse che non senta e che possa vivere senza che nessuno mi voglia bene e sia buono per me? No, e voi non avete avuto pietà di me.'}},\n",
       " {'id': '464',\n",
       "  'translation': {'en': 'I shall remember how you thrust me back--roughly and violently thrust me back--into the red-room, and locked me up there, to my dying day; though I was in agony; though I cried out, while suffocating with distress,',\n",
       "   'it': 'Mi rammenterò sempre con quanta durezza mi avete respinta nella camera rossa, quale sguardo mi avete gettato quando ero in agonia. Eppure, oppressa dal dolore, vi avevo gridato:'}},\n",
       " {'id': '465',\n",
       "  'translation': {'en': \"'Have mercy! Have mercy, Aunt Reed!'\",\n",
       "   'it': '\"Zia, abbiate pietà di me!\"'}},\n",
       " {'id': '466',\n",
       "  'translation': {'en': 'And that punishment you made me suffer because your wicked boy struck me--knocked me down for nothing.',\n",
       "   'it': \"E quella punizione me l'avevate inflitta perché era stata percossa, gettata in terra dal vostro perfido figliuolo.\"}},\n",
       " {'id': '467',\n",
       "  'translation': {'en': 'I will tell anybody who asks me questions, this exact tale.',\n",
       "   'it': \"Dirò la pura verità a tutti quelli che m'interrogheranno.\"}},\n",
       " {'id': '468',\n",
       "  'translation': {'en': 'People think you a good woman, but you are bad, hard-hearted. _You_ are deceitful!\"',\n",
       "   'it': 'Credono che siate buona, ma avete il cuore come un masso e siete falsa.'}},\n",
       " {'id': '469',\n",
       "  'translation': {'en': 'Ere I had finished this reply, my soul began to expand, to exult, with the strangest sense of freedom, of triumph, I ever felt.',\n",
       "   'it': 'Quando ebbi cessato di parlare, il più strano sentimento di trionfo, che abbia mai provato, erasi impossessato di me.'}},\n",
       " {'id': '470',\n",
       "  'translation': {'en': 'It seemed as if an invisible bond had burst, and that I had struggled out into unhoped- for liberty.',\n",
       "   'it': \"Credei che un'invincibile catena si fosse infranta, e che avessi riconquistata la mia libertà.\"}},\n",
       " {'id': '471',\n",
       "  'translation': {'en': 'Not without cause was this sentiment: Mrs. Reed looked frightened; her work had slipped from her knee; she was lifting up her hands, rocking herself to and fro, and even twisting her face as if she would cry.',\n",
       "   'it': 'Potevo crederlo infatti, perché la signora Reed pareva sgomenta; il lavoro le era scivolato di grembo; alzava le mani e sul volto contratto si sarebbe detto che stessero per iscendere le lagrime.'}},\n",
       " {'id': '472',\n",
       "  'translation': {'en': '\"Jane, you are under a mistake: what is the matter with you?',\n",
       "   'it': '— Jane, vi sbagliate, che cosa avete?'}},\n",
       " {'id': '473',\n",
       "  'translation': {'en': 'Why do you tremble so violently?',\n",
       "   'it': 'Perché tremate tanto?'}},\n",
       " {'id': '474',\n",
       "  'translation': {'en': 'Would you like to drink some water?\"',\n",
       "   'it': \"Volete bere un po' d'acqua?\"}},\n",
       " {'id': '475',\n",
       "  'translation': {'en': '\"No, Mrs. Reed.\"', 'it': '— No, signora Reed.'}},\n",
       " {'id': '476',\n",
       "  'translation': {'en': '\"Is there anything else you wish for, Jane?',\n",
       "   'it': '— Desiderate qualche altra cosa, Jane?'}},\n",
       " {'id': '477',\n",
       "  'translation': {'en': 'I assure you, I desire to be your friend.\"',\n",
       "   'it': 'Vi assicuro che vorrei esservi amica.'}},\n",
       " {'id': '478', 'translation': {'en': '\"Not you.', 'it': '— Non è vero.'}},\n",
       " {'id': '479',\n",
       "  'translation': {'en': 'You told Mr. Brocklehurst I had a bad character, a deceitful disposition; and I\\'ll let everybody at Lowood know what you are, and what you have done.\"',\n",
       "   'it': 'Avete detto poco fa al signor Bockelhurst che avevo un cattivo carattere, che ero una bugiarda; ma tutti a Lowood saranno informati della vostra condotta.'}},\n",
       " {'id': '480',\n",
       "  'translation': {'en': '\"Jane, you don\\'t understand these things: children must be corrected for their faults.\"',\n",
       "   'it': '— Jane, non potete capire certe cose; i bambini debbono esser corretti dei loro difetti.'}},\n",
       " {'id': '481',\n",
       "  'translation': {'en': '\"Deceit is not my fault!\" I cried out in a savage, high voice.',\n",
       "   'it': '— La menzogna non è il mio difetto, — esclamai con voce piena di collera.'}},\n",
       " {'id': '482',\n",
       "  'translation': {'en': '\"But you are passionate, Jane, that you must allow: and now return to the nursery--there\\'s a dear--and lie down a little.\"',\n",
       "   'it': '— Ma siete violenta, dovete confessarlo; e ora tornate in camera vostra, mia cara, e cercate di dormire un poco.'}},\n",
       " {'id': '483',\n",
       "  'translation': {'en': '\"I am not your dear; I cannot lie down: send me to school soon, Mrs. Reed, for I hate to live here.\"',\n",
       "   'it': '— Non sono la vostra cara, e non posso dormire. Mandatemi subito in pensione, signora Reed, perché questa casa mi è odiosa.'}},\n",
       " {'id': '484',\n",
       "  'translation': {'en': '\"I will indeed send her to school soon,\" murmured Mrs. Reed _sotto voce_; and gathering up her work, she abruptly quitted the apartment.',\n",
       "   'it': '— Sì, sì, voglio mandartici più presto che posso, — disse sottovoce; e prendendo il lavoro, uscì precipitosamente dalla stanza.'}},\n",
       " {'id': '485',\n",
       "  'translation': {'en': 'I was left there alone--winner of the field.',\n",
       "   'it': 'Ero rimasta sola, padrona del campo.'}},\n",
       " {'id': '486',\n",
       "  'translation': {'en': \"It was the hardest battle I had fought, and the first victory I had gained: I stood awhile on the rug, where Mr. Brocklehurst had stood, and I enjoyed my conqueror's solitude.\",\n",
       "   'it': \"Era la più tremenda battaglia che avessi combattuta, e la prima vittoria riportata. Restai un momento seduta al posto ov'era prima il signor Bockelhurst, assaporando la mia solitudine di conquistatrice.\"}},\n",
       " {'id': '487',\n",
       "  'translation': {'en': 'First, I smiled to myself and felt elate; but this fierce pleasure subsided in me as fast as did the accelerated throb of my pulses.',\n",
       "   'it': 'Prima sorrisi a me stessa e mi sentii sollevata, ma quel feroce piacere cessò col cessare dei violenti battiti del cuore.'}},\n",
       " {'id': '488',\n",
       "  'translation': {'en': 'A child cannot quarrel with its elders, as I had done; cannot give its furious feelings uncontrolled play, as I had given mine, without experiencing afterwards the pang of remorse and the chill of reaction.',\n",
       "   'it': 'Una bimba non può insultare i suoi superiori, come avevo fatto io, non può dare sfogo alla collera, senza provar subito la puntura del rimorso e il gelo della reazione.'}},\n",
       " {'id': '489',\n",
       "  'translation': {'en': \"A ridge of lighted heath, alive, glancing, devouring, would have been a meet emblem of my mind when I accused and menaced Mrs. Reed: the same ridge, black and blasted after the flames are dead, would have represented as meetly my subsequent condition, when half-an-hour's silence and reflection had shown me the madness of my conduct, and the dreariness of my hated and hating position.\",\n",
       "   'it': \"Quando avevo accusato e minacciato la signora Reed, la mia anima era in fiamme, ma dopo una mezz'ora di silenzio e di riflessione riconobbi la pazzia commessa e la tristezza della mia posizione di bimba che odia e che è odiata.\"}},\n",
       " {'id': '490',\n",
       "  'translation': {'en': 'Something of vengeance I had tasted for the first time; as aromatic wine it seemed, on swallowing, warm and racy: its after-flavour, metallic and corroding, gave me a sensation as if I had been poisoned.',\n",
       "   'it': 'Per la prima volta aveva assaporata la vendetta e mi parve dolce e vivificante; ma la sensazione che lasciava in me era amara come il veleno.'}},\n",
       " {'id': '491',\n",
       "  'translation': {'en': \"Willingly would I now have gone and asked Mrs. Reed's pardon; but I knew, partly from experience and partly from instinct, that was the way to make her repulse me with double scorn, thereby re-exciting every turbulent impulse of my nature.\",\n",
       "   'it': 'Allora sarei andata a chiedere scusa alla signora Reed, ma sapevo per istinto e per esperienza, che me la sarei maggiormente inimicata ed avrei rieccitato i violenti impulsi della mia indole.'}},\n",
       " {'id': '492',\n",
       "  'translation': {'en': 'I took a book--some Arabian tales; I sat down and endeavoured to read.',\n",
       "   'it': 'Presi un volume di racconti arabi e cercai di leggere, senza capire nulla.'}},\n",
       " {'id': '493',\n",
       "  'translation': {'en': 'I could make no sense of the subject; my own thoughts swam always between me and the page I had usually found fascinating.',\n",
       "   'it': 'Il pensiero vagava e non potevo fissarlo né su me stessa, né su quelle pagine, che mi avevano procurato in passato tanto piacere.'}},\n",
       " {'id': '494',\n",
       "  'translation': {'en': 'I opened the glass-door in the breakfast-room: the shrubbery was quite still: the black frost reigned, unbroken by sun or breeze, through the grounds.',\n",
       "   'it': 'Aprii la porta a vetri della sala da pranzo, il boschetto era silenzioso e il sole nè il vento avevano potuto vincere il ghiaccio che copriva la terra.'}},\n",
       " {'id': '495',\n",
       "  'translation': {'en': 'I covered my head and arms with the skirt of my frock, and went out to walk in a part of the plantation which was quite sequestrated; but I found no pleasure in the silent trees, the falling fir-cones, the congealed relics of autumn, russet leaves, swept by past winds in heaps, and now stiffened together.',\n",
       "   'it': \"Mi coprii la testa con la sottana e andai a passeggiare in una parte isolata del parco, senza provare alcun piacere sotto quegli alberi silenziosi, tra quelle pine, ultimi avanzi dell'autunno, di cui era coperta la terra, in mezzo a quelle foglie secche, ammonticchiate dal vento.\"}},\n",
       " {'id': '496',\n",
       "  'translation': {'en': 'I leaned against a gate, and looked into an empty field where no sheep were feeding, where the short grass was nipped and blanched.',\n",
       "   'it': \"Mi appoggiai al cancello guardando un campo deserto, dove le vacche non pascevano più, dove l'erba era stata falciata dal gelo e coperta di neve.\"}},\n",
       " {'id': '497',\n",
       "  'translation': {'en': 'It was a very grey day; a most opaque sky, \"onding on snaw,\" canopied all; thence flakes felt it intervals, which settled on the hard path and on the hoary lea without melting.',\n",
       "   'it': 'Era una giornata tristissima, e ogni tanto le falde di neve cadevano al suolo indurito del viale, senza liquefarsi.'}},\n",
       " {'id': '498',\n",
       "  'translation': {'en': 'I stood, a wretched child enough, whispering to myself over and over again, \"What shall I do?--what shall I do?\"',\n",
       "   'it': 'Ero tanto infelice e ogni tanto dicevo a me stessa: — Che cosa devo fare?'}},\n",
       " {'id': '499',\n",
       "  'translation': {'en': 'All at once I heard a clear voice call, \"Miss Jane! where are you?',\n",
       "   'it': 'Sentii a un tratto una voce chiara gridare: — Signorina Jane, dove siete?'}},\n",
       " {'id': '500',\n",
       "  'translation': {'en': 'Come to lunch!\"', 'it': 'Venite a colazione.'}},\n",
       " {'id': '501',\n",
       "  'translation': {'en': 'It was Bessie, I knew well enough; but I did not stir; her light step came tripping down the path.',\n",
       "   'it': 'Però poco dopo sentii un lieve rumore di passi. Ella traversava il viale per venir da me.'}},\n",
       " {'id': '502',\n",
       "  'translation': {'en': '\"You naughty little thing!\" she said. \"Why don\\'t you come when you are called?\"',\n",
       "   'it': '— Cattiva, — mi disse, — perché non venite quando vi si chiama?'}},\n",
       " {'id': '503',\n",
       "  'translation': {'en': \"Bessie's presence, compared with the thoughts over which I had been brooding, seemed cheerful; even though, as usual, she was somewhat cross.\",\n",
       "   'it': 'La presenza di Bessie mi parve dolce in confronto dei pensieri che mi torturavano, benché ella fosse, secondo il solito, di cattivo umore.'}},\n",
       " {'id': '504',\n",
       "  'translation': {'en': \"The fact is, after my conflict with and victory over Mrs. Reed, I was not disposed to care much for the nursemaid's transitory anger; and I _was_ disposed to bask in her youthful lightness of heart.\",\n",
       "   'it': 'È un fatto che dopo la mia disputa con la signora Reed e la mia vittoria, faceva poco conto della collera passeggiera della bambinaia, ed ero pronta a cercar conforto nel suo giovane cuore.'}},\n",
       " {'id': '505',\n",
       "  'translation': {'en': 'I just put my two arms round her and said, \"Come, Bessie! don\\'t scold.\"',\n",
       "   'it': 'Le gettai le braccia al collo, dicendole: — Venite, Bessie, non mi sgridate.'}},\n",
       " {'id': '506',\n",
       "  'translation': {'en': 'The action was more frank and fearless than any I was habituated to indulge in: somehow it pleased her.',\n",
       "   'it': 'Non mi ero mai mostrata così franca ed espansiva, e il mio modo di fare le piacque.'}},\n",
       " {'id': '507',\n",
       "  'translation': {'en': '\"You are a strange child, Miss Jane,\" she said, as she looked down at me; \"a little roving, solitary thing: and you are going to school, I suppose?\"',\n",
       "   'it': '— Siete una strana bambina, signorina Jane, — mi disse, fissandomi, — una bimba vagabonda e amica della solitudine. Andate in pensione, eh?'}},\n",
       " {'id': '508',\n",
       "  'translation': {'en': 'I nodded.', 'it': 'Feci un cenno affermativo.'}},\n",
       " {'id': '509',\n",
       "  'translation': {'en': '\"And won\\'t you be sorry to leave poor Bessie?\"',\n",
       "   'it': '— E non vi dispiace di lasciare la povera Bessie?'}},\n",
       " {'id': '510',\n",
       "  'translation': {'en': '\"What does Bessie care for me?',\n",
       "   'it': '— Che cosa sono per Bessie?'}},\n",
       " {'id': '511',\n",
       "  'translation': {'en': 'She is always scolding me.\"',\n",
       "   'it': 'Mi sgrida sempre.'}},\n",
       " {'id': '512',\n",
       "  'translation': {'en': '\"Because you\\'re such a queer, frightened, shy little thing.',\n",
       "   'it': '— Perché vi mostrate bizzarra, timida, spaventata, piccina.'}},\n",
       " {'id': '513',\n",
       "  'translation': {'en': 'You should be bolder.\"',\n",
       "   'it': 'Se foste più ardita....'}},\n",
       " {'id': '514',\n",
       "  'translation': {'en': '\"What! to get more knocks?\"',\n",
       "   'it': '— Sì, per essere picchiata!'}},\n",
       " {'id': '515', 'translation': {'en': '\"Nonsense!', 'it': '— Sciocchezze!'}},\n",
       " {'id': '516',\n",
       "  'translation': {'en': \"But you are rather put upon, that's certain.\",\n",
       "   'it': 'Ma è certo che non siete trattata bene.'}},\n",
       " {'id': '517',\n",
       "  'translation': {'en': 'My mother said, when she came to see me last week, that she would not like a little one of her own to be in your place.--Now, come in, and I\\'ve some good news for you.\"',\n",
       "   'it': 'Mia madre, quando venne qui la settimana passata, disse che non vorrebbe vedere uno dei suoi figli al vostro posto.'}},\n",
       " {'id': '518',\n",
       "  'translation': {'en': '\"I don\\'t think you have, Bessie.\"',\n",
       "   'it': 'Ma ho una buona notizia per voi. — Non ci credo.'}},\n",
       " {'id': '519',\n",
       "  'translation': {'en': '\"Child! what do you mean?',\n",
       "   'it': '— Bimba, che volete dire?'}},\n",
       " {'id': '520',\n",
       "  'translation': {'en': 'What sorrowful eyes you fix on me!',\n",
       "   'it': 'Perché fissate su di me uno sguardo così triste?'}},\n",
       " {'id': '521',\n",
       "  'translation': {'en': \"Well, but Missis and the young ladies and Master John are going out to tea this afternoon, and you shall have tea with me. I'll ask cook to bake you a little cake, and then you shall help me to look over your drawers; for I am soon to pack your trunk.\",\n",
       "   'it': 'Ebbene, sappiate che il padroncino, la signora e le signorine sono andate a prendere il thè da un loro amico; voi lo prenderete con me e dirò alla cuoca di farvi un dolce, e poi mi aiuterete a guardare nei cassetti, perché presto dovrò prepararvi il baule.'}},\n",
       " {'id': '522',\n",
       "  'translation': {'en': 'Missis intends you to leave Gateshead in a day or two, and you shall choose what toys you like to take with you.\"',\n",
       "   'it': 'La signora vuole che andiate via fra un paio di giorni, così sceglierete la roba che volete portar con voi.'}},\n",
       " {'id': '523',\n",
       "  'translation': {'en': '\"Bessie, you must promise not to scold me any more till I go.\"',\n",
       "   'it': '— Bessie, promettetemi di non rimproverarmi più fino alla partenza.'}},\n",
       " {'id': '524',\n",
       "  'translation': {'en': '\"Well, I will; but mind you are a very good girl, and don\\'t be afraid of me.',\n",
       "   'it': '— Ebbene, sì, ma siate buona e non abbiate paura di me.'}},\n",
       " {'id': '525',\n",
       "  'translation': {'en': 'Don\\'t start when I chance to speak rather sharply; it\\'s so provoking.\"',\n",
       "   'it': 'Non vi scostate quando alzo la voce; questo mi irrita i nervi.'}},\n",
       " {'id': '526',\n",
       "  'translation': {'en': '\"I don\\'t think I shall ever be afraid of you again, Bessie, because I have got used to you, and I shall soon have another set of people to dread.\"',\n",
       "   'it': '— Sento che ora non ho più paura di voi, perché mi sono assuefatta ai vostri modi, ma dovrò presto temere di altre persone.'}},\n",
       " {'id': '527',\n",
       "  'translation': {'en': '\"If you dread them they\\'ll dislike you.\"',\n",
       "   'it': '— Se le temerete, vi odieranno.'}},\n",
       " {'id': '528',\n",
       "  'translation': {'en': '\"As you do, Bessie?\"', 'it': '— Come voi, Bessie?'}},\n",
       " {'id': '529',\n",
       "  'translation': {'en': '\"I don\\'t dislike you, Miss; I believe I am fonder of you than of all the others.\"',\n",
       "   'it': '— Non vi odio, signorina. Mi pare anzi di volervi più bene che agli altri.'}},\n",
       " {'id': '530',\n",
       "  'translation': {'en': '\"You don\\'t show it.\"',\n",
       "   'it': '— Non me lo dimostrate davvero.'}},\n",
       " {'id': '531',\n",
       "  'translation': {'en': '\"You little sharp thing! you\\'ve got quite a new way of talking.',\n",
       "   'it': '— Aspra creatura, ecco una nuova maniera di parlare.'}},\n",
       " {'id': '532',\n",
       "  'translation': {'en': 'What makes you so venturesome and hardy?\"',\n",
       "   'it': 'Che cosa vi rende così sicura ed ardita?'}},\n",
       " {'id': '533',\n",
       "  'translation': {'en': '\"Why, I shall soon be away from you, and besides\"--I was going to say something about what had passed between me and Mrs. Reed, but on second thoughts I considered it better to remain silent on that head.',\n",
       "   'it': 'Stavo per narrare quello che era avvenuto fra me e la signora Reed, ma riflettendo mi accorsi che era meglio tacere.'}},\n",
       " {'id': '534',\n",
       "  'translation': {'en': '\"And so you\\'re glad to leave me?\"',\n",
       "   'it': '— Allora siete contenta di lasciarmi?'}},\n",
       " {'id': '535',\n",
       "  'translation': {'en': '\"Not at all, Bessie; indeed, just now I\\'m rather sorry.\"',\n",
       "   'it': '— No, Bessie, no davvero, e in questo momento mi sento triste.'}},\n",
       " {'id': '536',\n",
       "  'translation': {'en': '\"Just now! and rather!',\n",
       "   'it': '— In questo momento!'}},\n",
       " {'id': '537',\n",
       "  'translation': {'en': 'How coolly my little lady says it!',\n",
       "   'it': 'Come lo dite freddamente, signorina.'}},\n",
       " {'id': '538',\n",
       "  'translation': {'en': 'I dare say now if I were to ask you for a kiss you wouldn\\'t give it me: you\\'d say you\\'d _rather_ not.\"',\n",
       "   'it': 'Sono sicura che se vi domandassi di abbracciarmi, mi direste di no.'}},\n",
       " {'id': '539',\n",
       "  'translation': {'en': '\"I\\'ll kiss you and welcome: bend your head down.\"',\n",
       "   'it': '— Oh, no. Voglio abbracciarvi e mi farete tanto piacere; abbassate un poco la testa.'}},\n",
       " {'id': '540',\n",
       "  'translation': {'en': 'Bessie stooped; we mutually embraced, and I followed her into the house quite comforted.',\n",
       "   'it': 'Bessie si chinò e ci abbracciammo, poi, divenuta tranquilla, la seguii in casa.'}},\n",
       " {'id': '541',\n",
       "  'translation': {'en': 'That afternoon lapsed in peace and harmony; and in the evening Bessie told me some of her most enchanting stories, and sang me some of her sweetest songs.',\n",
       "   'it': \"Il dopopranzo trascorse nella pace e nell'armonia. La sera Bessie mi narrò le più belle fra le sue novelle e mi cantò le più dolci canzoni.\"}},\n",
       " {'id': '542',\n",
       "  'translation': {'en': 'Even for me life had its gleams of sunshine.',\n",
       "   'it': 'Anche sulla mia vita splendevano are luminose.'}},\n",
       " {'id': '543', 'translation': {'en': 'CHAPTER V', 'it': 'V.'}},\n",
       " {'id': '544',\n",
       "  'translation': {'en': \"Five o'clock had hardly struck on the morning of the 19th of January, when Bessie brought a candle into my closet and found me already up and nearly dressed.\",\n",
       "   'it': 'Era la mattina del 19 gennaio; le cinque suonavano mentre Bessie, con la candela in mano, entrava nel mio stanzino. Ero alzata e quasi vestita.'}},\n",
       " {'id': '545',\n",
       "  'translation': {'en': 'I had risen half-an-hour before her entrance, and had washed my face, and put on my clothes by the light of a half-moon just setting, whose rays streamed through the narrow window near my crib.',\n",
       "   'it': \"Mi ero levata una mezz'ora prima, e dopo essermi lavata il viso, mi ero infilata i vestiti alla pallida luce della luna, i cui raggi penetravano nella stanza dall'angusta finestra.\"}},\n",
       " {'id': '546',\n",
       "  'translation': {'en': 'I was to leave Gateshead that day by a coach which passed the lodge gates at six a.m.',\n",
       "   'it': 'Dovevo partire da Gateshead quel giorno e prendere alle sei la diligenza che passava davanti alla casetta del portinaio.'}},\n",
       " {'id': '547',\n",
       "  'translation': {'en': 'Bessie was the only person yet risen; she had lit a fire in the nursery, where she now proceeded to make my breakfast.',\n",
       "   'it': 'Bessie sola era alzata; ella aveva acceso il fuoco e si preparava a scaldarsi la colazione.'}},\n",
       " {'id': '548',\n",
       "  'translation': {'en': 'Few children can eat when excited with the thoughts of a journey; nor could I. Bessie, having pressed me in vain to take a few spoonfuls of the boiled milk and bread she had prepared for me, wrapped up some biscuits in a paper and put them into my bag; then she helped me on with my pelisse and bonnet, and wrapping herself in a shawl, she and I left the nursery.',\n",
       "   'it': 'Rari sono i bimbi che possano mangiare prima di mettersi in viaggio, neppur io poteva. Bessie mi pregò di buttar giù una o due cucchiaiate di pappa col latte che mi aveva prima preparato.'}},\n",
       " {'id': '549',\n",
       "  'translation': {'en': 'As we passed Mrs. Reed\\'s bedroom, she said, \"Will you go in and bid Missis good- bye?\"',\n",
       "   'it': 'Quando giunsi davanti alla camera della signora Reed, Bessie mi domandò se volevo dire addio alla sua padrona.'}},\n",
       " {'id': '550',\n",
       "  'translation': {'en': '\"No, Bessie: she came to my crib last night when you were gone down to supper, and said I need not disturb her in the morning, or my cousins either; and she told me to remember that she had always been my best friend, and to speak of her and be grateful to her accordingly.\"',\n",
       "   'it': '— No, Bessie, — risposi. — Ieri sera quando scendeste per la cena, ella si avvicinò al mio letto e mi dichiarò che partendo non aveva bisogno di disturbare né lei né le mie cugine; mi disse pure che era stata sempre la mia migliore amica e che non lo dimenticassi. Poi mi pregò di parlar bene di lei e di esserle grata.'}},\n",
       " {'id': '551',\n",
       "  'translation': {'en': '\"What did you say, Miss?\"',\n",
       "   'it': '— E che cosa le rispondeste?'}},\n",
       " {'id': '552',\n",
       "  'translation': {'en': '\"Nothing: I covered my face with the bedclothes, and turned from her to the wall.\"',\n",
       "   'it': '— Niente; nascosi il viso sotto le coperte e mi voltai verso il muro.'}},\n",
       " {'id': '553',\n",
       "  'translation': {'en': '\"That was wrong, Miss Jane.\"',\n",
       "   'it': '— Faceste male, signorina Jane.'}},\n",
       " {'id': '554',\n",
       "  'translation': {'en': '\"It was quite right, Bessie.',\n",
       "   'it': '— No, Bessie. Era giusto.'}},\n",
       " {'id': '555',\n",
       "  'translation': {'en': 'Your Missis has not been my friend: she has been my foe.\"',\n",
       "   'it': 'La vostra padrona non è mai stata buona con me, anzi mi ha trattato sempre come una nemica.'}},\n",
       " {'id': '556',\n",
       "  'translation': {'en': '\"O Miss Jane! don\\'t say so!\"',\n",
       "   'it': '— Oh! signorina, non lo dite!'}},\n",
       " {'id': '557',\n",
       "  'translation': {'en': '\"Good-bye to Gateshead!\" cried I, as we passed through the hall and went out at the front door.',\n",
       "   'it': '— Addio, Gateshead, — dissi passando sotto il portone.'}},\n",
       " {'id': '558',\n",
       "  'translation': {'en': 'The moon was set, and it was very dark; Bessie carried a lantern, whose light glanced on wet steps and gravel road sodden by a recent thaw.',\n",
       "   'it': 'La luna era sparita e la notte rimasta tenebrosa. Bessie portava una lanterna che illuminava gli scalini umidi della gradinata, e i viali inondati dal disgelo.'}},\n",
       " {'id': '559',\n",
       "  'translation': {'en': 'Raw and chill was the winter morning: my teeth chattered as I hastened down the drive.',\n",
       "   'it': 'Io battevo i denti per il freddo.'}},\n",
       " {'id': '560',\n",
       "  'translation': {'en': \"There was a light in the porter's lodge: when we reached it, we found the porter's wife just kindling her fire: my trunk, which had been carried down the evening before, stood corded at the door.\",\n",
       "   'it': 'La casetta del portiere era illuminata e giungendovi trovammo la moglie che accendeva il fuoco. La sera prima vi avevano portato il mio baule già legato.'}},\n",
       " {'id': '561',\n",
       "  'translation': {'en': 'It wanted but a few minutes of six, and shortly after that hour had struck, the distant roll of wheels announced the coming coach; I went to the door and watched its lamps approach rapidly through the gloom.',\n",
       "   'it': \"Erano le sei meno qualche minuto quando un rumore di ruote annunziò l'arrivo della diligenza. Mi diressi verso la porta e vidi la luce delle lanterne avanzarsi nelle tenebre.\"}},\n",
       " {'id': '562',\n",
       "  'translation': {'en': '\"Is she going by herself?\" asked the porter\\'s wife.',\n",
       "   'it': '— Parte sola? — domandò la portinaia.'}},\n",
       " {'id': '563', 'translation': {'en': '\"Yes.\"', 'it': '— Sì.'}},\n",
       " {'id': '564',\n",
       "  'translation': {'en': '\"And how far is it?\"',\n",
       "   'it': '— Va lontana? — A cinquanta miglia.'}},\n",
       " {'id': '565',\n",
       "  'translation': {'en': '\"Fifty miles.\"', 'it': \"— Com'è distante!\"}},\n",
       " {'id': '566',\n",
       "  'translation': {'en': '\"What a long way! I wonder Mrs. Reed is not afraid to trust her so far alone.\"',\n",
       "   'it': 'Mi sorprende che la signora Reed la mandi sola per fare un viaggio così lungo.'}},\n",
       " {'id': '567',\n",
       "  'translation': {'en': \"The coach drew up; there it was at the gates with its four horses and its top laden with passengers: the guard and coachman loudly urged haste; my trunk was hoisted up; I was taken from Bessie's neck, to which I clung with kisses.\",\n",
       "   'it': \"Una carrozza tirata da due cavalli, con l'imperiale coperto di viaggiatori, si fermò davanti alla porta. Il postiglione e il conduttore raccomandarono di far presto.\"}},\n",
       " {'id': '568',\n",
       "  'translation': {'en': '\"Be sure and take good care of her,\" cried she to the guard, as he lifted me into the inside.',\n",
       "   'it': 'Il baule fu alzato e mi strapparono dalle braccia di Bessie, mentre le ero sospesa al collo.'}},\n",
       " {'id': '569',\n",
       "  'translation': {'en': '\"Ay, ay!\" was the answer: the door was slapped to, a voice exclaimed \"All right,\" and on we drove.',\n",
       "   'it': '— Abbiate cura della bimba, — gridò ella al conduttore quando questi mi metteva dentro il legno. — Sì — rispose. Lo sportello fu chiuso, e sentii una voce che diceva: \"Avanti!\"'}},\n",
       " {'id': '570',\n",
       "  'translation': {'en': 'Thus was I severed from Bessie and Gateshead; thus whirled away to unknown, and, as I then deemed, remote and mysterious regions.',\n",
       "   'it': 'Così fui separata da Bessie e da Gateshead, così fui condotta verso regioni ignote e che credevo lontane e misteriose.'}},\n",
       " {'id': '571',\n",
       "  'translation': {'en': 'I remember but little of the journey; I only know that the day seemed to me of a preternatural length, and that we appeared to travel over hundreds of miles of road.',\n",
       "   'it': 'Mi rammento poco del viaggio; il giorno mi parve interminabile, e credevo che avessimo percorso centinaia di leghe.'}},\n",
       " {'id': '572',\n",
       "  'translation': {'en': 'We passed through several towns, and in one, a very large one, the coach stopped; the horses were taken out, and the passengers alighted to dine.',\n",
       "   'it': 'Si traversò diverse città, e in una di esse la carrozza fece sosta. I cavalli furono cambiati e i viaggiatori scesero per desinare.'}},\n",
       " {'id': '573',\n",
       "  'translation': {'en': 'I was carried into an inn, where the guard wanted me to have some dinner; but, as I had no appetite, he left me in an immense room with a fireplace at each end, a chandelier pendent from the ceiling, and a little red gallery high up against the wall filled with musical instruments.',\n",
       "   'it': 'Mi condussero in un albergo, e il conduttore volle farmi mangiare qualcosa; ma siccome non avevo fame, mi lasciò in una sala immensa nella quale vi erano due caminetti alle estremità. Nel mezzo era sospesa una lumiera e in alto, nella galleria, vi erano tanti strumenti musicali.'}},\n",
       " {'id': '574',\n",
       "  'translation': {'en': \"Here I walked about for a long time, feeling very strange, and mortally apprehensive of some one coming in and kidnapping me; for I believed in kidnappers, their exploits having frequently figured in Bessie's fireside chronicles.\",\n",
       "   'it': 'Passeggiai un pezzo nella sala, sentendomi oppressa da strani pensieri. Temevo che mi portassero via, perché credevo ai rapitori, le cui gesta figuravano spesso nei racconti di Bessie.'}},\n",
       " {'id': '575',\n",
       "  'translation': {'en': 'At last the guard returned; once more I was stowed away in the coach, my protector mounted his own seat, sounded his hollow horn, and away we rattled over the \"stony street\" of L-.',\n",
       "   'it': 'Alla fine il conduttore tornò e mi fece salire in carrozza, e poi soffiò nel corno e la carrozza partì. La sera si annunziava umida e carica di nebbia.'}},\n",
       " {'id': '576',\n",
       "  'translation': {'en': 'The afternoon came on wet and somewhat misty: as it waned into dusk, I began to feel that we were getting very far indeed from Gateshead: we ceased to pass through towns; the country changed; great grey hills heaved up round the horizon: as twilight deepened, we descended a valley, dark with wood, and long after night had overclouded the prospect, I heard a wild wind rushing amongst trees.',\n",
       "   'it': \"Non traversavamo più città; il paesaggio era cambiato. Alte montagne bigie limitavano l'orizzonte, l'oscurità aumentava più c'inoltravamo nella valle.\"}},\n",
       " {'id': '577',\n",
       "  'translation': {'en': 'Lulled by the sound, I at last dropped asleep; I had not long slumbered when the sudden cessation of motion awoke me; the coach-door was open, and a person like a servant was standing at it: I saw her face and dress by the light of the lamps.',\n",
       "   'it': 'Cullata da suoni armoniosi mi addormentai, e dormivo da un pezzo quando la scossa che fece la carrozza nel fermarsi mi destò. Davanti a me stava una donna che non conoscevo.'}},\n",
       " {'id': '578',\n",
       "  'translation': {'en': '\"Is there a little girl called Jane Eyre here?\" she asked.',\n",
       "   'it': \"— C'è qui una bimba, che si chiama Jane Eyre? — domandò.\"}},\n",
       " {'id': '579',\n",
       "  'translation': {'en': 'I answered \"Yes,\" and was then lifted out; my trunk was handed down, and the coach instantly drove away.',\n",
       "   'it': 'Ella mi fece scender subito e prese in consegna il baule. La diligenza ripartì.'}},\n",
       " {'id': '580',\n",
       "  'translation': {'en': 'I was stiff with long sitting, and bewildered with the noise and motion of the coach: Gathering my faculties, I looked about me.',\n",
       "   'it': 'Il rumore e le scosse della carrozza mi avevano sbalordita. Riunii le facoltà mentali per guardare attorno a me.'}},\n",
       " {'id': '581',\n",
       "  'translation': {'en': 'Rain, wind, and darkness filled the air; nevertheless, I dimly discerned a wall before me and a door open in it; through this door I passed with my new guide: she shut and locked it behind her.',\n",
       "   'it': 'Il vento, la pioggia e il buio riempivano lo spazio. Però potei distinguere un muro, nel quale era aperta una porta; la mia nuova guida me la fece passare, e, dopo averla chiusa dietro a sè, spinse il catenaccio.'}},\n",
       " {'id': '582',\n",
       "  'translation': {'en': 'There was now visible a house or houses--for the building spread far--with many windows, and lights burning in some; we went up a broad pebbly path, splashing wet, and were admitted at a door; then the servant led me through a passage into a room with a fire, where she left me alone.',\n",
       "   'it': 'Avevo allora davanti una casa, o, per dir meglio, una serie di case, che occupavano una vasta area. Le loro facciate eran forate da molte finestre, poche delle quali erano illuminate.'}},\n",
       " {'id': '583',\n",
       "  'translation': {'en': 'I stood and warmed my numbed fingers over the blaze, then I looked round; there was no candle, but the uncertain light from the hearth showed, by intervals, papered walls, carpet, curtains, shining mahogany furniture: it was a parlour, not so spacious or splendid as the drawing-room at Gateshead, but comfortable enough.',\n",
       "   'it': \"Non c'era lume, ma la fiamma oscillante del caminetto mi mostrava a intervalli un muro coperto di carta, dei tappeti, delle portiere, dei mobili di mogano brillante. Ero in un salotto, non così elegante come quello di Gateshead, ma che mi parve comodo e abbastanza bello.\"}},\n",
       " {'id': '584',\n",
       "  'translation': {'en': 'I was puzzling to make out the subject of a picture on the wall, when the door opened, and an individual carrying a light entered; another followed close behind.',\n",
       "   'it': 'Mi studiavo di capire che cosa rappresentasse un quadro appeso al muro, quando qualcuno entrò con un lume; dietro vi era una seconda persona.'}},\n",
       " {'id': '585',\n",
       "  'translation': {'en': 'The first was a tall lady with dark hair, dark eyes, and a pale and large forehead; her figure was partly enveloped in a shawl, her countenance was grave, her bearing erect.',\n",
       "   'it': 'La prima era una donna alta, con occhi e capelli neri, con la fronte spaziosa e pallida. Benché fosse avvolta in uno scialle, mi parve che la sua figura fosse nobile e grave il contegno.'}},\n",
       " {'id': '586',\n",
       "  'translation': {'en': '\"The child is very young to be sent alone,\" said she, putting her candle down on the table.',\n",
       "   'it': '— Questa bimba è molto piccina per esser mandata qui sola, — disse, posando il candeliere sulla tavola.'}},\n",
       " {'id': '587',\n",
       "  'translation': {'en': 'She considered me attentively for a minute or two, then further added--',\n",
       "   'it': 'Per un momento mi esaminò, poi aggiunse:'}},\n",
       " {'id': '588',\n",
       "  'translation': {'en': '\"She had better be put to bed soon; she looks tired: are you tired?\" she asked, placing her hand on my shoulder.',\n",
       "   'it': '— Bisogna metterla subito a letto; è stanca. Siete stanca, bambina? — mi domandò, posandomi la mano sulla spalla.'}},\n",
       " {'id': '589',\n",
       "  'translation': {'en': '\"A little, ma\\'am.\"', 'it': '— Un poco, signora.'}},\n",
       " {'id': '590',\n",
       "  'translation': {'en': '\"And hungry too, no doubt: let her have some supper before she goes to bed, Miss Miller.',\n",
       "   'it': '— Avete fame, certo. Prima di mandarla a letto, datele da mangiare, signorina Miller.'}},\n",
       " {'id': '591',\n",
       "  'translation': {'en': 'Is this the first time you have left your parents to come to school, my little girl?\"',\n",
       "   'it': 'È la prima volta che lasciate i vostri genitori, per venire in pensione, piccina?'}},\n",
       " {'id': '592',\n",
       "  'translation': {'en': 'I explained to her that I had no parents. She inquired how long they had been dead: then how old I was, what was my name, whether I could read, write, and sew a little: then she touched my cheek gently with her forefinger, and saying, \"She hoped I should be a good child,\" dismissed me along with Miss Miller.',\n",
       "   'it': 'Le risposi che non avevo genitori; mi domandò da quanto tempo li avevo perduti, quanti anni avevo, come mi chiamavo, se sapevo leggere e scrivere e cucire; quindi mi accarezzò dolcemente il viso, dicendo: — Spero che sarete buona, — poi mi consegnò alla signorina Miller.'}},\n",
       " {'id': '593',\n",
       "  'translation': {'en': 'The lady I had left might be about twenty-nine; the one who went with me appeared some years younger: the first impressed me by her voice, look, and air.',\n",
       "   'it': \"La giovane signora che avevo lasciato poteva avere poco meno di trent'anni; quella che mi accompagnava era un poco più giovane. La prima mi aveva colpito per l'aspetto, per la voce e per lo sguardo.\"}},\n",
       " {'id': '594',\n",
       "  'translation': {'en': 'Miss Miller was more ordinary; ruddy in complexion, though of a careworn countenance; hurried in gait and action, like one who had always a multiplicity of tasks on hand: she looked, indeed, what I afterwards found she really was, an under-teacher.',\n",
       "   'it': 'La signorina Miller era meno notevole; aveva la carnagione rossastra a macchie e il viso stanco. La camminatura e i movimenti di lei rivelavano una persona che è sopraccarica di lavoro; pareva una sottomaestra, e tale era infatti.'}},\n",
       " {'id': '595',\n",
       "  'translation': {'en': 'Led by her, I passed from compartment to compartment, from passage to passage, of a large and irregular building; till, emerging from the total and somewhat dreary silence pervading that portion of the house we had traversed, we came upon the hum of many voices, and presently entered a wide, long room, with great deal tables, two at each end, on each of which burnt a pair of candles, and seated all round on benches, a congregation of girls of every age, from nine or ten to twenty.',\n",
       "   'it': \"Ella mi condusse di stanza in stanza, di corridoio in corridoio, attraverso una vasta casa costruita irregolarmente. Un silenzio profondo, che mi sgomentava un poco, regnava in quella parte dell'istituto, che avevamo traversato.\"}},\n",
       " {'id': '596',\n",
       "  'translation': {'en': 'Seen by the dim light of the dips, their number to me appeared countless, though not in reality exceeding eighty; they were uniformly dressed in brown stuff frocks of quaint fashion, and long holland pinafores.',\n",
       "   'it': \"Attorno alle tavole, sulle panche, erano sedute tante ragazze, dai dieci ai vent'anni. Mi parvero innumerevoli, benché arrivassero appena a ottanta.\"}},\n",
       " {'id': '597',\n",
       "  'translation': {'en': \"It was the hour of study; they were engaged in conning over their to-morrow's task, and the hum I had heard was the combined result of their whispered repetitions.\",\n",
       "   'it': \"Sopra al vestito avevano lunghi grembiuli di tela. Era l'ora dello studio e tutte ripassavano la lezione per il giorno seguente.\"}},\n",
       " {'id': '598',\n",
       "  'translation': {'en': 'Miss Miller signed to me to sit on a bench near the door, then walking up to the top of the long room she cried out--',\n",
       "   'it': 'La signorina Miller mi fece cenno di sedermi su una panca, vicina alla porta, poi dirigendosi in fondo alla stanza, esclamò:'}},\n",
       " {'id': '599',\n",
       "  'translation': {'en': '\"Monitors, collect the lesson-books and put them away!\"',\n",
       "   'it': '— Monitrici, ricevete i libri di lezione e ritirateli.'}},\n",
       " {'id': '600',\n",
       "  'translation': {'en': 'Four tall girls arose from different tables, and going round, gathered the books and removed them.',\n",
       "   'it': 'Quattro ragazze grandi si alzarono, presero i libri e li riposero.'}},\n",
       " {'id': '601',\n",
       "  'translation': {'en': 'Miss Miller again gave the word of command--',\n",
       "   'it': 'La signorina Miller esclamò di nuovo:'}},\n",
       " {'id': '602',\n",
       "  'translation': {'en': '\"Monitors, fetch the supper-trays!\"',\n",
       "   'it': '— Monitrici, andate a prendere la cena.'}},\n",
       " {'id': '603',\n",
       "  'translation': {'en': 'The tall girls went out and returned presently, each bearing a tray, with portions of something, I knew not what, arranged thereon, and a pitcher of water and mug in the middle of each tray.',\n",
       "   'it': \"Le quattro ragazze uscirono e tornarono poco dopo recando un vassoio sul quale era una torta tagliata a pezzi. Nel centro era collocato un boccale e un vaso pieno d'acqua.\"}},\n",
       " {'id': '604',\n",
       "  'translation': {'en': 'The portions were handed round; those who liked took a draught of the water, the mug being common to all.',\n",
       "   'it': 'Le parti furono distribuite alle alunne, e quelle che avevano sete presero il boccale, che serviva a tutte.'}},\n",
       " {'id': '605',\n",
       "  'translation': {'en': 'When it came to my turn, I drank, for I was thirsty, but did not touch the food, excitement and fatigue rendering me incapable of eating: I now saw, however, that it was a thin oaten cake shared into fragments.',\n",
       "   'it': \"L'eccitamento e la fatica del viaggio mi avevano tolto l'appetito. Quando il vassoio mi passò davanti mi accorsi che la cosa consisteva in una torta d'avena.\"}},\n",
       " {'id': '606',\n",
       "  'translation': {'en': 'The meal over, prayers were read by Miss Miller, and the classes filed off, two and two, upstairs.',\n",
       "   'it': 'Dopo il pasto, la signorina Miller lesse la preghiera, e poi le alunne, a due a due, salirono.'}},\n",
       " {'id': '607',\n",
       "  'translation': {'en': 'Overpowered by this time with weariness, I scarcely noticed what sort of a place the bedroom was, except that, like the schoolroom, I saw it was very long.',\n",
       "   'it': \"Affranta dalla fatica com'ero, badai poco al dormitorio, ma mi parve lungo come la sala di studio.\"}},\n",
       " {'id': '608',\n",
       "  'translation': {'en': \"To-night I was to be Miss Miller's bed-fellow; she helped me to undress: when laid down I glanced at the long rows of beds, each of which was quickly filled with two occupants; in ten minutes the single light was extinguished, and amidst silence and complete darkness I fell asleep.\",\n",
       "   'it': 'Quella notte dovevo dormire con la signorina Miller, che mi aiutò a spogliarmi, e appena mi fui coricata caddi in un profondo sonno.'}},\n",
       " {'id': '609',\n",
       "  'translation': {'en': 'The night passed rapidly. I was too tired even to dream; I only once awoke to hear the wind rave in furious gusts, and the rain fall in torrents, and to be sensible that Miss Miller had taken her place by my side.',\n",
       "   'it': \"Nello svegliarmi sentii il vento muggire e l'acqua cadere a torrenti. Suonava una campana e tutte le ragazze si alzarono.\"}},\n",
       " {'id': '610',\n",
       "  'translation': {'en': 'When I again unclosed my eyes, a loud bell was ringing; the girls were up and dressing; day had not yet begun to dawn, and a rushlight or two burned in the room.',\n",
       "   'it': 'Il giorno non era ancora spuntato e un paio di lumi erano accesi nel dormitorio.'}},\n",
       " {'id': '611',\n",
       "  'translation': {'en': 'I too rose reluctantly; it was bitter cold, and I dressed as well as I could for shivering, and washed when there was a basin at liberty, which did not occur soon, as there was but one basin to six girls, on the stands down the middle of the room.',\n",
       "   'it': \"Mi alzai anch'io di mala voglia, perché era freddo, e mi vestii tremando. Quando una delle catinelle fu libera mi lavai, ma dovetti aspettare un pezzo, perché una serviva a sei.\"}},\n",
       " {'id': '612',\n",
       "  'translation': {'en': 'Again the bell rang: all formed in file, two and two, and in that order descended the stairs and entered the cold and dimly lit schoolroom: here prayers were read by Miss Miller; afterwards she called out--',\n",
       "   'it': 'Tutte le alunne si allinearono a due a due, scesero la scala ed entrarono nella sala di studio, appena illuminata. Le preghiere furono lette dalla signorina Miller, che esclamò dopo:'}},\n",
       " {'id': '613',\n",
       "  'translation': {'en': '\"Form classes!\"', 'it': '— Formate le classi!'}},\n",
       " {'id': '614',\n",
       "  'translation': {'en': 'A great tumult succeeded for some minutes, during which Miss Miller repeatedly exclaimed, \"Silence!\" and \"Order!\"',\n",
       "   'it': 'Ne nacque un certo rumore. La signorina Miller non cessava di ripetere: \"Ordine e silenzio\"'}},\n",
       " {'id': '615',\n",
       "  'translation': {'en': 'When it subsided, I saw them all drawn up in four semicircles, before four chairs, placed at the four tables; all held books in their hands, and a great book, like a Bible, lay on each table, before the vacant seat.',\n",
       "   'it': 'Quando la calma fu ristabilita, mi accorsi che le alunne erano separate in quattro gruppi. Ognuna di esse era davanti a una seggiola e ogni alunna aveva un volume in mano; un altro che presi per una Bibbia, era collocato sulla tavola, dinanzi alla sedia vuota.'}},\n",
       " {'id': '616',\n",
       "  'translation': {'en': 'A distant bell tinkled: immediately three ladies entered the room, each walked to a table and took her seat.',\n",
       "   'it': 'Il suono di una campana lontana aveva colpito le nostre orecchie, quando tre signore entrarono nella stanza.'}},\n",
       " {'id': '617',\n",
       "  'translation': {'en': 'Miss Miller assumed the fourth vacant chair, which was that nearest the door, and around which the smallest of the children were assembled: to this inferior class I was called, and placed at the bottom of it.',\n",
       "   'it': \"Ognuna di esse si sedè dinanzi a una delle tavole; la signora Miller alla quarta, presso la porta, ov'erano le piccine, fra le quali fui collocata.\"}},\n",
       " {'id': '618',\n",
       "  'translation': {'en': \"Business now began, the day's Collect was repeated, then certain texts of Scripture were said, and to these succeeded a protracted reading of chapters in the Bible, which lasted an hour.\",\n",
       "   'it': 'Il lavoro incominciò; si recitarono le lezioni del giorno e alcuni passi della Scrittura. Poi si fece una lunga lettura della Bibbia.'}},\n",
       " {'id': '619',\n",
       "  'translation': {'en': 'By the time that exercise was terminated, day had fully dawned.',\n",
       "   'it': 'Quando gli esercizi furono terminati, era giorno chiaro.'}},\n",
       " {'id': '620',\n",
       "  'translation': {'en': 'The indefatigable bell now sounded for the fourth time: the classes were marshalled and marched into another room to breakfast: how glad I was to behold a prospect of getting something to eat!',\n",
       "   'it': \"L'instancabile campana suonò per la quarta volta; le alunne si separarono di nuovo e si diressero al refettorio.\"}},\n",
       " {'id': '621',\n",
       "  'translation': {'en': 'I was now nearly sick from inanition, having taken so little the day before.',\n",
       "   'it': \"Ero contenta di poter mangiare un poco, perché il giorno avanti mi ero così poco nutrita che mi sentivo morire d'inedia.\"}},\n",
       " {'id': '622',\n",
       "  'translation': {'en': 'The refectory was a great, low-ceiled, gloomy room; on two long tables smoked basins of something hot, which, however, to my dismay, sent forth an odour far from inviting.',\n",
       "   'it': \"Sulle lunghe tavole dell'ampio refettorio fumavano due bacini, che non eccitavano davvero l'appetito.\"}},\n",
       " {'id': '623',\n",
       "  'translation': {'en': 'I saw a universal manifestation of discontent when the fumes of the repast met the nostrils of those destined to swallow it; from the van of the procession, the tall girls of the first class, rose the whispered words--',\n",
       "   'it': \"Vi fu un movimento generale di malcontento quando l'odore della pietanza giunse alle nari delle educande. Le grandi, che erano avanti, mormorarono:\"}},\n",
       " {'id': '624', 'translation': {'en': '\"Disgusting!', 'it': '— Che orrore!'}},\n",
       " {'id': '625',\n",
       "  'translation': {'en': 'The porridge is burnt again!\"',\n",
       "   'it': 'La minestra è bruciata anche oggi!'}},\n",
       " {'id': '626',\n",
       "  'translation': {'en': '\"Silence!\" ejaculated a voice; not that of Miss Miller, but one of the upper teachers, a little and dark personage, smartly dressed, but of somewhat morose aspect, who installed herself at the top of one table, while a more buxom lady presided at the other.',\n",
       "   'it': \"Chi aveva dato quell'ordine era la maestra delle grandi, donnina vestita bene, ma non simpatica. Ella si mise in cima alla prima tavola, mentre che un'altra signora, più gentile d'aspetto, presiedeva la seconda.\"}},\n",
       " {'id': '627',\n",
       "  'translation': {'en': 'I looked in vain for her I had first seen the night before; she was not visible: Miss Miller occupied the foot of the table where I sat, and a strange, foreign-looking, elderly lady, the French teacher, as I afterwards found, took the corresponding seat at the other board.',\n",
       "   'it': 'Alla mia sorvegliava la signorina Miller, e alla quarta la maestra di francese.'}},\n",
       " {'id': '628',\n",
       "  'translation': {'en': 'A long grace was said and a hymn sung; then a servant brought in some tea for the teachers, and the meal began.',\n",
       "   'it': 'Si cantò un inno, una donna portò il thè alle maestre e noi cominciammo a mangiare.'}},\n",
       " {'id': '629',\n",
       "  'translation': {'en': 'Ravenous, and now very faint, I devoured a spoonful or two of my portion without thinking of its taste; but the first edge of hunger blunted, I perceived I had got in hand a nauseous mess; burnt porridge is almost as bad as rotten potatoes; famine itself soon sickens over it.',\n",
       "   'it': 'Buttai giù qualche cucchiaiata di brodo, senza pensare al sapore che poteva avere, ma quando la fame si fu un poco calmata, mi accorsi che mangiavo una minestra disgustosa.'}},\n",
       " {'id': '630',\n",
       "  'translation': {'en': 'The spoons were moved slowly: I saw each girl taste her food and try to swallow it; but in most cases the effort was soon relinquished.',\n",
       "   'it': 'Ogni educanda si portava il cucchiaio alle labbra e poi lo posava disgustata.'}},\n",
       " {'id': '631',\n",
       "  'translation': {'en': 'Breakfast was over, and none had breakfasted. Thanks being returned for what we had not got, and a second hymn chanted, the refectory was evacuated for the schoolroom.',\n",
       "   'it': 'Allorché la colazione fu terminata, si rese grazie di ciò che non si aveva avuto e si cantò un secondo inno. Dal refettorio si passò nella sala di studio.'}},\n",
       " {'id': '632',\n",
       "  'translation': {'en': 'I was one of the last to go out, and in passing the tables, I saw one teacher take a basin of the porridge and taste it; she looked at the others; all their countenances expressed displeasure, and one of them, the stout one, whispered--',\n",
       "   'it': \"Nell'uscire vidi una maestra assaggiare la minestra, guardare le altre e la udii dire:\"}},\n",
       " {'id': '633',\n",
       "  'translation': {'en': '\"Abominable stuff!', 'it': '— Che razza di cucina!'}},\n",
       " {'id': '634',\n",
       "  'translation': {'en': 'How shameful!\"', 'it': 'È una vergogna.'}},\n",
       " {'id': '635',\n",
       "  'translation': {'en': 'A quarter of an hour passed before lessons again began, during which the schoolroom was in a glorious tumult; for that space of time it seemed to be permitted to talk loud and more freely, and they used their privilege.',\n",
       "   'it': \"Soltanto dopo un quarto d'ora ci si rimise al lavoro. In quel tempo era permesso di parlare, e tutti ne profittarono per dir male della colazione.\"}},\n",
       " {'id': '636',\n",
       "  'translation': {'en': 'Poor things! it was the sole consolation they had.',\n",
       "   'it': 'Povere creature! era quella la loro unica consolazione.'}},\n",
       " {'id': '637',\n",
       "  'translation': {'en': 'Miss Miller was now the only teacher in the room: a group of great girls standing about her spoke with serious and sullen gestures.',\n",
       "   'it': 'Non vi era di maestre altro che la signorina Miller; le grandi la circondarono parlandole con aria seria e triste.'}},\n",
       " {'id': '638',\n",
       "  'translation': {'en': 'I heard the name of Mr. Brocklehurst pronounced by some lips; at which Miss Miller shook her head disapprovingly; but she made no great effort to check the general wrath; doubtless she shared in it.',\n",
       "   'it': 'Sentii pronunziare il nome della signora Bockelhurst; la maestra scrollava la testa come se disapprovasse il discorso, ma non faceva nulla per calmare la generale indignazione, che certo divideva.'}},\n",
       " {'id': '639',\n",
       "  'translation': {'en': 'A clock in the schoolroom struck nine; Miss Miller left her circle, and standing in the middle of the room, cried--',\n",
       "   'it': 'Suonarono le nove e la signorina Miller ci ordinò di tornare ai nostri posti.'}},\n",
       " {'id': '640',\n",
       "  'translation': {'en': 'Discipline prevailed: in five minutes the confused throng was resolved into order, and comparative silence quelled the Babel clamour of tongues.',\n",
       "   'it': 'Dopo dieci minuti regnava il silenzio.'}},\n",
       " {'id': '641',\n",
       "  'translation': {'en': 'The upper teachers now punctually resumed their posts: but still, all seemed to wait.',\n",
       "   'it': 'Le maestre erano tornate; la scuola pareva in attesa di qualcosa.'}},\n",
       " {'id': '642',\n",
       "  'translation': {'en': \"Ranged on benches down the sides of the room, the eighty girls sat motionless and erect; a quaint assemblage they appeared, all with plain locks combed from their faces, not a curl visible; in brown dresses, made high and surrounded by a narrow tucker about the throat, with little pockets of holland (shaped something like a Highlander's purse) tied in front of their frocks, and destined to serve the purpose of a work-bag: all, too, wearing woollen stockings and country-made shoes, fastened with brass buckles.\",\n",
       "   'it': \"Tutte avevano i capelli lisci sulla fronte e passati dietro l'orecchio; nessun ricciolo incorniciava i loro volti; il solo ornamento era un colletto. Sul davanti dei vestiti scuri portavano cucita una tasca per il lavoro.\"}},\n",
       " {'id': '643',\n",
       "  'translation': {'en': 'Above twenty of those clad in this costume were full-grown girls, or rather young women; it suited them ill, and gave an air of oddity even to the prettiest.',\n",
       "   'it': 'Una ventina di loro erano già donne e quel vestito bizzarro le faceva parer tutte brutte.'}},\n",
       " {'id': '644',\n",
       "  'translation': {'en': 'I was still looking at them, and also at intervals examining the teachers--none of whom precisely pleased me; for the stout one was a little coarse, the dark one not a little fierce, the foreigner harsh and grotesque, and Miss Miller, poor thing! looked purple, weather-beaten, and over-worked--when, as my eye wandered from face to face, the whole school rose simultaneously, as if moved by a common spring.',\n",
       "   'it': 'Nessuna di esse mi piaceva; la grande era dura, la piccina pareva irascibile, la francese era rude e grottesca. La signorina Miller poi, così rossa in viso, pareva schiacciata sotto il peso dei pensieri.'}},\n",
       " {'id': '645',\n",
       "  'translation': {'en': 'Ere I had gathered my wits, the classes were again seated: but as all eyes were now turned to one point, mine followed the general direction, and encountered the personage who had received me last night.',\n",
       "   'it': 'Entrava allora la signora che mi aveva ricevuto la sera prima.'}},\n",
       " {'id': '646',\n",
       "  'translation': {'en': 'She stood at the bottom of the long room, on the hearth; for there was a fire at each end; she surveyed the two rows of girls silently and gravely.',\n",
       "   'it': 'Ella si fermò guardando le due linee di educande gravemente.'}},\n",
       " {'id': '647',\n",
       "  'translation': {'en': 'Miss Miller approaching, seemed to ask her a question, and having received her answer, went back to her place, and said aloud--',\n",
       "   'it': 'La signorina Miller le si avvicinò, le rivolse una domanda, e, dopo aver ricevuta la risposta, tornò al suo posto e disse:'}},\n",
       " {'id': '648',\n",
       "  'translation': {'en': '\"Monitor of the first class, fetch the globes!\"',\n",
       "   'it': '— Monitrici della prima classe, portate le sfere.'}},\n",
       " {'id': '649',\n",
       "  'translation': {'en': 'While the direction was being executed, the lady consulted moved slowly up the room. I suppose I have a considerable organ of veneration, for I retain yet the sense of admiring awe with which my eyes traced her steps.',\n",
       "   'it': \"Mentre l'ordine era eseguito, la sconosciuta passeggiava lentamente nella sala; non so se ho in me un istinto di venerazione, ma rammento ancora il rispetto col quale io seguiva i passi di lei.\"}},\n",
       " {'id': '650',\n",
       "  'translation': {'en': 'Seen now, in broad daylight, she looked tall, fair, and shapely; brown eyes with a benignant light in their irids, and a fine pencilling of long lashes round, relieved the whiteness of her large front; on each of her temples her hair, of a very dark brown, was clustered in round curls, according to the fashion of those times, when neither smooth bands nor long ringlets were in vogue; her dress, also in the mode of the day, was of purple cloth, relieved by a sort of Spanish trimming of black velvet; a gold watch (watches were not so common then as now) shone at her girdle.',\n",
       "   'it': 'Alla luce del giorno mi parve bella, alta, ben fatta; nei suoi occhi bruni brillava una viva benevolenza; i sopraccigli ben disegnati facevano risaltare la candidezza della fronte e i capelli bruni erano scalati in tanti piccoli ricci sulle tempie. Non si portavano allora né ricci lunghi, né sgonfi.'}},\n",
       " {'id': '651',\n",
       "  'translation': {'en': 'Let the reader add, to complete the picture, refined features; a complexion, if pale, clear; and a stately air and carriage, and he will have, at least, as clearly as words can give it, a correct idea of the exterior of Miss Temple--Maria Temple, as I afterwards saw the name written in a prayer-book intrusted to me to carry to church.',\n",
       "   'it': \"Il suo vestito, secondo la moda del tempo, era color porpora, con ornamenti di velluto nero frastagliato, e alla cintura le brillava un orologio d'oro, gioiello più raro allora che ora. Per completare quel ritratto occorre aggiungere che la signorina Maria Temple aveva i lineamenti fini, una carnagione pallida, ma chiara, un portamento nobile.\"}},\n",
       " {'id': '652',\n",
       "  'translation': {'en': 'The superintendent of Lowood (for such was this lady) having taken her seat before a pair of globes placed on one of the tables, summoned the first class round her, and commenced giving a lesson on geography; the lower classes were called by the teachers: repetitions in history, grammar, &c., went on for an hour; writing and arithmetic succeeded, and music lessons were given by Miss Temple to some of the elder girls.',\n",
       "   'it': \"La direttrice di Lowood si sedè davanti alla tavola su cui erano posate le sfere, e riunendo intorno a sé la prima classe, incominciò la lezione di geografia; le classi inferiori furono chiamate dalle altre maestre, e per un'ora continuarono le ripetizioni di grammatica e di storia. La lezione di musica fu data dalla signorina Temple ad alcune fra le grandi.\"}},\n",
       " {'id': '653',\n",
       "  'translation': {'en': 'The duration of each lesson was measured by the clock, which at last struck twelve.',\n",
       "   'it': \"L'orologio annunziava quando era finita l'ora, assegnata a ciascuna lezione.\"}},\n",
       " {'id': '654',\n",
       "  'translation': {'en': 'The superintendent rose--',\n",
       "   'it': 'Quando suonò mezzogiorno, la direttrice si alzò.'}},\n",
       " {'id': '655',\n",
       "  'translation': {'en': '\"I have a word to address to the pupils,\" said she.',\n",
       "   'it': \"— Ho una parola da dire alle educande di Lowood, — diss'ella.\"}},\n",
       " {'id': '656',\n",
       "  'translation': {'en': 'The tumult of cessation from lessons was already breaking forth, but it sank at her voice.',\n",
       "   'it': 'Il mormorio che seguiva ogni lezione cessò, ed ella aggiunse:'}},\n",
       " {'id': '657',\n",
       "  'translation': {'en': 'She went on-- \"You had this morning a breakfast which you could not eat; you must be hungry:--I have ordered that a lunch of bread and cheese shall be served to all.\"',\n",
       "   'it': '— Stamani avete avuta una colazione che non avete potuto mangiare; dovete aver fame, e per questo ho ordinato che vi fosse preparata una merenda di pane e formaggio.'}},\n",
       " {'id': '658',\n",
       "  'translation': {'en': 'The teachers looked at her with a sort of surprise.',\n",
       "   'it': 'Le maestre si guardarono meravigliate.'}},\n",
       " {'id': '659',\n",
       "  'translation': {'en': '\"It is to be done on my responsibility,\" she added, in an explanatory tone to them, and immediately afterwards left the room.',\n",
       "   'it': '— Mi addosso la responsabilità di una disposizione siffatta, — aggiunse come per ispiegare la sua condotta; quindi uscì dalla sala.'}},\n",
       " {'id': '660',\n",
       "  'translation': {'en': 'The bread and cheese was presently brought in and distributed, to the high delight and refreshment of the whole school.',\n",
       "   'it': 'Fu portata la merenda con gran piacere di tutta la scuola, e dopo si ebbe ordine di andare in giardino.'}},\n",
       " {'id': '661',\n",
       "  'translation': {'en': 'The order was now given \"To the garden!\" Each put on a coarse straw bonnet, with strings of coloured calico, and a cloak of grey frieze. I was similarly equipped, and, following the stream, I made my way into the open air.',\n",
       "   'it': \"Ognuna si mise in testa un cappello di paglia ordinario, fermato da nastri di cotone, e si ravvolse in un mantello di panno bigio; fui vestita come le altre, e, seguendo le compagne, giunsi all'aria aperta.\"}},\n",
       " {'id': '662',\n",
       "  'translation': {'en': 'The garden was a wide inclosure, surrounded with walls so high as to exclude every glimpse of prospect; a covered verandah ran down one side, and broad walks bordered a middle space divided into scores of little beds: these beds were assigned as gardens for the pupils to cultivate, and each bed had an owner.',\n",
       "   'it': 'Il giardino era un vasto appezzamento di terreno, circondato da muri assai alti per impedire gli sguardi indiscreti; da uno dei lati eravi un porticato. Il centro, circondato da larghi viali, era diviso in piccoli boschetti.'}},\n",
       " {'id': '663',\n",
       "  'translation': {'en': 'When full of flowers they would doubtless look pretty; but now, at the latter end of January, all was wintry blight and brown decay.',\n",
       "   'it': \"Nell'estate, quando la terra si copre di fiori, quei giardinetti dovevano esser veramente carini, ma alla fine di gennaio tutto era pallido, gelato e triste.\"}},\n",
       " {'id': '664',\n",
       "  'translation': {'en': 'I shuddered as I stood and looked round me: it was an inclement day for outdoor exercise; not positively rainy, but darkened by a drizzling yellow fog; all under foot was still soaking wet with the floods of yesterday.',\n",
       "   'it': \"Tremai guardando intorno a me. La giornata non era propizia alla ricreazione all'aria aperta, non che piovesse, ma tutto era avvolto in una fitta nebbia umidiccia.\"}},\n",
       " {'id': '665',\n",
       "  'translation': {'en': 'The stronger among the girls ran about and engaged in active games, but sundry pale and thin ones herded together for shelter and warmth in the verandah; and amongst these, as the dense mist penetrated to their shivering frames, I heard frequently the sound of a hollow cough.',\n",
       "   'it': \"La tempesta del giorno prima aveva mantenuto la terra bagnata. Le più robuste fra le educande correvano da una parte all'altra facendo esercizi violenti; alcune, pallide e magre, andavano a rifugiarsi sotto il porticato, e dai loro petti usciva spesso una tosse cavernosa.\"}},\n",
       " {'id': '666',\n",
       "  'translation': {'en': 'As yet I had spoken to no one, nor did anybody seem to take notice of me; I stood lonely enough: but to that feeling of isolation I was accustomed; it did not oppress me much.',\n",
       "   'it': \"Non avevo parlato a nessuno e nessuno pareva si accorgesse di me; ero sola, ma l'isolamento non mi pesava: vi ero assuefatta.\"}},\n",
       " {'id': '667',\n",
       "  'translation': {'en': 'I leant against a pillar of the verandah, drew my grey mantle close about me, and, trying to forget the cold which nipped me without, and the unsatisfied hunger which gnawed me within, delivered myself up to the employment of watching and thinking.',\n",
       "   'it': 'Mi appoggiai a una delle colonne del porticato, avvolgendomi nel mantello; cercavo di dimenticare il freddo e la fame che mi dilaniava. Io passavo il tempo a esaminare e a pensare; ma le mie riflessioni erano troppo vaghe e troppo spesso interrotte, per poter essere riferite.'}},\n",
       " {'id': '668',\n",
       "  'translation': {'en': 'My reflections were too undefined and fragmentary to merit record: I hardly yet knew where I was; Gateshead and my past life seemed floated away to an immeasurable distance; the present was vague and strange, and of the future I could form no conjecture.',\n",
       "   'it': \"Sapevo appena dov'ero. Gateshead e la mia vita passata fluttuavano dietro a me ad una distanza incommensurabile; il presente era vago e strano, e sul futuro non potevo far pronostici.\"}},\n",
       " {'id': '669',\n",
       "  'translation': {'en': 'I looked round the convent-like garden, and then up at the house--a large building, half of which seemed grey and old, the other half quite new.',\n",
       "   'it': \"Mi misi a guardare il giardino, che pareva quello di un convento, poi fissai la casa, una parte della quale era grigia e vecchia, mentre l'altra era nuova.\"}},\n",
       " {'id': '670',\n",
       "  'translation': {'en': 'The new part, containing the schoolroom and dormitory, was lit by mullioned and latticed windows, which gave it a church-like aspect; a stone tablet over the door bore this inscription:--',\n",
       "   'it': \"Questa parte, che conteneva la sala di studio e i dormitorii, aveva finestre tonde e munite di inferriata, che le davano l'apparenza di una chiesa. Una larga pietra, collocata sopra l'ingresso, portava questa iscrizione:\"}},\n",
       " {'id': '671',\n",
       "  'translation': {'en': '\"Lowood Institution.--This portion was rebuilt A.D. ---, by Naomi Brocklehurst, of Brocklehurst Hall, in this county.\"',\n",
       "   'it': '\"Istituzione di Lowood: questa parte è stata \"costruita da Noemi Bockelhurst, del castello di \"Bochelhurst, in questa Contea.'}},\n",
       " {'id': '672',\n",
       "  'translation': {'en': '\"Let your light so shine before men, that they may see your good works, and glorify your Father which is in heaven.\"--St.',\n",
       "   'it': '\"Che la nostra luce splenda dinanzi agli uomini \"affinchè possano vedere le vostre opere \"buone e glorificare vostro Padre che è in cielo.\"'}},\n",
       " {'id': '673',\n",
       "  'translation': {'en': 'Matt. v. 16.', 'it': '(S. Matteo, v. 16).'}},\n",
       " {'id': '674',\n",
       "  'translation': {'en': 'I read these words over and over again: I felt that an explanation belonged to them, and was unable fully to penetrate their import.',\n",
       "   'it': \"Dopo aver letto e riletto l'iscrizione capii che doveva essermi spiegata, perché da me non ne avrei afferrato il senso.\"}},\n",
       " {'id': '675',\n",
       "  'translation': {'en': 'I was still pondering the signification of \"Institution,\" and endeavouring to make out a connection between the first words and the verse of Scripture, when the sound of a cough close behind me made me turn my head.',\n",
       "   'it': \"Pensavo a quel che voleva dire istituzione e mi studiavo di trovare il rapporto che poteva esservi fra la prima parte dell'iscrizione e il versetto della Bibbia, quando una tosse cavernosa mi fece volger la testa.\"}},\n",
       " {'id': '676',\n",
       "  'translation': {'en': 'I saw a girl sitting on a stone bench near; she was bent over a book, on the perusal of which she seemed intent: from where I stood I could see the title--it was \"Rasselas;\" a name that struck me as strange, and consequently attractive.',\n",
       "   'it': 'Scórsi allora una ragazza seduta a poca distanza da me su una panchina; ella teneva fra le mani un libro, che pareva assorbire tutta la sua attenzione. Lessi il titolo: era Rasselas.'}},\n",
       " {'id': '677',\n",
       "  'translation': {'en': 'In turning a leaf she happened to look up, and I said to her directly--',\n",
       "   'it': 'Volgendo una pagina, la ragazza alzò gli occhi, e ne profittai per parlarle.'}},\n",
       " {'id': '678',\n",
       "  'translation': {'en': '\"Is your book interesting?\" I had already formed the intention of asking her to lend it to me some day.',\n",
       "   'it': '— Vi diverte codesto libro? — le domandai.'}},\n",
       " {'id': '679',\n",
       "  'translation': {'en': '\"I like it,\" she answered, after a pause of a second or two, during which she examined me.',\n",
       "   'it': '— Mi piace, — risposemi.'}},\n",
       " {'id': '680',\n",
       "  'translation': {'en': '\"What is it about?\" I continued.',\n",
       "   'it': '— Di che cosa parla?'}},\n",
       " {'id': '681',\n",
       "  'translation': {'en': 'I hardly know where I found the hardihood thus to open a conversation with a stranger; the step was contrary to my nature and habits: but I think her occupation touched a chord of sympathy somewhere; for I too liked reading, though of a frivolous and childish kind; I could not digest or comprehend the serious or substantial.',\n",
       "   'it': \"Non potevo capire come mai io avessi la sfacciataggine d'intavolar discorso con una sconosciuta, contrariamente alla mia indole. L'occupazione, in cui l'avevo trovata assorta, aveva certo fatto vibrare nel mio cuore una corda sensibile.\"}},\n",
       " {'id': '682',\n",
       "  'translation': {'en': '\"You may look at it,\" replied the girl, offering me the book.',\n",
       "   'it': '— Volete vederlo? — mi disse la sconosciuta offrendomi il libro.'}},\n",
       " {'id': '683',\n",
       "  'translation': {'en': 'I did so; a brief examination convinced me that the contents were less taking than the title: \"Rasselas\" looked dull to my trifling taste; I saw nothing about fairies, nothing about genii; no bright variety seemed spread over the closely-printed pages.',\n",
       "   'it': 'Fui convinta da un rapido esame, che il contenuto era meno interessante del titolo, e, non vedendovi rappresentati né genii, né fate, glielo resi.'}},\n",
       " {'id': '684',\n",
       "  'translation': {'en': 'I returned it to her; she received it quietly, and without saying anything she was about to relapse into her former studious mood: again I ventured to disturb her--',\n",
       "   'it': 'Ella lo riprese senza dirmi nulla, e stava per rimettersi a leggere, quando la interruppi di nuovo.'}},\n",
       " {'id': '685',\n",
       "  'translation': {'en': '\"Can you tell me what the writing on that stone over the door means?',\n",
       "   'it': \"— Potete dirmi, — le domandai, — che cosa significa l'iscrizione incisa su quella pietra?\"}},\n",
       " {'id': '686',\n",
       "  'translation': {'en': 'What is Lowood Institution?\"',\n",
       "   'it': \"Che cos'è l'istituzione di Lowood?\"}},\n",
       " {'id': '687',\n",
       "  'translation': {'en': '\"This house where you are come to live.\"',\n",
       "   'it': '— È la casa dove siete venuta ad abitare.'}},\n",
       " {'id': '688',\n",
       "  'translation': {'en': '\"And why do they call it Institution?',\n",
       "   'it': '— Perché si chiama istituzione?'}},\n",
       " {'id': '689',\n",
       "  'translation': {'en': 'Is it in any way different from other schools?\"',\n",
       "   'it': 'Che è forse diversa dalle altre scuole?'}},\n",
       " {'id': '690',\n",
       "  'translation': {'en': '\"It is partly a charity-school: you and I, and all the rest of us, are charity-children.',\n",
       "   'it': '— È in parte una scuola di beneficenza.'}},\n",
       " {'id': '691',\n",
       "  'translation': {'en': 'I suppose you are an orphan: are not either your father or your mother dead?\"',\n",
       "   'it': 'Voi, io e tutte le altre siamo figlie della carità. Dovete essere orfana.'}},\n",
       " {'id': '692',\n",
       "  'translation': {'en': '\"Both died before I can remember.\"',\n",
       "   'it': '— Difatti di mio padre e di mia madre non mi ricordo neppure.'}},\n",
       " {'id': '693',\n",
       "  'translation': {'en': '\"Well, all the girls here have lost either one or both parents, and this is called an institution for educating orphans.\"',\n",
       "   'it': \"— Ebbene, tutte le ragazze che vedete qui hanno perduto almeno uno dei genitori, ed ecco la ragione che fa dare alla scuola il nome d'istituzione per l'educazione delle orfane.\"}},\n",
       " {'id': '694',\n",
       "  'translation': {'en': '\"Do we pay no money? Do they keep us for nothing?\"',\n",
       "   'it': '— Paghiamo, o siamo educate gratuitamente?'}},\n",
       " {'id': '695',\n",
       "  'translation': {'en': '\"We pay, or our friends pay, fifteen pounds a year for each.\"',\n",
       "   'it': \"— Noi paghiamo o i nostri amici pagano quindici sterline l'anno.\"}},\n",
       " {'id': '696',\n",
       "  'translation': {'en': '\"Then why do they call us charity-children?\"',\n",
       "   'it': '— Allora perché ci chiamano le figlie della carità?'}},\n",
       " {'id': '697',\n",
       "  'translation': {'en': '\"Because fifteen pounds is not enough for board and teaching, and the deficiency is supplied by subscription.\"',\n",
       "   'it': '— Perché la somma che paghiamo non basta alle spese per il nostro mantenimento e per la nostra educazione; ciò che manca è fornito dai soscrittori.'}},\n",
       " {'id': '698',\n",
       "  'translation': {'en': '\"Who subscribes?\"', 'it': '— E chi sono essi?'}},\n",
       " {'id': '699',\n",
       "  'translation': {'en': '\"Different benevolent-minded ladies and gentlemen in this neighbourhood and in London.\"',\n",
       "   'it': '— Alcune persone caritatevoli dei dintorni e anche di Londra.'}},\n",
       " {'id': '700',\n",
       "  'translation': {'en': '\"Who was Naomi Brocklehurst?\"',\n",
       "   'it': '— E chi è quella Noemi Bockelhurst?'}},\n",
       " {'id': '701',\n",
       "  'translation': {'en': '\"The lady who built the new part of this house as that tablet records, and whose son overlooks and directs everything here.\"',\n",
       "   'it': \"— La signora che ha costruita la parte nuova della casa, come indica l'iscrizione. Suo figlio ha ora la direzione generale della scuola.\"}},\n",
       " {'id': '702', 'translation': {'en': '\"Why?\"', 'it': '— Perché?'}},\n",
       " {'id': '703',\n",
       "  'translation': {'en': '\"Because he is treasurer and manager of the establishment.\"',\n",
       "   'it': '— Perché è tesoriere e capo dello stabilimento.'}},\n",
       " {'id': '704',\n",
       "  'translation': {'en': '\"Then this house does not belong to that tall lady who wears a watch, and who said we were to have some bread and cheese?\"',\n",
       "   'it': \"— Allora la casa non appartiene a quella signora che ha un orologio d'oro e che ci ha fatto dar la merenda?\"}},\n",
       " {'id': '705',\n",
       "  'translation': {'en': '\"To Miss Temple? Oh, no!',\n",
       "   'it': '— La signorina Temple è soltanto la direttrice; ma vorrei che le appartenesse.'}},\n",
       " {'id': '706',\n",
       "  'translation': {'en': 'I wish it did: she has to answer to Mr. Brocklehurst for all she does.',\n",
       "   'it': 'Ella deve dar conto di tutto al signor Bockelhurst.'}},\n",
       " {'id': '707',\n",
       "  'translation': {'en': 'Mr. Brocklehurst buys all our food and all our clothes.\"',\n",
       "   'it': 'È lui che compra il vitto e i vestiti.'}},\n",
       " {'id': '708',\n",
       "  'translation': {'en': '\"Does he live here?\"', 'it': '— E abita qui?'}},\n",
       " {'id': '709',\n",
       "  'translation': {'en': '\"No--two miles off, at a large hall.\"',\n",
       "   'it': '— No; abita una villa distante mezza lega da Lowood.'}},\n",
       " {'id': '710',\n",
       "  'translation': {'en': '\"Is he a good man?\"', 'it': '— È buono?'}},\n",
       " {'id': '711',\n",
       "  'translation': {'en': '\"He is a clergyman, and is said to do a great deal of good.\"',\n",
       "   'it': '— È un pastore, e si dice che faccia molto bene.'}},\n",
       " {'id': '712',\n",
       "  'translation': {'en': '\"And what are the other teachers called?\"',\n",
       "   'it': '— Come si chiamano le altre maestre?'}},\n",
       " {'id': '713',\n",
       "  'translation': {'en': '\"The one with red cheeks is called Miss Smith; she attends to the work, and cuts out--for we make our own clothes, our frocks, and pelisses, and everything; the little one with black hair is Miss Scatcherd; she teaches history and grammar, and hears the second class repetitions; and the one who wears a shawl, and has a pocket-handkerchief tied to her side with a yellow ribband, is Madame Pierrot: she comes from Lisle, in France, and teaches French.\"',\n",
       "   'it': 'Dà lezioni di storia e di geografia e fa ripetizione alla seconda classe. Quella infine che vedete ravvolta nello scialle e che porta il fazzoletto legato da un lato, con un nastro giallo, è la signora Pierrot; viene da Lille e insegna il francese.'}},\n",
       " {'id': '714',\n",
       "  'translation': {'en': '\"Do you like the teachers?\"',\n",
       "   'it': '— Volete bene alle maestre?'}},\n",
       " {'id': '715', 'translation': {'en': '\"Well enough.\"', 'it': '— Abbastanza.'}},\n",
       " {'id': '716',\n",
       "  'translation': {'en': '\"Do you like the little black one, and the Madame ---?--I cannot pronounce her name as you do.\"',\n",
       "   'it': '— Volete bene alla piccina, che ha i capelli neri, e alla signora.... non so pronunziarne il nome come voi.'}},\n",
       " {'id': '717',\n",
       "  'translation': {'en': '\"Miss Scatcherd is hasty--you must take care not to offend her; Madame Pierrot is not a bad sort of person.\"',\n",
       "   'it': '— La signorina Scatcherd è impetuosa e bisogna fare attenzione di non ferirla. La signora Pierrot è abbastanza buona.'}},\n",
       " {'id': '718',\n",
       "  'translation': {'en': '\"But Miss Temple is the best--isn\\'t she?\"',\n",
       "   'it': '— Ma la direttrice è la migliore, non è vero?'}},\n",
       " {'id': '719',\n",
       "  'translation': {'en': '\"Miss Temple is very good and very clever; she is above the rest, because she knows far more than they do.\"',\n",
       "   'it': '— Oh! la signorina Temple è buonissima, sa molto ed è superiore a tutte le maestre, perché è più istruita di tutte.'}},\n",
       " {'id': '720',\n",
       "  'translation': {'en': '\"Have you been long here?\"',\n",
       "   'it': '— È da molto tempo che siete qui?'}},\n",
       " {'id': '721', 'translation': {'en': '\"Two years.\"', 'it': '— Due anni.'}},\n",
       " {'id': '722',\n",
       "  'translation': {'en': '\"Are you an orphan?\"', 'it': '— Siete orfana?'}},\n",
       " {'id': '723',\n",
       "  'translation': {'en': '\"My mother is dead.\"', 'it': '— Mia madre è morta.'}},\n",
       " {'id': '724',\n",
       "  'translation': {'en': '\"Are you happy here?\"',\n",
       "   'it': '— Vi state volentieri?'}},\n",
       " {'id': '725',\n",
       "  'translation': {'en': '\"You ask rather too many questions.',\n",
       "   'it': '— Mi fate troppe domande; per oggi basta: vorrei leggere un poco.'}},\n",
       " {'id': '726',\n",
       "  'translation': {'en': 'I have given you answers enough for the present: now I want to read.\"',\n",
       "   'it': 'Ma in quel momento la campana del desinare ci fece entrar tutte in casa.'}},\n",
       " {'id': '727',\n",
       "  'translation': {'en': 'But at that moment the summons sounded for dinner; all re-entered the house.',\n",
       "   'it': \"L'odore che empiva il refettorio era appena appena più appetitoso di quello della colazione.\"}},\n",
       " {'id': '728',\n",
       "  'translation': {'en': 'The odour which now filled the refectory was scarcely more appetising than that which had regaled our nostrils at breakfast: the dinner was served in two huge tin-plated vessels, whence rose a strong steam redolent of rancid fat.',\n",
       "   'it': 'Le pietanze furono servite in due larghi vassoi di stagno, dai quali esalava un gran puzzo di grasso rancido.'}},\n",
       " {'id': '729',\n",
       "  'translation': {'en': 'I found the mess to consist of indifferent potatoes and strange shreds of rusty meat, mixed and cooked together.',\n",
       "   'it': 'Il desinare si componeva di patate, che non sapevan di nulla, e di carne che sapeva di troppo.'}},\n",
       " {'id': '730',\n",
       "  'translation': {'en': 'Of this preparation a tolerably abundant plateful was apportioned to each pupil.',\n",
       "   'it': 'Ogni alunna ebbe una porzione assai abbondante.'}},\n",
       " {'id': '731',\n",
       "  'translation': {'en': \"I ate what I could, and wondered within myself whether every day's fare would be like this.\",\n",
       "   'it': 'Mangiai quello che potei, chiedendomi se tutti i giorni ci avrebbero dato lo stesso.'}},\n",
       " {'id': '732',\n",
       "  'translation': {'en': \"After dinner, we immediately adjourned to the schoolroom: lessons recommenced, and were continued till five o'clock.\",\n",
       "   'it': 'Dopo desinare passammo subito nella sala di studio; le lezioni ricominciarono per durare fino alle cinque.'}},\n",
       " {'id': '733',\n",
       "  'translation': {'en': 'The only marked event of the afternoon was, that I saw the girl with whom I had conversed in the verandah dismissed in disgrace by Miss Scatcherd from a history class, and sent to stand in the middle of the large schoolroom.',\n",
       "   'it': \"Il solo avvenimento notevole del pomeriggio fu il vedere che l'educanda, con la quale avevo parlato la mattina, venne mandata via dalla signorina Scatcherd dalla lezione di storia, senza che ne sapessi il motivo, e condannata a stare in mezzo alla sala.\"}},\n",
       " {'id': '734',\n",
       "  'translation': {'en': 'The punishment seemed to me in a high degree ignominious, especially for so great a girl--she looked thirteen or upwards.',\n",
       "   'it': 'Quella punizione mi parve molto umiliante, specialmente per una ragazza di tredici o quattordici anni, come lei.'}},\n",
       " {'id': '735',\n",
       "  'translation': {'en': 'I expected she would show signs of great distress and shame; but to my surprise she neither wept nor blushed: composed, though grave, she stood, the central mark of all eyes.',\n",
       "   'it': 'Mi aspettavo di vederla dar segni di dolore e di vergogna, ma con mia grande meraviglia non pianse né arrossì. Calma e grave, ella rimase esposta agli sguardi di tutti.'}},\n",
       " {'id': '736',\n",
       "  'translation': {'en': '\"How can she bear it so quietly--so firmly?\" I asked of myself. \"Were I in her place, it seems to me I should wish the earth to open and swallow me up.',\n",
       "   'it': \"Pensavo che, se fossi stata al suo posto, avrei desiderato che la terra m'inghiottisse!\"}},\n",
       " {'id': '737',\n",
       "  'translation': {'en': 'She looks as if she were thinking of something beyond her punishment--beyond her situation: of something not round her nor before her.',\n",
       "   'it': 'Ma pareva che ella pensasse a qualcosa che non era il suo castigo, qualcosa che non era la sua triste situazione, a qualcosa che non era attorno a lei, né davanti a lei.'}},\n",
       " {'id': '738',\n",
       "  'translation': {'en': 'I have heard of day-dreams--is she in a day-dream now?',\n",
       "   'it': 'Avevo sentito parlare di persone che sognano a occhi aperti: sognava forse?'}},\n",
       " {'id': '739',\n",
       "  'translation': {'en': 'Her eyes are fixed on the floor, but I am sure they do not see it--her sight seems turned in, gone down into her heart: she is looking at what she can remember, I believe; not at what is really present.',\n",
       "   'it': 'Il suo sguardo era fisso in terra, ma sono sicura che non la vedeva; pareva che lo sguardo di lei scrutasse il suo proprio cuore, che fosse fisso nei ricordi, ma in ciò che era realmente presente.'}},\n",
       " {'id': '740',\n",
       "  'translation': {'en': 'I wonder what sort of a girl she is--whether good or naughty.\"',\n",
       "   'it': 'Quella ragazza era un enigma per me, e non sapevo se fosse buona o cattiva.'}},\n",
       " {'id': '741',\n",
       "  'translation': {'en': 'Soon after five p.m. we had another meal, consisting of a small mug of coffee, and half-a-slice of brown bread.',\n",
       "   'it': 'Alle cinque ci portarono di nuovo da mangiare. Questo pasto consisteva in una tazza di caffè e in un pezzetto di pane nero.'}},\n",
       " {'id': '742',\n",
       "  'translation': {'en': 'I devoured my bread and drank my coffee with relish; but I should have been glad of as much more--I was still hungry.',\n",
       "   'it': 'Bevvi il caffè e divorai il pane, ma avrei mangiato di più, perché avevo sempre fame.'}},\n",
       " {'id': '743',\n",
       "  'translation': {'en': \"Half-an-hour's recreation succeeded, then study; then the glass of water and the piece of oat-cake, prayers, and bed.\",\n",
       "   'it': \"Dopo avemmo mezz'ora di ricreazione, poi di nuovo lo studio; finalmente il bicchier d'acqua e la fetta di torta d'avena, la preghiera, e tutte andammo a letto.\"}},\n",
       " {'id': '744',\n",
       "  'translation': {'en': 'Such was my first day at Lowood.',\n",
       "   'it': 'Così passai il primo giorno a Lowood.'}},\n",
       " {'id': '745', 'translation': {'en': 'CHAPTER VI', 'it': 'VI.'}},\n",
       " {'id': '746',\n",
       "  'translation': {'en': 'The next day commenced as before, getting up and dressing by rushlight; but this morning we were obliged to dispense with the ceremony of washing; the water in the pitchers was frozen.',\n",
       "   'it': \"Il giorno seguente incominciò nella stessa maniera che il primo; ci levammo, ci vestimmo senza lume, ma quella mattina fummo dispensate dal lavarci, perché l'acqua era gelata nelle catinelle.\"}},\n",
       " {'id': '747',\n",
       "  'translation': {'en': 'A change had taken place in the weather the preceding evening, and a keen north-east wind, whistling through the crevices of our bedroom windows all night long, had made us shiver in our beds, and turned the contents of the ewers to ice.',\n",
       "   'it': \"La sera avanti c'era stato un cambiamento di temperatura, e il vento di nord-est, soffiando tutta la notte attraverso le fessure delle finestre, ci aveva fatto tremare nei nostri letti e aveva gelato l'acqua.\"}},\n",
       " {'id': '748',\n",
       "  'translation': {'en': 'Before the long hour and a half of prayers and Bible-reading was over, I felt ready to perish with cold.',\n",
       "   'it': \"Prima che l'ora e mezzo destinata alla preghiera e alla lettura della Bibbia fosse trascorsa, io mi sentivo morire di freddo.\"}},\n",
       " {'id': '749',\n",
       "  'translation': {'en': 'Breakfast-time came at last, and this morning the porridge was not burnt; the quality was eatable, the quantity small.',\n",
       "   'it': 'La colazione giunse in fine e la mia parte parvemi scarsa; ne avrei mangiato il doppio.'}},\n",
       " {'id': '750',\n",
       "  'translation': {'en': 'How small my portion seemed! I wished it had been doubled.',\n",
       "   'it': 'Quel giorno fui arruolata nella quarta classe e mi dettero da studiare.'}},\n",
       " {'id': '751',\n",
       "  'translation': {'en': 'In the course of the day I was enrolled a member of the fourth class, and regular tasks and occupations were assigned me: hitherto, I had only been a spectator of the proceedings at Lowood; I was now to become an actor therein.',\n",
       "   'it': 'Fino a quel momento ero stata spettatrice a Lowood; ora divenivo attrice.'}},\n",
       " {'id': '752',\n",
       "  'translation': {'en': \"At first, being little accustomed to learn by heart, the lessons appeared to me both long and difficult; the frequent change from task to task, too, bewildered me; and I was glad when, about three o'clock in the afternoon, Miss Smith put into my hands a border of muslin two yards long, together with needle, thimble, &c., and sent me to sit in a quiet corner of the schoolroom, with directions to hem the same.\",\n",
       "   'it': \"Siccome ero poco assuefatta a imparare a mente, da principio le lezioni mi parvero lunghe e difficili; il passaggio continuo da uno studio a un altro m'imbrogliava; così fui ben felice quando verso le tre del dopopranzo la signorina Smith mi consegnò una striscia di mussolina, lunga due metri, ditale e aghi, e mandandomi in un angolo mi ordinò di orlarla.\"}},\n",
       " {'id': '753',\n",
       "  'translation': {'en': \"At that hour most of the others were sewing likewise; but one class still stood round Miss Scatcherd's chair reading, and as all was quiet, the subject of their lessons could be heard, together with the manner in which each girl acquitted herself, and the animadversions or commendations of Miss Scatcherd on the performance.\",\n",
       "   'it': \"Quasi tutte cucivano in quell'ora, eccetto alcune alunne che leggevano a voce alta attorno alla sedia della signorina Scatcherd.\"}},\n",
       " {'id': '754',\n",
       "  'translation': {'en': 'It was English history: among the readers I observed my acquaintance of the verandah: at the commencement of the lesson, her place had been at the top of the class, but for some error of pronunciation, or some inattention to stops, she was suddenly sent to the very bottom.',\n",
       "   'it': \"Esse leggevano la storia d'Inghilterra, e fra le lettrici riconobbi la ragazza con cui avevo parlato nel porticato. Al principio della lezione ella era in prima fila; ma per qualche errore di pronunzia, o per non essersi fermata quando doveva, fu mandata in fondo alla stanza, e la signorina Scatcherd continuò a perseguitarla anche laggiù con le sue incessanti osservazioni.\"}},\n",
       " {'id': '755',\n",
       "  'translation': {'en': 'Even in that obscure position, Miss Scatcherd continued to make her an object of constant notice: she was continually addressing to her such phrases as the following:--',\n",
       "   'it': \"Ella si voltava sempre verso l'educanda per dirle:\"}},\n",
       " {'id': '756',\n",
       "  'translation': {'en': '\"Burns\" (such it seems was her name: the girls here were all called by their surnames, as boys are elsewhere), \"Burns, you are standing on the side of your shoe; turn your toes out immediately.\"',\n",
       "   'it': '— Burns, tenete male un piede; raddrizzatelo subito.... Burns, piegate il mento in modo sconcio; smettete subito....'}},\n",
       " {'id': '757',\n",
       "  'translation': {'en': '\"Burns, you poke your chin most unpleasantly; draw it in.\" \"Burns, I insist on your holding your head up; I will not have you before me in that attitude,\" &c. &c.',\n",
       "   'it': \"Burns, vi ho detto di tener la testa diritta; non voglio vedervi davanti a me in quell'atteggiamento.\"}},\n",
       " {'id': '758',\n",
       "  'translation': {'en': 'A chapter having been read through twice, the books were closed and the girls examined.',\n",
       "   'it': \"Quando il capitolo fu letto due volte, vennero chiusi i libri e l'interrogatorio cominciò.\"}},\n",
       " {'id': '759',\n",
       "  'translation': {'en': 'The lesson had comprised part of the reign of Charles I., and there were sundry questions about tonnage and poundage and ship- money, which most of them appeared unable to answer; still, every little difficulty was solved instantly when it reached Burns: her memory seemed to have retained the substance of the whole lesson, and she was ready with answers on every point.',\n",
       "   'it': \"La lezione comprendeva una parte del regno di Carlo I; vi furono diverse domande sul tonnellaggio, sull'imposta e il diritto pagato dai bastimenti, alle quali molte alunne non sapevano rispondere; ma tutte quelle piccole difficoltà erano subito risolte appena era interrogata la Burns; pareva che la sua mente avesse ritenuta tutta la lezione, e sapeva rispondere ad ogni domanda.\"}},\n",
       " {'id': '760',\n",
       "  'translation': {'en': 'I kept expecting that Miss Scatcherd would praise her attention; but, instead of that, she suddenly cried out--',\n",
       "   'it': 'Mi aspettavo che la signorina Scatcherd le facesse una lode, invece la sentii gridare a un tratto:'}},\n",
       " {'id': '761',\n",
       "  'translation': {'en': '\"You dirty, disagreeable girl! you have never cleaned your nails this morning!\"',\n",
       "   'it': '— Ditemi perché non vi siete pulite le unghie, porcellina insopportabile?'}},\n",
       " {'id': '762',\n",
       "  'translation': {'en': 'Burns made no answer: I wondered at her silence.',\n",
       "   'it': 'La ragazza non rispose, e io fui meravigliata del suo silenzio.'}},\n",
       " {'id': '763',\n",
       "  'translation': {'en': '\"Why,\" thought I, \"does she not explain that she could neither clean her nails nor wash her face, as the water was frozen?\"',\n",
       "   'it': \"— Perché, — pensavo, — non le dice che non ha potuto lavarsi stamani, essendo l'acqua gelata?\"}},\n",
       " {'id': '764',\n",
       "  'translation': {'en': \"My attention was now called off by Miss Smith desiring me to hold a skein of thread: while she was winding it, she talked to me from time to time, asking whether I had ever been at school before, whether I could mark, stitch, knit, &c.; till she dismissed me, I could not pursue my observations on Miss Scatcherd's movements.\",\n",
       "   'it': 'Ma in quel momento la signorina Smith, pregandomi di reggerle una matassa di filo, distrasse la mia attenzione. Mentre che aggomitolava, parlavami di tanto in tanto domandandomi se ero stata in pensione, se sapevo marcare, cucire e far la calza.'}},\n",
       " {'id': '765',\n",
       "  'translation': {'en': 'When I returned to my seat, that lady was just delivering an order of which I did not catch the import; but Burns immediately left the class, and going into the small inner room where the books were kept, returned in half a minute, carrying in her hand a bundle of twigs tied together at one end.',\n",
       "   'it': \"Quando tornai al mio posto, la signorina Scatcherd aveva dato un ordine di cui non capii l'importanza, ma vidi Burns uscir subito dalla sala, andare in uno stanzino dove si tenevano i libri e tornare con un pacco di verghe legate insieme.\"}},\n",
       " {'id': '766',\n",
       "  'translation': {'en': 'This ominous tool she presented to Miss Scatcherd with a respectful curtesy; then she quietly, and without being told, unloosed her pinafore, and the teacher instantly and sharply inflicted on her neck a dozen strokes with the bunch of twigs.',\n",
       "   'it': 'Ella presentò con rispetto il fatale strumento alla signorina Scatcherd, poi, senza averne avuto ordine, si sciolse il grembiule, e la maestra le dette subito dodici colpi sulle spalle con il fascio di verghe.'}},\n",
       " {'id': '767',\n",
       "  'translation': {'en': \"Not a tear rose to Burns' eye; and, while I paused from my sewing, because my fingers quivered at this spectacle with a sentiment of unavailing and impotent anger, not a feature of her pensive face altered its ordinary expression.\",\n",
       "   'it': 'Nessuna lagrima comparve sugli occhi di Burns, mentre io aveva terminato di cucire, perché le dita mi tremavano a quello spettacolo, ed ero agitata da una collera impotente.'}},\n",
       " {'id': '768',\n",
       "  'translation': {'en': '\"Hardened girl!\" exclaimed Miss Scatcherd; \"nothing can correct you of your slatternly habits: carry the rod away.\"',\n",
       "   'it': '— Testarda! — esclamò la signorina Scatcherd, — nulla dunque può correggervi di questo disordine? Riportate queste verghe.'}},\n",
       " {'id': '769',\n",
       "  'translation': {'en': 'Burns obeyed: I looked at her narrowly as she emerged from the book-closet; she was just putting back her handkerchief into her pocket, and the trace of a tear glistened on her thin cheek.',\n",
       "   'it': 'Burns obbedì. La guardavo furtivamente; nel momento in cui usciva dalla stanza ripose il fazzoletto in tasca; la traccia di una lagrima brillavale sulle guance scarne.'}},\n",
       " {'id': '770',\n",
       "  'translation': {'en': \"The play-hour in the evening I thought the pleasantest fraction of the day at Lowood: the bit of bread, the draught of coffee swallowed at five o'clock had revived vitality, if it had not satisfied hunger: the long restraint of the day was slackened; the schoolroom felt warmer than in the morning--its fires being allowed to burn a little more brightly, to supply, in some measure, the place of candles, not yet introduced: the ruddy gloaming, the licensed uproar, the confusion of many voices gave one a welcome sense of liberty.\",\n",
       "   'it': 'Il caffè e il pane, distribuiti alle cinque, senza calmare la fame, rianimavano la vitalità; cessava il lungo ritegno, la sala era più calda che la mattina, si alimentava meglio il fuoco per supplire alle candele non ancora accese. La pallida luce del caminetto, il rumore permesso, il vocìo, tutto insomma destava in noi una dolce sensazione di libertà.'}},\n",
       " {'id': '771',\n",
       "  'translation': {'en': 'On the evening of the day on which I had seen Miss Scatcherd flog her pupil, Burns, I wandered as usual among the forms and tables and laughing groups without a companion, yet not feeling lonely: when I passed the windows, I now and then lifted a blind, and looked out; it snowed fast, a drift was already forming against the lower panes; putting my ear close to the window, I could distinguish from the gleeful tumult within, the disconsolate moan of the wind outside.',\n",
       "   'it': 'La sera di quel giorno io passeggiava fra i gruppi allegri, senza una compagna, eppure non mi sentivo isolata.'}},\n",
       " {'id': '772',\n",
       "  'translation': {'en': 'Probably, if I had lately left a good home and kind parents, this would have been the hour when I should most keenly have regretted the separation; that wind would then have saddened my heart; this obscure chaos would have disturbed my peace! as it was, I derived from both a strange excitement, and reckless and feverish, I wished the wind to howl more wildly, the gloom to deepen to darkness, and the confusion to rise to clamour.',\n",
       "   'it': \"Forse, se avessi lasciato una casa cara e buoni parenti, in quel momento sarei stata disperata, ma non provavo nessun rammarico. Saltando le panche e strisciando sotto le tavole, giunsi al caminetto e m'inginocchiai davanti al fuoco.\"}},\n",
       " {'id': '773',\n",
       "  'translation': {'en': '\"Is it still \\'Rasselas\\'?\" I asked, coming behind her.',\n",
       "   'it': '— È sempre Rasselas? — le domandai.'}},\n",
       " {'id': '774',\n",
       "  'translation': {'en': '\"Yes,\" she said, \"and I have just finished it.\"',\n",
       "   'it': \"— Sì, l'ho quasi finito.\"}},\n",
       " {'id': '775',\n",
       "  'translation': {'en': 'And in five minutes more she shut it up. I was glad of this.',\n",
       "   'it': 'Difatti dopo cinque minuti chiuse il libro con mia soddisfazione.'}},\n",
       " {'id': '776',\n",
       "  'translation': {'en': '\"Now,\" thought I, \"I can perhaps get her to talk.\" I sat down by her on the floor.',\n",
       "   'it': '— Ora, — pensai, — vorrà parlare un poco con me, — e mi sedei davanti a lei per terra.'}},\n",
       " {'id': '777',\n",
       "  'translation': {'en': '\"What is your name besides Burns?\"',\n",
       "   'it': '— Quale è il vostro nome di battesimo?'}},\n",
       " {'id': '778', 'translation': {'en': '\"Helen.\"', 'it': '— Elena.'}},\n",
       " {'id': '779',\n",
       "  'translation': {'en': '\"Do you come a long way from here?\"',\n",
       "   'it': '— Venite di lontano?'}},\n",
       " {'id': '780',\n",
       "  'translation': {'en': '\"I come from a place farther north, quite on the borders of Scotland.\"',\n",
       "   'it': '— Vengo da un paese del nord, vicino alla Scozia.'}},\n",
       " {'id': '781',\n",
       "  'translation': {'en': '\"Will you ever go back?\"', 'it': '— Ci tornerete?'}},\n",
       " {'id': '782',\n",
       "  'translation': {'en': '\"I hope so; but nobody can be sure of the future.\"',\n",
       "   'it': \"— Lo spero, ma nessuno è sicuro dell'avvenire.\"}},\n",
       " {'id': '783',\n",
       "  'translation': {'en': '\"You must wish to leave Lowood?\"',\n",
       "   'it': '— Dovete desiderare di andarvene di qui?'}},\n",
       " {'id': '784',\n",
       "  'translation': {'en': '\"No! why should I?',\n",
       "   'it': '— No; perché lo desidererei?'}},\n",
       " {'id': '785',\n",
       "  'translation': {'en': 'I was sent to Lowood to get an education; and it would be of no use going away until I have attained that object.\"',\n",
       "   'it': \"Sono stata mandata a Lowood per istruirmi; che ci guadagnerei andandomene senza aver compiuta l'istruzione?\"}},\n",
       " {'id': '786',\n",
       "  'translation': {'en': '\"But that teacher, Miss Scatcherd, is so cruel to you?\" \"Cruel?',\n",
       "   'it': '— Ma la signorina Scatcherd è così crudele con voi!...'}},\n",
       " {'id': '787',\n",
       "  'translation': {'en': 'Not at all! She is severe: she dislikes my faults.\"',\n",
       "   'it': '— Crudele no; ella aborre i miei difetti.'}},\n",
       " {'id': '788',\n",
       "  'translation': {'en': '\"And if I were in your place I should dislike her; I should resist her. If she struck me with that rod, I should get it from her hand; I should break it under her nose.\"',\n",
       "   'it': '— Se fossi in voi, la odierei; le resisterei, e, se mi battesse con le verghe, gliele strapperei di mano, e gliele romperei sul viso!'}},\n",
       " {'id': '789',\n",
       "  'translation': {'en': '\"Probably you would do nothing of the sort: but if you did, Mr. Brocklehurst would expel you from the school; that would be a great grief to your relations.',\n",
       "   'it': '— È probabile di no, ma, se lo faceste, il signor Bockelhurst vi manderebbe via, e cagionereste un gran dolore ai vostri parenti.'}},\n",
       " {'id': '790',\n",
       "  'translation': {'en': 'It is far better to endure patiently a smart which nobody feels but yourself, than to commit a hasty action whose evil consequences will extend to all connected with you; and besides, the Bible bids us return good for evil.\"',\n",
       "   'it': 'Val meglio sopportare pazientemente un dolore, del quale siamo soli a soffrire, che commettere un atto avventato, le cui spiacevoli conseguenze ricadrebbero sulla nostra famiglia.'}},\n",
       " {'id': '791',\n",
       "  'translation': {'en': '\"But then it seems disgraceful to be flogged, and to be sent to stand in the middle of a room full of people; and you are such a great girl: I am far younger than you, and I could not bear it.\"',\n",
       "   'it': 'Inoltre la Bibbia ci ordina di render bene per male. — Ma è duro di esser battuta, di essere messa in mezzo a una sala piena, soprattutto alla vostra età. Sono molto più giovane, eppur non lo tollererei.'}},\n",
       " {'id': '792',\n",
       "  'translation': {'en': '\"Yet it would be your duty to bear it, if you could not avoid it: it is weak and silly to say you _cannot bear_ what it is your fate to be required to bear.\"',\n",
       "   'it': '— Eppure sarebbe dovere vostro di rassegnarvi, se non poteste evitarlo. Sarebbe una viltà da parte vostra di dire: \"Non posso\" quando sapeste che è il vostro destino.'}},\n",
       " {'id': '793',\n",
       "  'translation': {'en': 'I heard her with wonder: I could not comprehend this doctrine of endurance; and still less could I understand or sympathise with the forbearance she expressed for her chastiser.',\n",
       "   'it': \"Io l'ascoltavo meravigliata. Non potevo capire quella dottrina di rassegnazione, e meno ancora accettare quella indulgenza che dimostrava per chi la puniva.\"}},\n",
       " {'id': '794',\n",
       "  'translation': {'en': 'Still I felt that Helen Burns considered things by a light invisible to my eyes.',\n",
       "   'it': 'Sentivo che Elena Burns considerava ogni cosa alla luce di una fiamma invisibile a me.'}},\n",
       " {'id': '795',\n",
       "  'translation': {'en': 'I suspected she might be right and I wrong; but I would not ponder the matter deeply; like Felix, I put it off to a more convenient season.',\n",
       "   'it': 'Poteva darsi che ella avesse ragione, ma non ero disposta ad approfondire quella faccenda.'}},\n",
       " {'id': '796',\n",
       "  'translation': {'en': '\"You say you have faults, Helen: what are they?',\n",
       "   'it': '— Dite che avete dei difetti, Elena: quali sono?'}},\n",
       " {'id': '797',\n",
       "  'translation': {'en': 'To me you seem very good.\"',\n",
       "   'it': 'Mi pare che siate tanto buona.'}},\n",
       " {'id': '798',\n",
       "  'translation': {'en': '\"Then learn from me, not to judge by appearances: I am, as Miss Scatcherd said, slatternly; I seldom put, and never keep, things, in order; I am careless; I forget rules; I read when I should learn my lessons; I have no method; and sometimes I say, like you, I cannot _bear_ to be subjected to systematic arrangements.',\n",
       "   'it': '— Imparate da me, allora, a non giudicare dalle apparenze. Sono molto negligente, come dice la signorina Scatcherd; metto raramente le cose in ordine e non ve le lascio mai; dimentico le regole stabilite; leggo quando dovrei imparare le lezioni; non ho alcuna, e dico talvolta come voi che non posso \"tollerare\" nessuna regola.'}},\n",
       " {'id': '799',\n",
       "  'translation': {'en': 'This is all very provoking to Miss Scatcherd, who is naturally neat, punctual, and particular.\"',\n",
       "   'it': 'Tutto questo irrita la signorina Scatcherd, che è linda, puntuale ed esatta.'}},\n",
       " {'id': '800',\n",
       "  'translation': {'en': '\"And cross and cruel,\" I added; but Helen Burns would not admit my addition: she kept silence.',\n",
       "   'it': \"— E intrattabile e crudele, — aggiunsi; — ma Elena non volle ammettere l'aggiunta e tacque.\"}},\n",
       " {'id': '801',\n",
       "  'translation': {'en': '\"Is Miss Temple as severe to you as Miss Scatcherd?\"',\n",
       "   'it': '— La signorina Temple è forse severa come la signorina Scatcherd?'}},\n",
       " {'id': '802',\n",
       "  'translation': {'en': \"At the utterance of Miss Temple's name, a soft smile flitted over her grave face.\",\n",
       "   'it': 'Nel sentir pronunziare il nome della direttrice, un dolce sorriso illuminò il serio volto di Elena.'}},\n",
       " {'id': '803',\n",
       "  'translation': {'en': '\"Miss Temple is full of goodness; it pains her to be severe to any one, even the worst in the school: she sees my errors, and tells me of them gently; and, if I do anything worthy of praise, she gives me my meed liberally. One strong proof of my wretchedly defective nature is, that even her expostulations, so mild, so rational, have not influence to cure me of my faults; and even her praise, though I value it most highly, cannot stimulate me to continued care and foresight.\"',\n",
       "   'it': '— La signorina Temple è piena di bontà, — disse, — le fa pena di dover esser severa, anche con le più cattive; ella vede i miei difetti e mi riprende dolcemente: se faccio cosa degna di lode, mi ricompensa liberalmente, e una prova del mio naturale difettoso la vedo nel fatto che i rimproveri di lei, improntati a tanta dolcezza e tanta ragionevolezza, non hanno il potere di emendarmi; e le sue lodi stesse, che hanno tanto valore ai miei occhi, non possono stimolarmi a divenire esatta e perseverante.'}},\n",
       " {'id': '804',\n",
       "  'translation': {'en': '\"That is curious,\" said I, \"it is so easy to be careful.\"',\n",
       "   'it': '— È strano! — esclamai, — è tanto facile di essere accurata.'}},\n",
       " {'id': '805',\n",
       "  'translation': {'en': '\"For _you_ I have no doubt it is.',\n",
       "   'it': '— Per voi, non ne dubito.'}},\n",
       " {'id': '806',\n",
       "  'translation': {'en': 'I observed you in your class this morning, and saw you were closely attentive: your thoughts never seemed to wander while Miss Miller explained the lesson and questioned you.',\n",
       "   'it': \"Stamattina, durante le lezioni, ho visto che eravate attenta; il vostro pensiero non pareva che vagasse allorché la signorina Miller spiegava la lezione e v'interrogava; il mio invece viaggia sempre.\"}},\n",
       " {'id': '807',\n",
       "  'translation': {'en': 'Now, mine continually rove away; when I should be listening to Miss Scatcherd, and collecting all she says with assiduity, often I lose the very sound of her voice; I fall into a sort of dream.',\n",
       "   'it': 'Quando dovrei ascoltare la signorina Scatcherd e raccogliere attentamente ciò che dice, non sento neppure il suono della sua voce.'}},\n",
       " {'id': '808',\n",
       "  'translation': {'en': 'Sometimes I think I am in Northumberland, and that the noises I hear round me are the bubbling of a little brook which runs through Deepden, near our house;--then, when it comes to my turn to reply, I have to be awakened; and having heard nothing of what was read for listening to the visionary brook, I have no answer ready.\"',\n",
       "   'it': 'Penso di essere nel Northumberland, scambio il rumore che sento intorno a me per il mormorio di un ruscello, che scorreva accanto a casa nostra. Quando viene la mia volta, debbo uscir dal sogno, ma siccome non ho ascoltato, non trovo la risposta.'}},\n",
       " {'id': '809',\n",
       "  'translation': {'en': '\"Yet how well you replied this afternoon.\"',\n",
       "   'it': '— Eppure, come avete risposto bene stamani!'}},\n",
       " {'id': '810',\n",
       "  'translation': {'en': '\"It was mere chance; the subject on which we had been reading had interested me.',\n",
       "   'it': \"— È stato un caso; l'argomento della lettura mi piaceva.\"}},\n",
       " {'id': '811',\n",
       "  'translation': {'en': 'This afternoon, instead of dreaming of Deepden, I was wondering how a man who wished to do right could act so unjustly and unwisely as Charles the First sometimes did; and I thought what a pity it was that, with his integrity and conscientiousness, he could see no farther than the prerogatives of the crown.',\n",
       "   'it': \"Invece di sognare il mio paese, ero meravigliata che un uomo che amava il bene potesse commettere tante ingiustizie e pazzie, come quel Carlo I. Pensavo che è triste con quella integrità e quella coscienza di non ammetter nulla all'infuori dell'autorità.\"}},\n",
       " {'id': '812',\n",
       "  'translation': {'en': 'If he had but been able to look to a distance, and see how what they call the spirit of the age was tending!',\n",
       "   'it': \"Se fosse stato capace di vedere l'avvenire, dove tendeva lo spirito del secolo!\"}},\n",
       " {'id': '813',\n",
       "  'translation': {'en': 'Still, I like Charles--I respect him--I pity him, poor murdered king!',\n",
       "   'it': 'Eppure amo e rispetto quel povero re assassinato.'}},\n",
       " {'id': '814',\n",
       "  'translation': {'en': 'Yes, his enemies were the worst: they shed blood they had no right to shed.',\n",
       "   'it': 'I suoi nemici furono più colpevoli di lui: versarono un sangue che non avevano diritto di versare.'}},\n",
       " {'id': '815',\n",
       "  'translation': {'en': 'How dared they kill him!\"',\n",
       "   'it': 'Come poterono ucciderlo?'}},\n",
       " {'id': '816',\n",
       "  'translation': {'en': 'Helen was talking to herself now: she had forgotten I could not very well understand her--that I was ignorant, or nearly so, of the subject she discussed. I recalled her to my level.',\n",
       "   'it': \"Elena parlava a sé stessa; aveva dimenticato che io non potevo capirla bene, e che ignoravo quasi l'argomento di cui trattava; la ricondussi sul mio terreno.\"}},\n",
       " {'id': '817',\n",
       "  'translation': {'en': '\"And when Miss Temple teaches you, do your thoughts wander then?\"',\n",
       "   'it': '— E quando vi dà lezioni la signorina Temple, continua a vagare il vostro pensiero?'}},\n",
       " {'id': '818',\n",
       "  'translation': {'en': '\"No, certainly, not often; because Miss Temple has generally something to say which is newer than my own reflections; her language is singularly agreeable to me, and the information she communicates is often just what I wished to gain.\"',\n",
       "   'it': \"— No, certo, o almeno avviene raramente. La direttrice ha sempre da dirmi qualcosa di più nuovo e di più conforme alle mie riflessioni: il suo linguaggio mi par dolce, ed ella m'insegna appunto ciò che desidero d'imparare.\"}},\n",
       " {'id': '819',\n",
       "  'translation': {'en': '\"Well, then, with Miss Temple you are good?\"',\n",
       "   'it': '— Allora con lei siete buona?'}},\n",
       " {'id': '820',\n",
       "  'translation': {'en': '\"Yes, in a passive way: I make no effort; I follow as inclination guides me.',\n",
       "   'it': \"— Sì, cioè sono buona passivamente: non faccio sforzi; vado dove mi conduce l'inclinazione.\"}},\n",
       " {'id': '821',\n",
       "  'translation': {'en': 'There is no merit in such goodness.\"',\n",
       "   'it': \"Non c'è merito in questa bontà.\"}},\n",
       " {'id': '822',\n",
       "  'translation': {'en': '\"A great deal: you are good to those who are good to you. It is all I ever desire to be.',\n",
       "   'it': \"— Ce n'è uno grande, al contrario; siete buona per quelli che sono buoni per voi; è stato sempre quello che ho desiderato.\"}},\n",
       " {'id': '823',\n",
       "  'translation': {'en': 'If people were always kind and obedient to those who are cruel and unjust, the wicked people would have it all their own way: they would never feel afraid, and so they would never alter, but would grow worse and worse.',\n",
       "   'it': 'Se si ubbidisse a coloro che sono crudeli e ingiusti, i cattivi proseguirebbero troppo facilmente per la loro via.'}},\n",
       " {'id': '824',\n",
       "  'translation': {'en': 'When we are struck at without a reason, we should strike back again very hard; I am sure we should--so hard as to teach the person who struck us never to do it again.\"',\n",
       "   'it': 'Quando ci colpiscono senza ragione, dobbiamo colpire pure, perché sarebbero tentati di ricominciare.'}},\n",
       " {'id': '825',\n",
       "  'translation': {'en': '\"You will change your mind, I hope, when you grow older: as yet you are but a little untaught girl.\"',\n",
       "   'it': \"— Spero che quando sarete più grande cambierete d'idea.\"}},\n",
       " {'id': '826',\n",
       "  'translation': {'en': '\"But I feel this, Helen; I must dislike those who, whatever I do to please them, persist in disliking me; I must resist those who punish me unjustly. It is as natural as that I should love those who show me affection, or submit to punishment when I feel it is deserved.\"',\n",
       "   'it': '— No, perché sento che odierò sempre quelli che mi odieranno, che resisterò a chi mi punirà ingiustamente, e che vorrò bene a chi me ne vorrà.'}},\n",
       " {'id': '827',\n",
       "  'translation': {'en': '\"Heathens and savage tribes hold that doctrine, but Christians and civilised nations disown it.\"',\n",
       "   'it': '— I pagani e i selvaggi proclamano questa dottrina, che è sconfessata dai cristiani e dalla gente civile.'}},\n",
       " {'id': '828', 'translation': {'en': '\"How?', 'it': '— Come?'}},\n",
       " {'id': '829',\n",
       "  'translation': {'en': 'I don\\'t understand.\"', 'it': 'Non capisco.'}},\n",
       " {'id': '830',\n",
       "  'translation': {'en': '\"It is not violence that best overcomes hate--nor vengeance that most certainly heals injury.\"',\n",
       "   'it': \"— Con l'odio non si doma la violenza; con la vendetta non si cancella l'ingiuria.\"}},\n",
       " {'id': '831',\n",
       "  'translation': {'en': '\"Read the New Testament, and observe what Christ says, and how He acts; make His word your rule, and His conduct your example.\"',\n",
       "   'it': 'Leggete il Nuovo Testamento, ascoltate che cosa dice Gesù, e che la sua parola diventi la vostra regola, la sua condotta il vostro esempio.'}},\n",
       " {'id': '832',\n",
       "  'translation': {'en': '\"What does He say?\"', 'it': '— E che cosa dice?'}},\n",
       " {'id': '833',\n",
       "  'translation': {'en': '\"Love your enemies; bless them that curse you; do good to them that hate you and despitefully use you.\"',\n",
       "   'it': '— Dice: \"Amate i nemici, benedite coloro che vi maledicono e fate del bene a quelli che vi odiano e vi trattano con disprezzo.\"'}},\n",
       " {'id': '834',\n",
       "  'translation': {'en': '\"Then I should love Mrs. Reed, which I cannot do; I should bless her son John, which is impossible.\"',\n",
       "   'it': '— Allora dovrei voler bene alla signora Reed? Non posso.'}},\n",
       " {'id': '835',\n",
       "  'translation': {'en': 'In her turn, Helen Burns asked me to explain, and I proceeded forthwith to pour out, in my own way, the tale of my sufferings and resentments.',\n",
       "   'it': 'Elena mi disse di spiegarmi, e cominciai allora a narrarle i miei dolori e i miei risentimenti.'}},\n",
       " {'id': '836',\n",
       "  'translation': {'en': 'Bitter and truculent when excited, I spoke as I felt, without reserve or softening.',\n",
       "   'it': 'Nel parlare mi eccitavo e divenni amara e spietata.'}},\n",
       " {'id': '837',\n",
       "  'translation': {'en': 'Helen heard me patiently to the end: I expected she would then make a remark, but she said nothing.',\n",
       "   'it': 'Elena mi ascoltò pazientemente fino alla fine; mi aspettavo qualche osservazione; ma tacque.'}},\n",
       " {'id': '838',\n",
       "  'translation': {'en': '\"Well,\" I asked impatiently, \"is not Mrs. Reed a hard-hearted, bad woman?\"',\n",
       "   'it': '— Ebbene, — le domandai, — la signora Reed non è forse una donna dura e senza cuore?'}},\n",
       " {'id': '839',\n",
       "  'translation': {'en': '\"She has been unkind to you, no doubt; because you see, she dislikes your cast of character, as Miss Scatcherd does mine; but how minutely you remember all she has done and said to you!',\n",
       "   'it': '— Senza dubbio; ella non è stata buona con voi, perché non le piaceva il vostro carattere, come il mio non piace alla signorina Scatcherd. Ma come vi rammentate esattamente tutte le azioni e le parole di lei!'}},\n",
       " {'id': '840',\n",
       "  'translation': {'en': 'What a singularly deep impression her injustice seems to have made on your heart!',\n",
       "   'it': 'Che profonda impressione vi hanno fatto le sue ingiustizie!'}},\n",
       " {'id': '841',\n",
       "  'translation': {'en': 'No ill-usage so brands its record on my feelings.',\n",
       "   'it': 'Nessun maltrattamento ha lasciato in me traccia così profonda.'}},\n",
       " {'id': '842',\n",
       "  'translation': {'en': 'Would you not be happier if you tried to forget her severity, together with the passionate emotions it excited?',\n",
       "   'it': 'Non sareste più felice, se cercaste di dimenticare la sua severità e le emozioni violente che ha eccitato in voi?'}},\n",
       " {'id': '843',\n",
       "  'translation': {'en': 'Life appears to me too short to be spent in nursing animosity or registering wrongs.',\n",
       "   'it': 'La vita mi par troppo breve per doverla spendere a odiare e a notare i torti altrui; non siamo tutti carichi di peccati in questo mondo?'}},\n",
       " {'id': '844',\n",
       "  'translation': {'en': 'We are, and must be, one and all, burdened with faults in this world: but the time will soon come when, I trust, we shall put them off in putting off our corruptible bodies; when debasement and sin will fall from us with this cumbrous frame of flesh, and only the spark of the spirit will remain,--the impalpable principle of light and thought, pure as when it left the Creator to inspire the creature: whence it came it will return; perhaps again to be communicated to some being higher than man--perhaps to pass through gradations of glory, from the pale human soul to brighten to the seraph!',\n",
       "   'it': \"Il tempo giungerà presto, spero, in cui ci spoglieremo di quest'involucro corruttibile; allora l'avvilimento e il peccato ci lasceranno insieme con l'incomoda prigione di carne; allora non ci rimarrà altro che la scintilla dello spirito, il principio impalpabile della vita pura, come uscì dalle mani del Creatore per animare la creatura. Quel principio ritornerà là da dove mosse, forse si comunicherà a qualche spirito superiore all'uomo, forse traverserà degli stadii di gloria, forse infine il pallido raggio dell'anima umana si trasformerà in quello splendente dei serafini.\"}},\n",
       " {'id': '845',\n",
       "  'translation': {'en': 'Surely it will never, on the contrary, be suffered to degenerate from man to fiend?',\n",
       "   'it': \"Il certo si è che questo principio non può degenerare, non può allearsi allo spirito del male; non posso crederlo: la mia fede è ben altra cosa. Nessuno me l'ha insegnato e ne parlo raramente, ma è la mia gioia.\"}},\n",
       " {'id': '846',\n",
       "  'translation': {'en': 'No; I cannot believe that: I hold another creed: which no one ever taught me, and which I seldom mention; but in which I delight, and to which I cling: for it extends hope to all: it makes Eternity a rest--a mighty home, not a terror and an abyss.',\n",
       "   'it': \"Non faccio della speranza il privilegio di pochi: la estendo a tutti. Considero l'eternità come un riposo, come una splendente dimora, non come un abisso né un luogo di terrore.\"}},\n",
       " {'id': '847',\n",
       "  'translation': {'en': 'Besides, with this creed, I can so clearly distinguish between the criminal and his crime; I can so sincerely forgive the first while I abhor the last: with this creed revenge never worries my heart, degradation never too deeply disgusts me, injustice never crushes me too low: I live in calm, looking to the end.\"',\n",
       "   'it': \"Con questa fede, faccio una differenza fra il peccatore e il suo peccato; perdono sinceramente al primo e odio il secondo; il desiderio della vendetta non mi opprime il cuore, il vizio non mi disgusta abbastanza per allontanarmi dal colpevole e l'ingiustizia non mi toglie il coraggio; vivo calma fissando la morte.\"}},\n",
       " {'id': '848',\n",
       "  'translation': {'en': \"Helen's head, always drooping, sank a little lower as she finished this sentence. I saw by her look she wished no longer to talk to me, but rather to converse with her own thoughts.\",\n",
       "   'it': \"La testa d'Elena si abbassava sempre più nel parlare; lessi nel suo sguardo il desiderio di cessare il discorso per potersi abbandonare ai suoi pensieri.\"}},\n",
       " {'id': '849',\n",
       "  'translation': {'en': 'She was not allowed much time for meditation: a monitor, a great rough girl, presently came up, exclaiming in a strong Cumberland accent--',\n",
       "   'it': 'Però non le fu lasciato molto tempo per meditare. Una monitrice, appena avevamo cessato di parlare, venne a dirle:'}},\n",
       " {'id': '850',\n",
       "  'translation': {'en': '\"Helen Burns, if you don\\'t go and put your drawer in order, and fold up your work this minute, I\\'ll tell Miss Scatcherd to come and look at it!\"',\n",
       "   'it': '— Elena Burns, se non mettete in ordine i vostri cassetti, se non piegate il lavoro, chiamo la signorina Scatcherd.'}},\n",
       " {'id': '851',\n",
       "  'translation': {'en': 'Helen sighed as her reverie fled, and getting up, obeyed the monitor without reply as without delay.',\n",
       "   'it': 'Elena sospirò, ed alzandosi senza rispondere ubbidì subito.'}},\n",
       " {'id': '852', 'translation': {'en': 'CHAPTER VII', 'it': 'VII.'}},\n",
       " {'id': '853',\n",
       "  'translation': {'en': 'My first quarter at Lowood seemed an age; and not the golden age either; it comprised an irksome struggle with difficulties in habituating myself to new rules and unwonted tasks.',\n",
       "   'it': 'I tre primi mesi passati a Lowood mi parvero un secolo. Ebbi a sostenere una lotta spossante contro ogni genere di difficoltà per assuefarmi alla mia nuova vita e ai nuovi doveri.'}},\n",
       " {'id': '854',\n",
       "  'translation': {'en': 'The fear of failure in these points harassed me worse than the physical hardships of my lot; though these were no trifles.',\n",
       "   'it': 'Il timore di non adempierne qualcuno mi spossava più che le sofferenze materiali, benché queste non fossero lievi.'}},\n",
       " {'id': '855',\n",
       "  'translation': {'en': 'During January, February, and part of March, the deep snows, and, after their melting, the almost impassable roads, prevented our stirring beyond the garden walls, except to go to church; but within these limits we had to pass an hour every day in the open air.',\n",
       "   'it': \"Nei tre mesi invernali il freddo e la neve c'impedivano di uscire; andavamo soltanto in chiesa, ma ogni giorno ci facevano passare un'ora all'aria aperta.\"}},\n",
       " {'id': '856',\n",
       "  'translation': {'en': 'Our clothing was insufficient to protect us from the severe cold: we had no boots, the snow got into our shoes and melted there: our ungloved hands became numbed and covered with chilblains, as were our feet: I remember well the distracting irritation I endured from this cause every evening, when my feet inflamed; and the torture of thrusting the swelled, raw, and stiff toes into my shoes in the morning.',\n",
       "   'it': 'I nostri vestiti non potevano ripararci da quel freddo intenso, nelle scarpe penetrava la neve, e le mani, senza guanti, si coprivano di geloni come i piedi. Mi rammento ancora come la sera mi dolevano quando erano gonfi e quanto pativo nel mettermi le scarpe.'}},\n",
       " {'id': '857',\n",
       "  'translation': {'en': 'Then the scanty supply of food was distressing: with the keen appetites of growing children, we had scarcely sufficient to keep alive a delicate invalid.',\n",
       "   'it': 'Inoltre lo scarso vitto era un vero supplizio e quello che ci davano non bastava a calmare il nostro appetito giovanile.'}},\n",
       " {'id': '858',\n",
       "  'translation': {'en': 'From this deficiency of nourishment resulted an abuse, which pressed hardly on the younger pupils: whenever the famished great girls had an opportunity, they would coax or menace the little ones out of their portion.',\n",
       "   'it': 'Ne nasceva un abuso a danno delle più piccine, perché le grandi, sempre affamate, esigevano da quelle una parte della porzione.'}},\n",
       " {'id': '859',\n",
       "  'translation': {'en': 'Many a time I have shared between two claimants the precious morsel of brown bread distributed at tea-time; and after relinquishing to a third half the contents of my mug of coffee, I have swallowed the remainder with an accompaniment of secret tears, forced from me by the exigency of hunger.',\n",
       "   'it': 'Quante volte non ho diviso con due grandi il pezzetto di pane nero che ci davano col caffè, dopo aver dato alla terza la metà della bevanda! Trangugiavo il resto piangendo per la fame.'}},\n",
       " {'id': '860',\n",
       "  'translation': {'en': 'Sundays were dreary days in that wintry season.',\n",
       "   'it': 'Le domeniche invernali erano giornate molto penose.'}},\n",
       " {'id': '861',\n",
       "  'translation': {'en': 'We had to walk two miles to Brocklebridge Church, where our patron officiated.',\n",
       "   'it': 'Avevamo due miglia da fare per giungere alla chiesa di Bockelebridge, ove ufficiava il nostro direttore.'}},\n",
       " {'id': '862',\n",
       "  'translation': {'en': 'We set out cold, we arrived at church colder: during the morning service we became almost paralysed.',\n",
       "   'it': 'Si parlava infreddolite; nel giungere si aveva anche più freddo e prima che terminasse il servizio del mattino eravamo intirizzite.'}},\n",
       " {'id': '863',\n",
       "  'translation': {'en': 'It was too far to return to dinner, and an allowance of cold meat and bread, in the same penurious proportion observed in our ordinary meals, was served round between the services.',\n",
       "   'it': 'Era troppo lontano per tornare a pranzo, così fra i due servizi ci davano pane e carne fredda, in porzioni insufficienti come al solito.'}},\n",
       " {'id': '864',\n",
       "  'translation': {'en': 'At the close of the afternoon service we returned by an exposed and hilly road, where the bitter winter wind, blowing over a range of snowy summits to the north, almost flayed the skin from our faces.',\n",
       "   'it': 'Dopo il servizio della sera si tornava per una strada scoscesa. Il vento del nord soffiava con tanta forza da tagliarci la faccia.'}},\n",
       " {'id': '865',\n",
       "  'translation': {'en': 'I can remember Miss Temple walking lightly and rapidly along our drooping line, her plaid cloak, which the frosty wind fluttered, gathered close about her, and encouraging us, by precept and example, to keep up our spirits, and march forward, as she said, \"like stalwart soldiers.\"',\n",
       "   'it': \"Mi rammento sempre la signorina Temple. Ella camminava leggiera e spedita lungo le file delle educande stanche, e con i precetti e con l'esempio ci incoraggiava a procedere come vecchi soldati.\"}},\n",
       " {'id': '866',\n",
       "  'translation': {'en': 'How we longed for the light and heat of a blazing fire when we got back!',\n",
       "   'it': 'Come desideravamo tutte un buon fuoco nel tornare a Lowood!'}},\n",
       " {'id': '867',\n",
       "  'translation': {'en': 'But, to the little ones at least, this was denied: each hearth in the schoolroom was immediately surrounded by a double row of great girls, and behind them the younger children crouched in groups, wrapping their starved arms in their pinafores.',\n",
       "   'it': \"Questo sollievo era negato alle piccine, perché le grandi formavano subito due doppie file dinanzi ai caminetti, e le altre dovevano contentarsi di procurarsi un po' di calore stringendosi fra loro e nascondendo le braccia intirizzite sotto il grembiale.\"}},\n",
       " {'id': '868',\n",
       "  'translation': {'en': 'A little solace came at tea-time, in the shape of a double ration of bread--a whole, instead of a half, slice--with the delicious addition of a thin scrape of butter: it was the hebdomadal treat to which we all looked forward from Sabbath to Sabbath.',\n",
       "   'it': \"Un piccolo godimento ci era però riservato; alle cinque ci distribuivano una doppia razione di pane con un po' di burro; era il festino domenicale, al quale si pensava tutta la settimana.\"}},\n",
       " {'id': '869',\n",
       "  'translation': {'en': 'I generally contrived to reserve a moiety of this bounteous repast for myself; but the remainder I was invariably obliged to part with.',\n",
       "   'it': \"Cercavo in generale di serbarmi la metà di quella deliziosa merenda, dell'altra ero costretta sempre a farne parte alle grandi.\"}},\n",
       " {'id': '870',\n",
       "  'translation': {'en': 'I have not yet alluded to the visits of Mr. Brocklehurst; and indeed that gentleman was from home during the greater part of the first month after my arrival; perhaps prolonging his stay with his friend the archdeacon: his absence was a relief to me.',\n",
       "   'it': \"Non ho parlato ancora delle visite del signor Bockelhurst: egli fu assente una parte del primo mese; forse aveva prolungato il soggiorno l'amico suo, l'arcidiacono.\"}},\n",
       " {'id': '871',\n",
       "  'translation': {'en': 'I need not say that I had my own reasons for dreading his coming: but come he did at last.',\n",
       "   'it': \"Quell'assenza era un sollievo per me, perché temevo che giungesse, ed egli giunse difatti. Ero a Lowood da tre settimane.\"}},\n",
       " {'id': '872',\n",
       "  'translation': {'en': 'One afternoon (I had then been three weeks at Lowood), as I was sitting with a slate in my hand, puzzling over a sum in long division, my eyes, raised in abstraction to the window, caught sight of a figure just passing: I recognised almost instinctively that gaunt outline; and when, two minutes after, all the school, teachers included, rose _en masse_, it was not necessary for me to look up in order to ascertain whose entrance they thus greeted.',\n",
       "   'it': \"Un pomeriggio, mentre ero seduta con la lavagna sulle ginocchia e mi arrabattavo per fare un'addizione lunga, alzai gli occhi per guardare verso la finestra e vidi passare una figura, che riconobbi istintivamente. Due minuti dopo, tutta la scuola si alzava in massa e non ebbi bisogno di guardare per capire chi era salutato a quel modo.\"}},\n",
       " {'id': '873',\n",
       "  'translation': {'en': 'A long stride measured the schoolroom, and presently beside Miss Temple, who herself had risen, stood the same black column which had frowned on me so ominously from the hearthrug of Gateshead.',\n",
       "   'it': 'Un passo lungo risuonò nella sala e il lungo fantasma nero, che mi aveva esaminato così sgradevolmente a Gateshead, comparve accanto alla signorina Temple.'}},\n",
       " {'id': '874',\n",
       "  'translation': {'en': 'I had my own reasons for being dismayed at this apparition; too well I remembered the perfidious hints given by Mrs. Reed about my disposition, &c.; the promise pledged by Mr. Brocklehurst to apprise Miss Temple and the teachers of my vicious nature.',\n",
       "   'it': \"Avevo le mie buone ragioni per temere quell'apparizione e mi rammentavo la promessa fatta dal signor Bockelhurst, d'informare la direttrice e le maestre sulla mia indole scorretta.\"}},\n",
       " {'id': '875',\n",
       "  'translation': {'en': 'All along I had been dreading the fulfilment of this promise,--I had been looking out daily for the \"Coming Man,\" whose information respecting my past life and conversation was to brand me as a bad child for ever: now there he was. He stood at Miss Temple\\'s side; he was speaking low in her ear: I did not doubt he was making disclosures of my villainy; and I watched her eye with painful anxiety, expecting every moment to see its dark orb turn on me a glance of repugnance and contempt.',\n",
       "   'it': 'Ero convinta che avrebbe rivelato le mie colpe ed esaminavo con dolorosa ansietà gli occhi della direttrice, aspettandovi di leggervi uno sguardo di avversione e di asprezza al mio indirizzo.'}},\n",
       " {'id': '876',\n",
       "  'translation': {'en': 'I listened too; and as I happened to be seated quite at the top of the room, I caught most of what he said: its import relieved me from immediate apprehension.',\n",
       "   'it': \"Tendevo l'orecchio per afferrare quello che dicevano, poiché non ero distante.\"}},\n",
       " {'id': '877',\n",
       "  'translation': {'en': '\"I suppose, Miss Temple, the thread I bought at Lowton will do; it struck me that it would be just of the quality for the calico chemises, and I sorted the needles to match.',\n",
       "   'it': '— Suppongo, signorina Temple, — diceva il signor Bockelhurst, — che il filo comprato a Lowood sarà buono. Mi pare di grossezza giusta per le camice di ghinea.'}},\n",
       " {'id': '878',\n",
       "  'translation': {'en': 'You may tell Miss Smith that I forgot to make a memorandum of the darning needles, but she shall have some papers sent in next week; and she is not, on any account, to give out more than one at a time to each pupil: if they have more, they are apt to be careless and lose them.',\n",
       "   'it': \"Direte alla signorina Smith che ho dimenticato quelli da rammendare, ma la settimana prossima ne avrà qualche carta; guardi bene di non darne che uno per volta alle educande; potrebbero perderli e sarebbe un'occasione di disordine.\"}},\n",
       " {'id': '879',\n",
       "  'translation': {'en': 'And, O ma\\'am! I wish the woollen stockings were better looked to!--when I was here last, I went into the kitchen-garden and examined the clothes drying on the line; there was a quantity of black hose in a very bad state of repair: from the size of the holes in them I was sure they had not been well mended from time to time.\"',\n",
       "   'it': \"— A proposito, signora, vorrei che le calze di lana fossero in migliore stato. Quando venni qui l'ultima volta, esaminai il bucato steso sulle corde in giardino, e vidi le calze nere così rotte da far ritenere che da un pezzo non fossero state rammendate.\"}},\n",
       " {'id': '880',\n",
       "  'translation': {'en': '\"Your directions shall be attended to, sir,\" said Miss Temple.',\n",
       "   'it': '— I vostri ordini, signore, saranno eseguiti, — rispose la direttrice.'}},\n",
       " {'id': '881',\n",
       "  'translation': {'en': '\"And, ma\\'am,\" he continued, \"the laundress tells me some of the girls have two clean tuckers in the week: it is too much; the rules limit them to one.\"',\n",
       "   'it': '— E poi, signora, la lavandaia mi ha detto che alcune ragazze avevano insudiciato due colletti in una settimana: è troppo, la regola non lo permette.'}},\n",
       " {'id': '882',\n",
       "  'translation': {'en': '\"I think I can explain that circumstance, sir.',\n",
       "   'it': '— Credo di poterle spiegare questo fatto, signore.'}},\n",
       " {'id': '883',\n",
       "  'translation': {'en': 'Agnes and Catherine Johnstone were invited to take tea with some friends at Lowton last Thursday, and I gave them leave to put on clean tuckers for the occasion.\"',\n",
       "   'it': 'Agnese e Caterina Jolmstone erano state invitate a prendere il tè a Lawton e permisi loro, per quella occasione, di mettersi i colletti bianchi.'}},\n",
       " {'id': '884',\n",
       "  'translation': {'en': 'Mr. Brocklehurst nodded.',\n",
       "   'it': 'Il signor Bockelhurst scrollò il capo.'}},\n",
       " {'id': '885',\n",
       "  'translation': {'en': '\"Well, for once it may pass; but please not to let the circumstance occur too often.',\n",
       "   'it': '— Per una volta passi, ma che simili fatti non si ripetano.'}},\n",
       " {'id': '886',\n",
       "  'translation': {'en': 'And there is another thing which surprised me; I find, in settling accounts with the housekeeper, that a lunch, consisting of bread and cheese, has twice been served out to the girls during the past fortnight. How is this?',\n",
       "   'it': \"C'è un'altra cosa, che mi ha meravigliato. Facendo i conti con la dispensiera ho visto che era stata data alle alunne per due volte una merenda di pane e formaggio, perché?\"}},\n",
       " {'id': '887',\n",
       "  'translation': {'en': 'I looked over the regulations, and I find no such meal as lunch mentioned.',\n",
       "   'it': 'Ho guardato il regolamento e non ho visto notata la merenda.'}},\n",
       " {'id': '888',\n",
       "  'translation': {'en': 'Who introduced this innovation? and by what authority?\"',\n",
       "   'it': 'Chi ha introdotta questa innovazione e con qual diritto?'}},\n",
       " {'id': '889',\n",
       "  'translation': {'en': '\"I must be responsible for the circumstance, sir,\" replied Miss Temple: \"the breakfast was so ill prepared that the pupils could not possibly eat it; and I dared not allow them to remain fasting till dinner-time.\"',\n",
       "   'it': \"— La responsabilità è mia, — rispose la direttrice, — le alunne non avevano potuto mangiare la colazione, che era troppo cattiva, e non ho potuto permettere che stessero digiune fino all'ora di pranzo.\"}},\n",
       " {'id': '890',\n",
       "  'translation': {'en': '\"Madam, allow me an instant.',\n",
       "   'it': '— Un momento, signora!'}},\n",
       " {'id': '891',\n",
       "  'translation': {'en': 'You are aware that my plan in bringing up these girls is, not to accustom them to habits of luxury and indulgence, but to render them hardy, patient, self-denying.',\n",
       "   'it': 'Voi sapete che educando queste ragazze, non è nelle mie vedute di assuefarle al lusso, ma di renderle misere, pazienti e tolleranti nella sofferenza.'}},\n",
       " {'id': '892',\n",
       "  'translation': {'en': 'Should any little accidental disappointment of the appetite occur, such as the spoiling of a meal, the under or the over dressing of a dish, the incident ought not to be neutralised by replacing with something more delicate the comfort lost, thus pampering the body and obviating the aim of this institution; it ought to be improved to the spiritual edification of the pupils, by encouraging them to evince fortitude under temporary privation.',\n",
       "   'it': \"Se accade loro un piccolo incidente, un pasto guastato, per esempio, non si deve paralizzare l'effetto dell'azione. Voi dimenticate lo scopo di questa istituzione e certi avvenimenti dovrebbero esser cagione di edificazione per le alunne; sarebbe quello il momento di predicare la forza d'animo nelle privazioni della vita, e un saggio educatore dovrebbe trarne argomento per rammentare le sofferenze dei primi cristiani, il tormento dei martiri, l'esempio del Divin Maestro.\"}},\n",
       " {'id': '893',\n",
       "  'translation': {'en': 'A brief address on those occasions would not be mistimed, wherein a judicious instructor would take the opportunity of referring to the sufferings of the primitive Christians; to the torments of martyrs; to the exhortations of our blessed Lord Himself, calling upon His disciples to take up their cross and follow Him; to His warnings that man shall not live by bread alone, but by every word that proceedeth out of the mouth of God; to His divine consolations, \"If ye suffer hunger or thirst for My sake, happy are ye.\"',\n",
       "   'it': 'O, signora!'}},\n",
       " {'id': '894',\n",
       "  'translation': {'en': 'Oh, madam, when you put bread and cheese, instead of burnt porridge, into these children\\'s mouths, you may indeed feed their vile bodies, but you little think how you starve their immortal souls!\"',\n",
       "   'it': 'Voi mettete nella bocca di queste ragazze pane e formaggio, invece di una minestra bruciata; ve lo dico in verità, voi nutrite così il loro vile involucro, ma uccidete la loro anima immortale!'}},\n",
       " {'id': '895',\n",
       "  'translation': {'en': 'Mr. Brocklehurst again paused--perhaps overcome by his feelings.',\n",
       "   'it': 'Il signor Bockelhurst si fermò di nuovo, come se i pensieri lo soffocassero.'}},\n",
       " {'id': '896',\n",
       "  'translation': {'en': \"Miss Temple had looked down when he first began to speak to her; but she now gazed straight before her, and her face, naturally pale as marble, appeared to be assuming also the coldness and fixity of that material; especially her mouth, closed as if it would have required a sculptor's chisel to open it, and her brow settled gradually into petrified severity.\",\n",
       "   'it': 'La signorina Temple aveva abbassato gli occhi quando egli aveva preso a parlare, ma ora teneva lo sguardo fisso dinanzi a sé, e il suo volto ordinariamente pallido come il marmo, ne aveva presa la freddezza e la fissità; la bocca specialmente era così chiusa che pareva non avrebbe potuto aprirla altro che lo scalpello dello scultore.'}},\n",
       " {'id': '897',\n",
       "  'translation': {'en': 'Meantime, Mr. Brocklehurst, standing on the hearth with his hands behind his back, majestically surveyed the whole school.',\n",
       "   'it': 'Il signor Bockelhurst, ritto davanti al caminetto, sorvegliava maestosamente la scuola.'}},\n",
       " {'id': '898',\n",
       "  'translation': {'en': 'Suddenly his eye gave a blink, as if it had met something that either dazzled or shocked its pupil; turning, he said in more rapid accents than he had hitherto used--',\n",
       "   'it': 'A un tratto fece un movimento, quasi il suo sguardo fosse stato ferito da uno spettacolo ripugnante, e volgendosi esclamò:'}},\n",
       " {'id': '899',\n",
       "  'translation': {'en': '\"Miss Temple, Miss Temple, what--_what_ is that girl with curled hair? Red hair, ma\\'am, curled--curled all over?\"',\n",
       "   'it': '— Signorina Temple! chi è quella bambina coi capelli arricciati, capelli rossi, signora, arricciati sulla fronte?'}},\n",
       " {'id': '900',\n",
       "  'translation': {'en': 'And extending his cane he pointed to the awful object, his hand shaking as he did so.',\n",
       "   'it': \"Egli stese il bastone verso l'oggetto ripugnante: la mano tremavagli.\"}},\n",
       " {'id': '901',\n",
       "  'translation': {'en': '\"It is Julia Severn,\" replied Miss Temple, very quietly.',\n",
       "   'it': '— È Giulia Severne, — rispose tranquillamente la direttrice. — Giulia Severne, signora.'}},\n",
       " {'id': '902',\n",
       "  'translation': {'en': '\"Julia Severn, ma\\'am! And why has she, or any other, curled hair?',\n",
       "   'it': 'Ebbene, perché, contrariamente a tutti i principii di questa casa, segue le leggi del mondo?'}},\n",
       " {'id': '903',\n",
       "  'translation': {'en': 'Why, in defiance of every precept and principle of this house, does she conform to the world so openly--here in an evangelical, charitable establishment--as to wear her hair one mass of curls?\"',\n",
       "   'it': 'Qui, in un istituto evangelico, portare tanti ricci!'}},\n",
       " {'id': '904',\n",
       "  'translation': {'en': '\"Julia\\'s hair curls naturally,\" returned Miss Temple, still more quietly.',\n",
       "   'it': '— I capelli di Giulia sono naturalmente arricciati, — rispose la signorina Temple con calma anche maggiore.'}},\n",
       " {'id': '905',\n",
       "  'translation': {'en': '\"Naturally! Yes, but we are not to conform to nature; I wish these girls to be the children of Grace: and why that abundance?',\n",
       "   'it': '— Naturalmente, sì, ma noi non ci conformiamo alla natura. Io voglio che queste ragazze sieno figlie della grazia.'}},\n",
       " {'id': '906',\n",
       "  'translation': {'en': 'I have again and again intimated that I desire the hair to be arranged closely, modestly, plainly.',\n",
       "   'it': 'E perché quella esuberanza? Ho ripetuto più volte che desideravo vedere i capelli modestamente lisciati.'}},\n",
       " {'id': '907',\n",
       "  'translation': {'en': \"Miss Temple, that girl's hair must be cut off entirely; I will send a barber to-morrow: and I see others who have far too much of the excrescence--that tall girl, tell her to turn round.\",\n",
       "   'it': 'Signorina Temple, bisogna che domani i capelli di quella bambina sieno rasi. Manderò il parrucchiere; ma ne vedo altre che hanno capelli troppo lunghi e troppo abbondanti.'}},\n",
       " {'id': '908',\n",
       "  'translation': {'en': 'Tell all the first form to rise up and direct their faces to the wall.\"',\n",
       "   'it': 'Dite a quella grande di voltarsi verso di me; no, dite a tutta la prima panca di alzarsi e di guardare verso il muro.'}},\n",
       " {'id': '909',\n",
       "  'translation': {'en': 'Miss Temple passed her handkerchief over her lips, as if to smooth away the involuntary smile that curled them; she gave the order, however, and when the first class could take in what was required of them, they obeyed.',\n",
       "   'it': \"La direttrice si coprì la bocca col manicotto per nascondere un sorriso involontario, ma dette l'ordine, e la prima classe obbedì.\"}},\n",
       " {'id': '910',\n",
       "  'translation': {'en': 'Leaning a little back on my bench, I could see the looks and grimaces with which they commented on this manoeuvre: it was a pity Mr. Brocklehurst could not see them too; he would perhaps have felt that, whatever he might do with the outside of the cup and platter, the inside was further beyond his interference than he imagined.',\n",
       "   'it': 'Curvandomi sulla panca, potei vedere le boccacce che esse facevano volgendo la testa verso il muro.'}},\n",
       " {'id': '911',\n",
       "  'translation': {'en': 'He scrutinised the reverse of these living medals some five minutes, then pronounced sentence. These words fell like the knell of doom--',\n",
       "   'it': 'Il signor Bockelhurst, dopo aver esaminato cinque minuti le ragazze, pronunziò una sentenza, che mi parve atroce.'}},\n",
       " {'id': '912',\n",
       "  'translation': {'en': '\"All those top-knots must be cut off.\"',\n",
       "   'it': '— Tutti quei capelli devono esser tagliati.'}},\n",
       " {'id': '913',\n",
       "  'translation': {'en': 'Miss Temple seemed to remonstrate.',\n",
       "   'it': \"La direttrice cercò di fare un'osservazione.\"}},\n",
       " {'id': '914',\n",
       "  'translation': {'en': '\"Madam,\" he pursued, \"I have a Master to serve whose kingdom is not of this world: my mission is to mortify in these girls the lusts of the flesh; to teach them to clothe themselves with shame-facedness and sobriety, not with braided hair and costly apparel; and each of the young persons before us has a string of hair twisted in plaits which vanity itself might have woven; these, I repeat, must be cut off; think of the time wasted, of--\" Mr. Brocklehurst was here interrupted: three other visitors, ladies, now entered the room.',\n",
       "   'it': \"— Signora, — diss'egli, — debbo servire un padrone, il cui regno non è di questo mondo; la mia missione è di mortificare in quelle ragazze i desiderii della carne. Sì, lo ripeto, quei capelli che la vanità stessa pare abbia intrecciati, debbono esser tagliati.\"}},\n",
       " {'id': '915',\n",
       "  'translation': {'en': 'They ought to have come a little sooner to have heard his lecture on dress, for they were splendidly attired in velvet, silk, and furs.',\n",
       "   'it': \"Sarebbero dovute giungere un po' prima per sentir la predica, perché erano sfarzosamente vestite di velluto, di seta e di pelliccie.\"}},\n",
       " {'id': '916',\n",
       "  'translation': {'en': 'The two younger of the trio (fine girls of sixteen and seventeen) had grey beaver hats, then in fashion, shaded with ostrich plumes, and from under the brim of this graceful head-dress fell a profusion of light tresses, elaborately curled; the elder lady was enveloped in a costly velvet shawl, trimmed with ermine, and she wore a false front of French curls.',\n",
       "   'it': \"Due di loro, belle ragazze dai sedici ai diciassette anni, portavano larghi cappelli di feltro guerniti di penne di struzzo, secondo l'ultimo figurino di mode. Una quantità di ricciolini facevano ombra alla fronte.\"}},\n",
       " {'id': '917',\n",
       "  'translation': {'en': 'These ladies were deferentially received by Miss Temple, as Mrs. and the Misses Brocklehurst, and conducted to seats of honour at the top of the room.',\n",
       "   'it': \"Quelle tre signore erano la moglie e le figlie del nostro direttore, e furono salutate rispettosamente dalla signorina Temple e condotte ai posti d'onore, in fondo alla stanza.\"}},\n",
       " {'id': '918',\n",
       "  'translation': {'en': 'It seems they had come in the carriage with their reverend relative, and had been conducting a rummaging scrutiny of the room upstairs, while he transacted business with the housekeeper, questioned the laundress, and lectured the superintendent.',\n",
       "   'it': 'Pare che fossero giunte prima in carrozza e avessero esaminati i dormitorii intanto che il signor Bockelhurst obbligava la direttrice ad ascoltar le prediche.'}},\n",
       " {'id': '919',\n",
       "  'translation': {'en': 'They now proceeded to address divers remarks and reproofs to Miss Smith, who was charged with the care of the linen and the inspection of the dormitories: but I had no time to listen to what they said; other matters called off and enchanted my attention.',\n",
       "   'it': \"Ora rivolgevano osservazioni e rimproveri alla signorina Smith, che aveva in consegna la biancheria, ma non ebbi il tempo di ascoltare, perché cercavo di non esser veduta e mi nascondevo dietro la lavagna, fingendo di essere assorta nell'addizione.\"}},\n",
       " {'id': '920',\n",
       "  'translation': {'en': 'To this end, I had sat well back on the form, and while seeming to be busy with my sum, had held my slate in such a manner as to conceal my face: I might have escaped notice, had not my treacherous slate somehow happened to slip from my hand, and falling with an obtrusive crash, directly drawn every eye upon me; I knew it was all over now, and, as I stooped to pick up the two fragments of slate, I rallied my forces for the worst. It came.',\n",
       "   'it': 'Sarei per certo sfuggita agli sguardi, se la lavagna non mi fosse scivolata di mano e, cadendo, non avesse prodotto un gran rumore. Tutti gli occhi si fissarono allora su di me e capii che era tutto perduto; per altro mi feci animo per affrontar la burrasca.'}},\n",
       " {'id': '921',\n",
       "  'translation': {'en': '\"A careless girl!\" said Mr. Brocklehurst, and immediately after--\"It is the new pupil, I perceive.\"',\n",
       "   'it': '— Una bambina sbadata, — disse il signor Bockelhurst.'}},\n",
       " {'id': '922',\n",
       "  'translation': {'en': 'And before I could draw breath, \"I must not forget I have a word to say respecting her.\"',\n",
       "   'it': 'E subito dopo aggiunse: — Mi pare sia la nuova educanda.'}},\n",
       " {'id': '923',\n",
       "  'translation': {'en': 'Then aloud: how loud it seemed to me!',\n",
       "   'it': 'Bisogna che non dimentichi quello che devo dire di lei.'}},\n",
       " {'id': '924',\n",
       "  'translation': {'en': '\"Let the child who broke her slate come forward!\"',\n",
       "   'it': 'Fate venire la bambina che ha rotto la lavagna.'}},\n",
       " {'id': '925',\n",
       "  'translation': {'en': 'Of my own accord I could not have stirred; I was paralysed: but the two great girls who sit on each side of me, set me on my legs and pushed me towards the dread judge, and then Miss Temple gently assisted me to his very feet, and I caught her whispered counsel--',\n",
       "   'it': \"Da me non avrei potuto muovermi: ero paralizzata, ma due grandi, che erano accanto a me, mi costrinsero ad alzarmi e mi spinsero verso il temuto giudice. La signorina Temple mi aiutò con dolcezza ad accostarmi e mi susurrò nell'orecchio:\"}},\n",
       " {'id': '926',\n",
       "  'translation': {'en': '\"Don\\'t be afraid, Jane, I saw it was an accident; you shall not be punished.\"',\n",
       "   'it': \"— Non vi spaventate, Jane; ho visto che non l'avete fatto apposta, e non sarete punita.\"}},\n",
       " {'id': '927',\n",
       "  'translation': {'en': 'The kind whisper went to my heart like a dagger.',\n",
       "   'it': 'Quelle buone parole mi ferirono come un dardo.'}},\n",
       " {'id': '928',\n",
       "  'translation': {'en': '\"Another minute, and she will despise me for a hypocrite,\" thought I; and an impulse of fury against Reed, Brocklehurst, and Co. bounded in my pulses at the conviction. I was no Helen Burns.',\n",
       "   'it': \"— Fra poco mi disprezzerà e vedrà in me un'ipocrita, pensai; e allora un sentimento di collera contro la signora Reed e contro il direttore, m'infiammò il sangue.\"}},\n",
       " {'id': '929',\n",
       "  'translation': {'en': '\"Fetch that stool,\" said Mr. Brocklehurst, pointing to a very high one from which a monitor had just risen: it was brought. \"Place the child upon it.\"',\n",
       "   'it': '— Avanzate quella seggiola, — disse il signor Bockelhurst accennando una sedia alta, — e metteteci la bambina.'}},\n",
       " {'id': '930',\n",
       "  'translation': {'en': \"And I was placed there, by whom I don't know: I was in no condition to note particulars; I was only aware that they had hoisted me up to the height of Mr. Brocklehurst's nose, that he was within a yard of me, and that a spread of shot orange and purple silk pelisses and a cloud of silvery plumage extended and waved below me.\",\n",
       "   'it': 'Mi accorsi che mi avevano alzata sulla sedia, ma non so chi fosse stata.'}},\n",
       " {'id': '931',\n",
       "  'translation': {'en': 'Mr. Brocklehurst hemmed. \"Ladies,\" said he, turning to his family, \"Miss Temple, teachers, and children, you all see this girl?\"',\n",
       "   'it': '— Signore, — disse il direttore rivolgendosi alla sua famiglia, — signorina Temple, maestre, alunne, voi vedete tutte questa bimba.'}},\n",
       " {'id': '932',\n",
       "  'translation': {'en': 'Of course they did; for I felt their eyes directed like burning-glasses against my scorched skin.',\n",
       "   'it': 'Certo mi vedevano tutte, e i loro sguardi mi bruciavano il viso.'}},\n",
       " {'id': '933',\n",
       "  'translation': {'en': '\"You see she is yet young; you observe she possesses the ordinary form of childhood; God has graciously given her the shape that He has given to all of us; no signal deformity points her out as a marked character.',\n",
       "   'it': \"— Voi vedete che è piccina; Dio le ha accordato liberalmente l'involucro che accorda a tutti. Nessuna deformità indica in lei un essere a parte.\"}},\n",
       " {'id': '934',\n",
       "  'translation': {'en': 'Who would think that the Evil One had already found a servant and agent in her?',\n",
       "   'it': 'Chi crederebbe che lo spirito del male ha trovato in lei una schiava e un agente?'}},\n",
       " {'id': '935',\n",
       "  'translation': {'en': 'Yet such, I grieve to say, is the case.\"',\n",
       "   'it': 'Eppure, è ben triste a dirsi, ma è la verità.'}},\n",
       " {'id': '936',\n",
       "  'translation': {'en': 'A pause--in which I began to steady the palsy of my nerves, and to feel that the Rubicon was passed; and that the trial, no longer to be shirked, must be firmly sustained.',\n",
       "   'it': 'Egli si fermò ed io ebbi tempo di rinforzare i miei nervi e di sentir svanire dal volto il rossore. Non potevo evitare la prova; dovevo sostenerla con coraggio.'}},\n",
       " {'id': '937',\n",
       "  'translation': {'en': '\"My dear children,\" pursued the black marble clergyman, with pathos, \"this is a sad, a melancholy occasion; for it becomes my duty to warn you, that this girl, who might be one of God\\'s own lambs, is a little castaway: not a member of the true flock, but evidently an interloper and an alien.',\n",
       "   'it': \"— Mie care bambine, — continuò il pastore, — è cosa dolorosa e triste, ed a me spetta di avvertirvi: questa piccina, che avrebbe potuto essere un agnello di Dio, è una reproba. State in guardia, diffidate del suo esempio; se è necessario, evitatene la compagnia, escludetela dai vostri giuochi, non l'introducete nelle vostre conversazioni.\"}},\n",
       " {'id': '938',\n",
       "  'translation': {'en': 'You must be on your guard against her; you must shun her example; if necessary, avoid her company, exclude her from your sports, and shut her out from your converse.',\n",
       "   'it': \"E voi, maestre, vigilate ogni suo atto, punite il suo corpo, per salvarne l'anima, se pure è possibile.\"}},\n",
       " {'id': '939',\n",
       "  'translation': {'en': 'Teachers, you must watch her: keep your eyes on her movements, weigh well her words, scrutinise her actions, punish her body to save her soul: if, indeed, such salvation be possible, for (my tongue falters while I tell it) this girl, this child, the native of a Christian land, worse than many a little heathen who says its prayers to Brahma and kneels before Juggernaut--this girl is--a liar!\"',\n",
       "   'it': \"Questa bimba, la mia lingua esita a dirlo, nata in un paese cristiano, è peggiore degli idolatri che inalzano preghiere a Brama e s'inginocchiano davanti a Jagornau: questa bimba è una bugiarda!\"}},\n",
       " {'id': '940',\n",
       "  'translation': {'en': 'Now came a pause of ten minutes, during which I, by this time in perfect possession of my wits, observed all the female Brocklehursts produce their pocket-handkerchiefs and apply them to their optics, while the elderly lady swayed herself to and fro, and the two younger ones whispered, \"How shocking!\"',\n",
       "   'it': 'Essendo pienamente in me, potei vedere le signore del pastore cavar di tasca i fazzoletti e portarseli agli occhi. La moglie ripeteva sempre: — Che vergogna!'}},\n",
       " {'id': '941',\n",
       "  'translation': {'en': 'Mr. Brocklehurst resumed. \"This I learned from her benefactress; from the pious and charitable lady who adopted her in her orphan state, reared her as her own daughter, and whose kindness, whose generosity the unhappy girl repaid by an ingratitude so bad, so dreadful, that at last her excellent patroness was obliged to separate her from her own young ones, fearful lest her vicious example should contaminate their purity: she has sent her here to be healed, even as the Jews of old sent their diseased to the troubled pool of Bethesda; and, teachers, superintendent, I beg of you not to allow the waters to stagnate round her.\"',\n",
       "   'it': \"— Tutte queste cose, — aggiunse il signor Bockelhurst, — le ho sapute dalla sua benefattrice, quella pia e caritatevole signora, che l'ha adottata quando rimase orfana, e l'ha educata insieme con le sue figlie; e questa disgraziata bambina ha pagata la sua bontà e la sua generosità con una ingratitudine così grande, che l'eccellente signora Reed è stata costretta di separare Jane dai suoi figli, affinchè il suo esempio non contaminasse la loro purezza. È stata mandata qui per essere guarita, come gli ebrei mandano i loro malati al lago di Betteda.\"}},\n",
       " {'id': '942',\n",
       "  'translation': {'en': 'With this sublime conclusion, Mr. Brocklehurst adjusted the top button of his surtout, muttered something to his family, who rose, bowed to Miss Temple, and then all the great people sailed in state from the room.',\n",
       "   'it': 'Dopo questa sublime conclusione il pastore si abbottonò il soprabito e disse qualcosa sottovoce alla famiglia. Le signore si alzarono, salutarono la signorina Temple e uscirono con sussiego dalla sala di studio.'}},\n",
       " {'id': '943',\n",
       "  'translation': {'en': 'Turning at the door, my judge said--',\n",
       "   'it': 'Giunto alla porta, il mio giudice si volse e disse:'}},\n",
       " {'id': '944',\n",
       "  'translation': {'en': '\"Let her stand half-an-hour longer on that stool, and let no one speak to her during the remainder of the day.\"',\n",
       "   'it': \"— Lasciatela per un'altra mezz'ora su quella seggiola e che nessuno le parli per tutta la giornata.\"}},\n",
       " {'id': '945',\n",
       "  'translation': {'en': 'There was I, then, mounted aloft; I, who had said I could not bear the shame of standing on my natural feet in the middle of the room, was now exposed to general view on a pedestal of infamy.',\n",
       "   'it': 'Ero dunque seduta lassù sulla seggiola, io che avevo dichiarato che non avrei potuto tollerare la vergogna di star ritta in mezzo alla sala! Mi trovavo esposta a tutti gli sguardi su quel piedestallo di vergogna.'}},\n",
       " {'id': '946',\n",
       "  'translation': {'en': 'What my sensations were no language can describe; but just as they all rose, stifling my breath and constricting my throat, a girl came up and passed me: in passing, she lifted her eyes.',\n",
       "   'it': 'Nessuna parola può esprimere i miei sentimenti, ma intanto che mi gonfiavano il cuore, una ragazza mi passò vicino e alzò su me lo sguardo.'}},\n",
       " {'id': '947',\n",
       "  'translation': {'en': 'What a strange light inspired them!',\n",
       "   'it': 'Quale fiamma strana brillava in quegli occhi!'}},\n",
       " {'id': '948',\n",
       "  'translation': {'en': 'What an extraordinary sensation that ray sent through me! How the new feeling bore me up!',\n",
       "   'it': 'Quale straordinaria impressione produsse in me quello sguardo luminoso!'}},\n",
       " {'id': '949',\n",
       "  'translation': {'en': 'It was as if a martyr, a hero, had passed a slave or victim, and imparted strength in the transit.',\n",
       "   'it': \"Mi sentii più forte; era un'eroina, una martire, che passando davanti a una vittima o a una schiava, le comunicava la sua forza.\"}},\n",
       " {'id': '950',\n",
       "  'translation': {'en': 'I mastered the rising hysteria, lifted up my head, and took a firm stand on the stool.',\n",
       "   'it': \"Dominai l'odio che mi saliva al cuore, rialzai la testa e rimasi ferma sulla sedia.\"}},\n",
       " {'id': '951',\n",
       "  'translation': {'en': 'Helen Burns asked some slight question about her work of Miss Smith, was chidden for the triviality of the inquiry, returned to her place, and smiled at me as she again went by.',\n",
       "   'it': 'Elena Burns fece alla signorina Smith una domanda, rispetto al suo cucito. Fu sgridata per aver domandato una cosa tanto ovvia, e, tornando al posto, mi sorrise di nuovo.'}},\n",
       " {'id': '952', 'translation': {'en': 'What a smile!', 'it': 'Che sorriso!'}},\n",
       " {'id': '953',\n",
       "  'translation': {'en': 'I remember it now, and I know that it was the effluence of fine intellect, of true courage; it lit up her marked lineaments, her thin face, her sunken grey eye, like a reflection from the aspect of an angel.',\n",
       "   'it': 'Me lo rammento anche ora; era la manifestazione di una bella intelligenza e di un vero coraggio; ne illuminò i tratti, il volto scarno, gli occhi abbattuti, come avrebbe fatto il sorriso di un angiolo.'}},\n",
       " {'id': '954',\n",
       "  'translation': {'en': 'Yet at that moment Helen Burns wore on her arm \"the untidy badge;\" scarcely an hour ago I had heard her condemned by Miss Scatcherd to a dinner of bread and water on the morrow because she had blotted an exercise in copying it out.',\n",
       "   'it': 'Eppure Elena Burns portava al braccio un cartello con queste parole: Alunna sciatta'}},\n",
       " {'id': '955',\n",
       "  'translation': {'en': \"Such is the imperfect nature of man! such spots are there on the disc of the clearest planet; and eyes like Miss Scatcherd's can only see those minute defects, and are blind to the full brightness of the orb.\",\n",
       "   'it': \"Un'ora prima avevo sentito la signorina Scatcherd condannarla a pane e acqua, per aver macchiato un esemplare di calligrafia copiandolo.\"}},\n",
       " {'id': '956', 'translation': {'en': 'CHAPTER VIII', 'it': 'VIII.'}},\n",
       " {'id': '957',\n",
       "  'translation': {'en': \"Ere the half-hour ended, five o'clock struck; school was dismissed, and all were gone into the refectory to tea.\",\n",
       "   'it': \"Prima che fosse trascorsa la mezz'ora della mia penitenza, sentii sonare le cinque. Cessarono il lavoro e tutte andarono in refettorio per prendere il caffè.\"}},\n",
       " {'id': '958',\n",
       "  'translation': {'en': 'I now ventured to descend: it was deep dusk; I retired into a corner and sat down on the floor.',\n",
       "   'it': \"Era notte e lasciandomi scivolare in un canto, mi sedei sull'impiantito.\"}},\n",
       " {'id': '959',\n",
       "  'translation': {'en': 'The spell by which I had been so far supported began to dissolve; reaction took place, and soon, so overwhelming was the grief that seized me, I sank prostrate with my face to the ground.',\n",
       "   'it': \"Era sul punto di svanire l'incantesimo che mi aveva sostenuto fino a quel momento. Sopraggiunse la reazione e il dolore che s'impossessò di me fu così opprimente, che mi abbandonai ad esso, col viso rivolto verso terra.\"}},\n",
       " {'id': '960',\n",
       "  'translation': {'en': 'Now I wept: Helen Burns was not here; nothing sustained me; left to myself I abandoned myself, and my tears watered the boards.',\n",
       "   'it': 'Nulla mi aiutava. Nessuno mi udiva ed Elena Burns non era vicina a me.'}},\n",
       " {'id': '961',\n",
       "  'translation': {'en': 'I had meant to be so good, and to do so much at Lowood: to make so many friends, to earn respect and win affection.',\n",
       "   'it': 'Giungendo a Lowood avevo risolto di esser così buona, così sottomessa, da conquistare simpatie e amicizie.'}},\n",
       " {'id': '962',\n",
       "  'translation': {'en': 'Already I had made visible progress: that very morning I had reached the head of my class; Miss Miller had praised me warmly; Miss Temple had smiled approbation; she had promised to teach me drawing, and to let me learn French, if I continued to make similar improvement two months longer: and then I was well received by my fellow-pupils; treated as an equal by those of my own age, and not molested by any; now, here I lay again crushed and trodden on; and could I ever rise more?',\n",
       "   'it': \"Avevo già fatto progressi evidenti e la mattina mi avevano dato il posto di capo-classe; la signorina Miller mi aveva caldamente complimentata, la signorina Temple mi aveva accordato un sorriso d'approvazione e s'era impegnata a insegnarmi il disegno e a farmi insegnare il francese, se continuavo a progredire per due mesi. Ero amata dalle mie compagne; quelle della mia età mi trattavano da eguale, le grandi non mi facevano disperare; e ora stavo per essere umiliata di nuovo, di nuovo respinta, senza sapere se avrei mai potuto rialzarmi.\"}},\n",
       " {'id': '963',\n",
       "  'translation': {'en': '\"Never,\" I thought; and ardently I wished to die.',\n",
       "   'it': '— No, non potrei, — pensavo e mi misi a desiderare ardentemente la morte.'}},\n",
       " {'id': '964',\n",
       "  'translation': {'en': 'While sobbing out this wish in broken accents, some one approached: I started up--again Helen Burns was near me; the fading fires just showed her coming up the long, vacant room; she brought my coffee and bread.',\n",
       "   'it': 'Mentre formulavo questo desiderio in mezzo ai singhiozzi, qualcuna si avvicinò a me; mi scossi. Elena Burns mi era accanto e mi portava il caffè e il pane.'}},\n",
       " {'id': '965',\n",
       "  'translation': {'en': '\"Come, eat something,\" she said; but I put both away from me, feeling as if a drop or a crumb would have choked me in my present condition.',\n",
       "   'it': '— Mangiate qualcosa, — mi disse. Respinsi quello che mi offriva, sentendo che nel mio stato anche un sorso di caffè mi avrebbe fatto male.'}},\n",
       " {'id': '966',\n",
       "  'translation': {'en': 'Helen regarded me, probably with surprise: I could not now abate my agitation, though I tried hard; I continued to weep aloud.',\n",
       "   'it': \"Ella mi guardò forse meravigliata; benché mi sforzassi, non potevo dominare l'agitazione e continuavo a piangere.\"}},\n",
       " {'id': '967',\n",
       "  'translation': {'en': 'She sat down on the ground near me, embraced her knees with her arms, and rested her head upon them; in that attitude she remained silent as an Indian.',\n",
       "   'it': 'Ella si sedè accanto a me, in silenzio.'}},\n",
       " {'id': '968',\n",
       "  'translation': {'en': 'I was the first who spoke--',\n",
       "   'it': 'Io fui la prima a parlare.'}},\n",
       " {'id': '969',\n",
       "  'translation': {'en': '\"Helen, why do you stay with a girl whom everybody believes to be a liar?\"',\n",
       "   'it': '— Elena, — le dissi, — perché state con una che tutti credono bugiarda?'}},\n",
       " {'id': '970',\n",
       "  'translation': {'en': '\"Everybody, Jane?', 'it': '— Tutti, Jane?'}},\n",
       " {'id': '971',\n",
       "  'translation': {'en': 'Why, there are only eighty people who have heard you called so, and the world contains hundreds of millions.\"',\n",
       "   'it': 'Appena ottanta persone vi hanno sentito accusare e il mondo ne contiene milioni e milioni!'}},\n",
       " {'id': '972',\n",
       "  'translation': {'en': '\"But what have I to do with millions? The eighty, I know, despise me.\"',\n",
       "   'it': \"— Che cosa m'importano quei milioni, le ottanta che conosco mi disprezzano.\"}},\n",
       " {'id': '973',\n",
       "  'translation': {'en': '\"Jane, you are mistaken: probably not one in the school either despises or dislikes you: many, I am sure, pity you much.\"',\n",
       "   'it': \"— Jane, v'ingannate; è probabile che nessuna delle educande vi disprezzi, né vi odii; molte invece vi compiangono, ne sono sicura.\"}},\n",
       " {'id': '974',\n",
       "  'translation': {'en': '\"How can they pity me after what Mr. Brocklehurst has said?\"',\n",
       "   'it': '— Come possono compiangermi dopo quello che ha detto il signor Bockelhurst?'}},\n",
       " {'id': '975',\n",
       "  'translation': {'en': '\"Mr. Brocklehurst is not a god: nor is he even a great and admired man: he is little liked here; he never took steps to make himself liked.',\n",
       "   'it': '— Egli non è Dio, non è un uomo che riscuota fiducia.'}},\n",
       " {'id': '976',\n",
       "  'translation': {'en': 'Had he treated you as an especial favourite, you would have found enemies, declared or covert, all around you; as it is, the greater number would offer you sympathy if they dared.',\n",
       "   'it': 'Se vi avesse accordato speciali favori, avreste trovato intorno a voi delle nemiche, palesi o occulte. Ma dopo quello che è accaduto, quasi tutte vorrebbero attestarvi la loro simpatia, se potessero.'}},\n",
       " {'id': '977',\n",
       "  'translation': {'en': 'Teachers and pupils may look coldly on you for a day or two, but friendly feelings are concealed in their hearts; and if you persevere in doing well, these feelings will ere long appear so much the more evidently for their temporary suppression.',\n",
       "   'it': 'Maestre e alunne potranno guardarvi freddamente per un giorno o due, ma in cuore hanno sentimenti di amicizia e ve li manifesteranno con più effusione tra qualche tempo.'}},\n",
       " {'id': '978',\n",
       "  'translation': {'en': 'Besides, Jane\"--she paused.',\n",
       "   'it': 'Del resto, Jane.....'}},\n",
       " {'id': '979',\n",
       "  'translation': {'en': '\"Well, Helen?\" said I, putting my hand into hers: she chafed my fingers gently to warm them, and went on--',\n",
       "   'it': '— Ebbene, Elena? — dissi mettendo le mani nelle sue. Ella strinse dolcemente le mie dita per riscaldarle, e continuò:'}},\n",
       " {'id': '980',\n",
       "  'translation': {'en': '\"If all the world hated you, and believed you wicked, while your own conscience approved you, and absolved you from guilt, you would not be without friends.\"',\n",
       "   'it': \"— Se il mondo intero vi odiasse e vi credesse colpevole, ma la vostra coscienza vi approvasse, vi credereste forse priva di un'amica?\"}},\n",
       " {'id': '981',\n",
       "  'translation': {'en': '\"No; I know I should think well of myself; but that is not enough: if others don\\'t love me I would rather die than live--I cannot bear to be solitary and hated, Helen.',\n",
       "   'it': '— No, ma questo non basta per me. Se non mi sento amata, preferisco morire.'}},\n",
       " {'id': '982',\n",
       "  'translation': {'en': 'Look here; to gain some real affection from you, or Miss Temple, or any other whom I truly love, I would willingly submit to have the bone of my arm broken, or to let a bull toss me, or to stand behind a kicking horse, and let it dash its hoof at my chest--\"',\n",
       "   'it': 'Elena, vedete, per ottenere un vero affetto da voi, dalla signorina Temple e da tutti quelli cui voglio sinceramente bene, mi sottoporrei ad aver un braccio rotto, ad esser rotolata per terra da un toro, a stare dietro un cavallo furioso che mi desse un calcio nel petto.'}},\n",
       " {'id': '983',\n",
       "  'translation': {'en': '\"Hush, Jane! you think too much of the love of human beings; you are too impulsive, too vehement; the sovereign hand that created your frame, and put life into it, has provided you with other resources than your feeble self, or than creatures feeble as you.',\n",
       "   'it': \"Voi fate troppo conto dell'affetto terrestre; siete troppo impressionabile, troppo ardente. La mano sovrana, che ha creato il vostro corpo, vi ha infuso un soffio vitale, ha posto per voi delle risorse fuori di voi stessa e delle creature deboli come voi.\"}},\n",
       " {'id': '984',\n",
       "  'translation': {'en': 'Besides this earth, and besides the race of men, there is an invisible world and a kingdom of spirits: that world is round us, for it is everywhere; and those spirits watch us, for they are commissioned to guard us; and if we were dying in pain and shame, if scorn smote us on all sides, and hatred crushed us, angels see our tortures, recognise our innocence (if innocent we be: as I know you are of this charge which Mr. Brocklehurst has weakly and pompously repeated at second-hand from Mrs. Reed; for I read a sincere nature in your ardent eyes and on your clear front), and God waits only the separation of spirit from flesh to crown us with a full reward.',\n",
       "   'it': \"Al di là di questa terra vi è un regno invisibile; al disopra di questo mondo abitato dagli uomini, ve n'è uno abitato dagli spiriti, e questi spiriti vegliano su di noi, e se moriamo oppressi dalla vergogna e dal disprezzo, ci riconoscono innocenti, se tali siamo. Io so che siete innocente delle colpe attribuitevi dal direttore, perché ho riconosciuto nei vostri occhi ardenti e sulla vostra fronte pura, un'anima sincera.\"}},\n",
       " {'id': '985',\n",
       "  'translation': {'en': 'Why, then, should we ever sink overwhelmed with distress, when life is so soon over, and death is so certain an entrance to happiness--to glory?\"',\n",
       "   'it': 'Perché lasciarci abbattere dalla sventura, se la vita è così corta e la morte è il principio della felicità?'}},\n",
       " {'id': '986',\n",
       "  'translation': {'en': 'I was silent; Helen had calmed me; but in the tranquillity she imparted there was an alloy of inexpressible sadness.',\n",
       "   'it': 'Tacevo; Elena mi aveva calmata, ma la calma che avevami infusa era piena di tristezza.'}},\n",
       " {'id': '987',\n",
       "  'translation': {'en': 'I felt the impression of woe as she spoke, but I could not tell whence it came; and when, having done speaking, she breathed a little fast and coughed a short cough, I momentarily forgot my own sorrows to yield to a vague concern for her.',\n",
       "   'it': 'Quando ella ebbe terminato di parlare, respirava affannosamente e una tosse secca le scuoteva il petto. Dimenticai allora per un momento il mio stato per abbandonarmi a una vaga inquietudine.'}},\n",
       " {'id': '988',\n",
       "  'translation': {'en': \"Resting my head on Helen's shoulder, I put my arms round her waist; she drew me to her, and we reposed in silence.\",\n",
       "   'it': \"Reclinando la testa sulla spalla d'Elena, le cinsi con un braccio la vita.\"}},\n",
       " {'id': '989',\n",
       "  'translation': {'en': 'We had not sat long thus, when another person came in.',\n",
       "   'it': 'Ella mi trasse a sé, e restammo così in silenzio.'}},\n",
       " {'id': '990',\n",
       "  'translation': {'en': 'Some heavy clouds, swept from the sky by a rising wind, had left the moon bare; and her light, streaming in through a window near, shone full both on us and on the approaching figure, which we at once recognised as Miss Temple.',\n",
       "   'it': \"Un'altra persona entrò nella sala, e siccome la luna aveva squarciate le nubi e penetrava dalle finestre, ci accorgemmo che era la signorina Temple.\"}},\n",
       " {'id': '991',\n",
       "  'translation': {'en': '\"I came on purpose to find you, Jane Eyre,\" said she; \"I want you in my room; and as Helen Burns is with you, she may come too.\"',\n",
       "   'it': '— Venivo a prendervi, Jane — disse la direttrice. — Debbo parlarvi in camera mia, e siccome è qui Elena, può venire con noi.'}},\n",
       " {'id': '992',\n",
       "  'translation': {'en': \"We went; following the superintendent's guidance, we had to thread some intricate passages, and mount a staircase before we reached her apartment; it contained a good fire, and looked cheerful.\",\n",
       "   'it': 'Ci alzammo per seguirla, e dopo aver traversati diversi corridoi e salito una scala, entrammo nel quartiere della direttrice. Mi parve allegro, e vi era acceso un bel fuoco.'}},\n",
       " {'id': '993',\n",
       "  'translation': {'en': 'Miss Temple told Helen Burns to be seated in a low arm-chair on one side of the hearth, and herself taking another, she called me to her side.',\n",
       "   'it': \"La signorina Temple disse a Elena di sdraiarsi in una poltrona posta a fianco di lei; ella ne prese un'altra e mi attrasse a sé.\"}},\n",
       " {'id': '994',\n",
       "  'translation': {'en': '\"Is it all over?\" she asked, looking down at my face. \"Have you cried your grief away?\"',\n",
       "   'it': '— Vi siete consolata? — mi domandò guardandomi in faccia. — Avete sfogato il vostro cruccio?'}},\n",
       " {'id': '995',\n",
       "  'translation': {'en': '\"I am afraid I never shall do that.\"',\n",
       "   'it': '— Credo di non potermi consolare mai.'}},\n",
       " {'id': '996', 'translation': {'en': '\"Why?\"', 'it': '— Perché?'}},\n",
       " {'id': '997',\n",
       "  'translation': {'en': '\"Because I have been wrongly accused; and you, ma\\'am, and everybody else, will now think me wicked.\"',\n",
       "   'it': '— Perché sono stata ingiustamente accusata dinanzi a tutti, e voi stessa, signora, mi credete colpevole.'}},\n",
       " {'id': '998',\n",
       "  'translation': {'en': '\"We shall think you what you prove yourself to be, my child.',\n",
       "   'it': \"— Noi crederemo ciò che vedremo e ci formeremo un'opinione sulla vostra condotta, bambina mia.\"}},\n",
       " {'id': '999',\n",
       "  'translation': {'en': 'Continue to act as a good girl, and you will satisfy us.\"',\n",
       "   'it': 'Continuate ad esser buona, e mi contenterete.'}},\n",
       " ...]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "eng_it_data = []\n",
    "with open(\n",
    "    file = r\"datasets/train_eng_it.json\", \n",
    "    mode = \"r\", \n",
    "    encoding = \"utf-8\") as f:\n",
    "\n",
    "    for line in f:\n",
    "        eng_it_data.append(json.loads(line))\n",
    "\n",
    "eng_it_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "feba15a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train import get_all_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89c3235",
   "metadata": {},
   "source": [
    "### source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a671218d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object get_all_sentences at 0x000002251F31A430>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_it_source = get_all_sentences(\n",
    "    ds = eng_it_data,\n",
    "    lang = \"en\"\n",
    ")\n",
    "\n",
    "eng_it_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05ef26d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Source: Project Gutenberg'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(eng_it_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70019293",
   "metadata": {},
   "source": [
    "### target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a46730c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object get_all_sentences at 0x000002251F31A4A0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_it_target = get_all_sentences(\n",
    "    ds = eng_it_data,\n",
    "    lang = \"it\"\n",
    ")\n",
    "\n",
    "eng_it_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f82164a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Source: www.liberliber.it/Audiobook available here'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(eng_it_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6799f055",
   "metadata": {},
   "source": [
    "## eng-to-fil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d771957f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tagalog', 'english'],\n",
       "    num_rows: 84177\n",
       "})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "eng_fil_data = load_dataset(\n",
    "    \"rhyliieee/tagalog-filipino-english-translation\",\n",
    "    split = \"train\")\n",
    "\n",
    "eng_fil_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "95b2c0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train import get_all_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99f9146",
   "metadata": {},
   "source": [
    "### source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "463639e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object get_all_sentences at 0x000002251F31A9E0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_fil_source = get_all_sentences(\n",
    "    ds = eng_fil_data,\n",
    "    lang = \"english\"\n",
    ")\n",
    "\n",
    "eng_fil_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77752d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Describe what you would see if you went to the Grand Canyon.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(eng_fil_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5874ef7",
   "metadata": {},
   "source": [
    "### target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7f0f35ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object get_all_sentences at 0x000002251F3533C0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_fil_target = get_all_sentences(\n",
    "    ds = eng_fil_data,\n",
    "    lang = \"tagalog\"\n",
    ")\n",
    "\n",
    "eng_fil_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aeee9ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Ilarawan kung ano ang makikita mo kung pupunta ka sa Grand Canyon.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(eng_fil_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39546ae0",
   "metadata": {},
   "source": [
    "# **get_or_build_tokenizer() -> Tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ed7f6358",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train import get_or_build_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198d3150",
   "metadata": {},
   "source": [
    "## eng-to-fil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8657f7c",
   "metadata": {},
   "source": [
    "### source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "881ce2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tokenizers.Tokenizer at 0x2251d64f490>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_fil_src_tokenizer = get_or_build_tokenizer(\n",
    "    config = config,\n",
    "    ds = eng_fil_data,\n",
    "    lang = \"english\"\n",
    ")\n",
    "\n",
    "eng_fil_src_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe571c1",
   "metadata": {},
   "source": [
    "#### .get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ad5c50b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'glucose': 3550,\n",
       " 'Everyone': 6142,\n",
       " 'Em': 18501,\n",
       " '1812': 13307,\n",
       " 'calculating': 4148,\n",
       " 'gravely': 26842,\n",
       " 'Bordeaux': 28050,\n",
       " 'event': 585,\n",
       " 'Telephone': 18712,\n",
       " 'See': 9270,\n",
       " 'glimmered': 22715,\n",
       " 'unfolds': 14483,\n",
       " 'GPUs': 12084,\n",
       " 'origins': 5905,\n",
       " 'servings': 14963,\n",
       " 'yo': 11768,\n",
       " 'Adults': 20471,\n",
       " 'flavonoids': 26789,\n",
       " 'Arkansas': 16823,\n",
       " 'workshop': 11028,\n",
       " 'Caves': 23460,\n",
       " 'CTA': 13337,\n",
       " 'contributed': 4928,\n",
       " 'Repetitive': 23933,\n",
       " 'trenches': 25060,\n",
       " 'gene': 5010,\n",
       " 'measurement': 6237,\n",
       " 'Warning': 24073,\n",
       " 'Road': 5782,\n",
       " 'Paella': 19597,\n",
       " 'tapestry': 12027,\n",
       " 'Cardio': 16188,\n",
       " 'resided': 24857,\n",
       " 'jealousy': 22798,\n",
       " 'Provide': 678,\n",
       " 'Zhang': 29250,\n",
       " 'keeps': 4051,\n",
       " 'chilies': 19817,\n",
       " 'evident': 6173,\n",
       " 'Allocate': 12618,\n",
       " 'clot': 24258,\n",
       " 'Dollar': 12643,\n",
       " 'deregulation': 22603,\n",
       " 'pharmacy': 27236,\n",
       " 'ethnicities': 19921,\n",
       " 'internet': 521,\n",
       " 'gray': 5987,\n",
       " 'toilets': 8574,\n",
       " 'MagSafe': 20746,\n",
       " 'Startups': 19666,\n",
       " 'Approval': 25343,\n",
       " 'brush': 4721,\n",
       " 'suffix': 19202,\n",
       " 'Substance': 24006,\n",
       " 'Oklahoma': 16300,\n",
       " 'happiest': 21241,\n",
       " 'plane': 5542,\n",
       " 'Assignment': 25362,\n",
       " 'walls': 2680,\n",
       " 'nucleic': 21369,\n",
       " 'Turkey': 7540,\n",
       " 'guy': 11929,\n",
       " 'Chancellor': 14551,\n",
       " 'Conversational': 19403,\n",
       " 'accredited': 26326,\n",
       " 'variable': 894,\n",
       " 'Acceptance': 14528,\n",
       " 'Protocol': 7048,\n",
       " 'Vegetable': 9436,\n",
       " 'Kiss': 22082,\n",
       " 'alien': 4398,\n",
       " 'Costume': 25509,\n",
       " 'kicked': 18983,\n",
       " '10m': 19302,\n",
       " 'Prompt': 13408,\n",
       " 'bucket': 9150,\n",
       " 'confirming': 14290,\n",
       " 'financials': 17214,\n",
       " 'riders': 12000,\n",
       " 'sugary': 8821,\n",
       " 'recyclable': 9798,\n",
       " 'Caffeine': 11793,\n",
       " 'ratios': 12865,\n",
       " 'manufactures': 21332,\n",
       " 'promising': 6541,\n",
       " 'Urbanization': 13844,\n",
       " 'microorganisms': 9777,\n",
       " 'IMF': 13781,\n",
       " 'fret': 15374,\n",
       " 'Attitude': 17594,\n",
       " 'bonds': 3336,\n",
       " 'City': 2027,\n",
       " 'utensils': 5817,\n",
       " 'necessities': 9619,\n",
       " 'distortion': 19894,\n",
       " 'interlocking': 26961,\n",
       " 'exiled': 29833,\n",
       " 'contracted': 21094,\n",
       " 'singing': 4116,\n",
       " 'Wisely': 26289,\n",
       " 'balances': 7290,\n",
       " 'purchase': 978,\n",
       " 'politician': 9626,\n",
       " 'Developer': 8462,\n",
       " 'donations': 11645,\n",
       " 'pinks': 11978,\n",
       " 'Capacity': 14548,\n",
       " 'collections': 8896,\n",
       " 'maximizes': 13974,\n",
       " 'transmits': 27553,\n",
       " 'Raising': 10446,\n",
       " 'Nestled': 19580,\n",
       " 'Moderation': 23812,\n",
       " 'patience': 4341,\n",
       " 'marshmallow': 24641,\n",
       " 'what': 152,\n",
       " 'Skywalker': 22290,\n",
       " 'egalitarian': 21159,\n",
       " 'registering': 13635,\n",
       " 'MP3': 19552,\n",
       " 'Bruschetta': 28067,\n",
       " 'Lime': 28583,\n",
       " 'instantaneous': 13568,\n",
       " 'Crime': 15631,\n",
       " 'prefixes': 21426,\n",
       " 'nomads': 27167,\n",
       " 'harvests': 24486,\n",
       " 'wetlands': 8971,\n",
       " 'woodland': 23220,\n",
       " 'RISC': 18656,\n",
       " 'judgmental': 18110,\n",
       " 'fairness': 5257,\n",
       " 'XPS': 22366,\n",
       " 'cheese': 1186,\n",
       " 'drip': 8388,\n",
       " 'magazines': 8785,\n",
       " 'irrigation': 6049,\n",
       " 'carvings': 14715,\n",
       " 'subtitles': 21566,\n",
       " 'Fire': 7113,\n",
       " 'predictor': 9792,\n",
       " 'journaling': 13965,\n",
       " 'swapped': 10584,\n",
       " 'Labrador': 14593,\n",
       " 'impostor': 26928,\n",
       " 'misconduct': 20078,\n",
       " 'walking': 1501,\n",
       " 'scalene': 18246,\n",
       " 'Dodgers': 18488,\n",
       " '634': 27875,\n",
       " 'floral': 11180,\n",
       " '<<': 5364,\n",
       " 'performed': 3214,\n",
       " 'displacing': 17996,\n",
       " 'OpenWeather': 28748,\n",
       " 'pleasing': 7325,\n",
       " '🎉': 21677,\n",
       " 'encyclopedias': 21171,\n",
       " 'conduction': 21089,\n",
       " 'crepe': 16464,\n",
       " 'Samsung': 4374,\n",
       " 'Advice': 21797,\n",
       " 'sharper': 23072,\n",
       " 'Bailey': 28012,\n",
       " 'Shoelace': 29001,\n",
       " 'spatula': 6489,\n",
       " 'erupted': 16497,\n",
       " 'shifted_char': 20255,\n",
       " ':**-': 4638,\n",
       " 'explores': 3286,\n",
       " 'Marvel': 10221,\n",
       " 'supplement': 12579,\n",
       " 'floorboards': 22695,\n",
       " 'signal': 3617,\n",
       " 'persistence': 7671,\n",
       " 'Tokenization': 20907,\n",
       " 'driver': 3402,\n",
       " 'seize': 13248,\n",
       " 'obesity': 4260,\n",
       " 'fallacy': 5947,\n",
       " 'circulation': 7294,\n",
       " 'remorse': 21467,\n",
       " 'anxious': 7731,\n",
       " 'millennia': 24664,\n",
       " 'fulfilling': 4190,\n",
       " 'chessboard': 15293,\n",
       " 'shoreline': 16695,\n",
       " 'comparable': 14732,\n",
       " 'Animation': 17587,\n",
       " 'diving': 9908,\n",
       " 'Livestock': 13009,\n",
       " 'corrupted': 13900,\n",
       " 'Effect': 8850,\n",
       " 'parfait': 18175,\n",
       " '_ratio': 20961,\n",
       " 'Penetration': 28797,\n",
       " 'Biological': 21835,\n",
       " 'Caps': 25448,\n",
       " 'lands': 4757,\n",
       " 'crevices': 21106,\n",
       " 'Interviewee': 13783,\n",
       " 'Leading': 15160,\n",
       " 'Orb': 28753,\n",
       " 'luggage': 13191,\n",
       " '289': 27817,\n",
       " 'Seuss': 18683,\n",
       " 'Pharaohs': 28809,\n",
       " 'ascii_uppercase': 29385,\n",
       " 'sightseeing': 17440,\n",
       " 'Choosing': 7801,\n",
       " 'refuse': 15475,\n",
       " 'punctual': 11457,\n",
       " 'V': 3465,\n",
       " 'monitored': 8197,\n",
       " 'spoke': 5110,\n",
       " 'Print': 5741,\n",
       " 'objectively': 15979,\n",
       " 'migrating': 21345,\n",
       " 'driest': 26698,\n",
       " 'continents': 7064,\n",
       " '1876': 17550,\n",
       " 'informing': 11677,\n",
       " 'absorbs': 9438,\n",
       " '1974': 15062,\n",
       " 'Categorize': 1716,\n",
       " 'paddle': 14897,\n",
       " 'dome': 18873,\n",
       " 'left_height': 24611,\n",
       " '?\".': 16161,\n",
       " 'Full': 9255,\n",
       " 'Damien': 21912,\n",
       " 'Trojans': 29146,\n",
       " 'Dairy': 10857,\n",
       " 'Deco': 23527,\n",
       " 'transferred': 6788,\n",
       " 'tablecloth': 21583,\n",
       " 'patents': 24745,\n",
       " 'MakeADifference': 28614,\n",
       " 'Swim': 20893,\n",
       " '\"`,': 27695,\n",
       " 'Loyal': 18584,\n",
       " 'footsteps': 11922,\n",
       " 'Scrabble': 26074,\n",
       " 'lifespans': 22826,\n",
       " 'breed': 6395,\n",
       " 'fictional': 4253,\n",
       " 'microbiome': 27107,\n",
       " 'Slack': 13422,\n",
       " 'Givenchy': 22003,\n",
       " 'spurred': 19186,\n",
       " 'butter': 1287,\n",
       " 'advisors': 13072,\n",
       " 'corrupt': 13111,\n",
       " 'Important': 14186,\n",
       " 'cell': 1189,\n",
       " 'Builder': 21845,\n",
       " 'overlooked': 10332,\n",
       " 'contemplative': 19847,\n",
       " 'binding': 10055,\n",
       " '\"\"': 12051,\n",
       " 'Tortoise': 19687,\n",
       " 'superposition': 11483,\n",
       " 'Wine': 16372,\n",
       " 'fit': 1488,\n",
       " ':`': 5363,\n",
       " 'organize': 1761,\n",
       " 'ratings': 4598,\n",
       " 'promptly': 4099,\n",
       " 'tow': 25050,\n",
       " 'Coriolis': 17645,\n",
       " 'amid': 26351,\n",
       " 'conflicts': 2854,\n",
       " 'daughters': 29670,\n",
       " 'Einstein': 3891,\n",
       " 'D3': 18474,\n",
       " 'TrueDepth': 29149,\n",
       " 'overworked': 27208,\n",
       " 'advises': 24117,\n",
       " 'barrels': 24161,\n",
       " 'kind': 1281,\n",
       " 'tarantula': 27510,\n",
       " 'ZIP': 26303,\n",
       " 'Search': 2938,\n",
       " '7am': 25277,\n",
       " 'aerial': 10253,\n",
       " 'Principle': 11094,\n",
       " 'Solution': 10449,\n",
       " 'Allow': 4562,\n",
       " 'formidable': 11406,\n",
       " 'dining': 3752,\n",
       " 'interpretations': 12815,\n",
       " \"!')\": 15561,\n",
       " 'Hughes': 16923,\n",
       " 'chi': 17933,\n",
       " 'bogged': 21024,\n",
       " 'Capybara': 23455,\n",
       " 'Disconnect': 23543,\n",
       " 'RecipeIngredients': 9860,\n",
       " 'Platforms': 13404,\n",
       " 'comprising': 17943,\n",
       " '.\";': 27734,\n",
       " 'Blocks': 28044,\n",
       " 'trust': 1273,\n",
       " 'AC': 8979,\n",
       " 'Inventory': 11309,\n",
       " 'Yet': 11605,\n",
       " 'segmenting': 18253,\n",
       " 'monotony': 17330,\n",
       " 'Ride': 13819,\n",
       " 'Gonna': 28396,\n",
       " 'implying': 9477,\n",
       " 'keen': 9326,\n",
       " 'Jack': 1262,\n",
       " 'aerators': 29310,\n",
       " 'colonized': 19829,\n",
       " 'pranks': 21421,\n",
       " '1830': 23287,\n",
       " 'onboard': 15443,\n",
       " 'flexibility': 1538,\n",
       " 'impromptu': 26929,\n",
       " 'dictate': 10487,\n",
       " 'picks': 18188,\n",
       " 'hoping': 5895,\n",
       " 'Stellar': 26133,\n",
       " 'six': 2313,\n",
       " 'cardholder': 18811,\n",
       " 'reflect': 2510,\n",
       " 'employee': 1316,\n",
       " 'riches': 12875,\n",
       " 'Coordinate': 14562,\n",
       " 'dressed': 6340,\n",
       " 'Decorate': 21915,\n",
       " 'manuscripts': 22844,\n",
       " 'Isle': 22058,\n",
       " 'continue': 860,\n",
       " 'Hermione': 8990,\n",
       " 'pastries': 12265,\n",
       " 'remedy': 15479,\n",
       " 'Mystery': 10440,\n",
       " 'learner': 11685,\n",
       " 'Conference': 8846,\n",
       " 'Culture': 8124,\n",
       " 'sandals': 15494,\n",
       " 'undergrowth': 17500,\n",
       " 'explore': 845,\n",
       " 'directory': 8512,\n",
       " 'Fortune': 20644,\n",
       " '2f': 16155,\n",
       " 'Presley': 28848,\n",
       " 'arrows': 16403,\n",
       " 'scuba': 23060,\n",
       " 'Zalarians': 26304,\n",
       " 'shareholder': 18259,\n",
       " 'print_board': 27288,\n",
       " 'betterment': 18788,\n",
       " 'Night': 4643,\n",
       " 'involve': 1091,\n",
       " 'crispy': 7223,\n",
       " 'intimidate': 22786,\n",
       " 'Cheesy': 19391,\n",
       " 'parse': 15451,\n",
       " 'okra': 27181,\n",
       " 'facility': 8070,\n",
       " 'se': 23062,\n",
       " 'unpleasant': 11254,\n",
       " 'Circles': 23471,\n",
       " 'beaded': 29429,\n",
       " 'chromatic': 29548,\n",
       " 'genders': 13942,\n",
       " 'opposable': 22907,\n",
       " 'impressionist': 22759,\n",
       " 'giggling': 22711,\n",
       " 'judged': 18980,\n",
       " '797': 27887,\n",
       " 'lovely': 7757,\n",
       " 'puzzled': 24814,\n",
       " 'Million': 17759,\n",
       " 'peel': 10780,\n",
       " 'notation': 5263,\n",
       " 'packaged': 10333,\n",
       " 'Jetsetter': 22068,\n",
       " 'IntroductionA': 23715,\n",
       " 'whiteboard': 16767,\n",
       " 'happened': 3165,\n",
       " 'Closet': 25477,\n",
       " 'executes': 11395,\n",
       " 'Barbados': 23408,\n",
       " 'counterparts': 7931,\n",
       " 'Upbeat': 22333,\n",
       " 'behalf': 8500,\n",
       " 'Dental': 25540,\n",
       " 'compassionate': 6758,\n",
       " 'Securing': 28984,\n",
       " 'Oranges4': 28752,\n",
       " 'responsibility': 1540,\n",
       " 'employers': 4401,\n",
       " 'disabling': 24340,\n",
       " 'closer': 2761,\n",
       " 'Razer': 23923,\n",
       " 'undergone': 9094,\n",
       " 'Serbian': 26087,\n",
       " 'breathtakingly': 26446,\n",
       " 'swapping': 10585,\n",
       " 'contribution': 6222,\n",
       " 'approvals': 19757,\n",
       " 'fits': 3697,\n",
       " 'imports': 11419,\n",
       " 'abort': 20966,\n",
       " 'Below': 3046,\n",
       " 'versatile': 3311,\n",
       " 'communicative': 21085,\n",
       " 'mention': 7964,\n",
       " 'tacos': 10587,\n",
       " 'kicking': 22802,\n",
       " 'Crafts': 23504,\n",
       " 'sneezes': 12889,\n",
       " 'gif': 26828,\n",
       " '15px': 27769,\n",
       " 'inverse': 8777,\n",
       " 'unknowns': 20354,\n",
       " 'Engineers': 10207,\n",
       " 'Echo': 11808,\n",
       " 'biometrics': 26413,\n",
       " 'exacerbate': 6229,\n",
       " 'Some': 445,\n",
       " 'Ponzi': 28834,\n",
       " 'Engagement': 7807,\n",
       " 'hoax': 20005,\n",
       " 'performance': 304,\n",
       " 'relievers': 17413,\n",
       " 'whatever': 6793,\n",
       " 'sigmoid': 27417,\n",
       " 'Idiom': 25730,\n",
       " 'sweat': 12297,\n",
       " 'Honda': 14182,\n",
       " 'overloaded': 27205,\n",
       " 'b5': 29411,\n",
       " 'arrival': 7211,\n",
       " 'exhilarating': 9592,\n",
       " 'Going': 6377,\n",
       " 'Bike': 15091,\n",
       " 'woods': 4061,\n",
       " 'microgravity': 20074,\n",
       " 'Seeds': 20863,\n",
       " '%);': 27700,\n",
       " 'transmission': 3727,\n",
       " 'crashes': 9457,\n",
       " 'spacetime': 16707,\n",
       " '232': 21735,\n",
       " 'interview': 2012,\n",
       " 'waits': 23203,\n",
       " 'contributor': 7065,\n",
       " 'deals': 2414,\n",
       " 'associations': 9878,\n",
       " '].\"': 20959,\n",
       " 'wicking': 23213,\n",
       " 'wand': 11026,\n",
       " 'Adult': 15070,\n",
       " 'radar': 12552,\n",
       " 'Bengal': 15610,\n",
       " 'deter': 10717,\n",
       " 'Hawks': 17708,\n",
       " 'ironed': 26973,\n",
       " 'glaring': 29959,\n",
       " 'missed': 4902,\n",
       " 'delegate': 7741,\n",
       " 'shady': 17435,\n",
       " 'foreground': 13151,\n",
       " 'Fuels': 20649,\n",
       " 'honing': 18077,\n",
       " 'paperless': 10541,\n",
       " 'rhythmically': 27369,\n",
       " 'flare': 26786,\n",
       " 'Coastal': 14136,\n",
       " 'peppered': 22930,\n",
       " 'Aztec': 16830,\n",
       " 's2': 15493,\n",
       " 'Medications': 22129,\n",
       " '4286': 23322,\n",
       " 'loud': 3825,\n",
       " 'Empires': 28291,\n",
       " 'fledged': 29888,\n",
       " 'breeze': 2105,\n",
       " 'domino': 18005,\n",
       " 'jaguar': 22793,\n",
       " 'responsible': 921,\n",
       " 'Read': 3319,\n",
       " 'Afternoon': 11274,\n",
       " 'council': 11632,\n",
       " 'Max': 2424,\n",
       " 'mile': 7160,\n",
       " 'clung': 19823,\n",
       " 'gorillas': 19976,\n",
       " 'Terror': 12405,\n",
       " '();': 11509,\n",
       " 'elemental': 22646,\n",
       " 'Mauritius': 23793,\n",
       " 'investigate': 6178,\n",
       " 'abundant': 6154,\n",
       " 'pork': 7244,\n",
       " 'club': 5645,\n",
       " 'setbacks': 6063,\n",
       " 'hydrocarbons': 20014,\n",
       " 'chivalry': 29543,\n",
       " 'splicing': 24956,\n",
       " 'Tamil': 24018,\n",
       " 'intersect': 9324,\n",
       " 'blowtorch': 16418,\n",
       " 'layoffs': 16583,\n",
       " 'UserData': 29187,\n",
       " 'address': 701,\n",
       " 'protocols': 3586,\n",
       " 'stamps': 14987,\n",
       " '\"}': 18351,\n",
       " 'Vaccine': 22338,\n",
       " 'contaminating': 24295,\n",
       " '))^': 27716,\n",
       " 'contests': 7929,\n",
       " 'colloquial': 21079,\n",
       " 'PhD': 22195,\n",
       " 'stimulants': 19192,\n",
       " 'selecting': 2733,\n",
       " 'threatened': 6495,\n",
       " 'Abbey': 25310,\n",
       " 'charm': 6397,\n",
       " 'scans': 4633,\n",
       " 'Specifically': 8612,\n",
       " 'equality': 3082,\n",
       " 'rendering': 8945,\n",
       " 'arccos': 16400,\n",
       " 'Shine': 22281,\n",
       " 'safe': 1083,\n",
       " 'Amendment': 5591,\n",
       " 'calming': 4168,\n",
       " 'Final': 6962,\n",
       " '::': 11273,\n",
       " 'shorten': 16051,\n",
       " 'Wilson': 13067,\n",
       " '1845': 21724,\n",
       " 'elegant': 4421,\n",
       " 'sympathy': 14074,\n",
       " 'tight': 4768,\n",
       " 'Vital': 22343,\n",
       " 'classify': 1545,\n",
       " 'separable': 21505,\n",
       " 'touchpad': 16737,\n",
       " 'workout': 3933,\n",
       " 'audacious': 29400,\n",
       " 'prisoners': 15463,\n",
       " 'substantial': 6862,\n",
       " 'shower': 5730,\n",
       " 'bathed': 11615,\n",
       " 'philosophies': 17375,\n",
       " 'beauty': 858,\n",
       " 'precautionary': 24790,\n",
       " 'Steven': 11107,\n",
       " 'unavailable': 15539,\n",
       " 'talked': 7177,\n",
       " 'powdered': 11217,\n",
       " 'Vito': 13062,\n",
       " 'benevolent': 22458,\n",
       " 'beeswax': 29434,\n",
       " 'utilized': 5629,\n",
       " '’': 111,\n",
       " 'alterations': 17883,\n",
       " 'imprisonment': 15394,\n",
       " 'guiding': 6768,\n",
       " 'rises': 4320,\n",
       " 'blueprint': 11360,\n",
       " 'Assistive': 20494,\n",
       " 'wavefunction': 25107,\n",
       " 'opponents': 9620,\n",
       " 'vital': 1739,\n",
       " 'phones': 2546,\n",
       " '804': 27890,\n",
       " 'cumulonimbus': 22574,\n",
       " 'alla': 29327,\n",
       " 'fetched': 29870,\n",
       " 'RAM': 3639,\n",
       " 'young': 693,\n",
       " 'renew': 14029,\n",
       " 'rehabilitation': 9501,\n",
       " 'malaria': 18125,\n",
       " 'Comma': 21885,\n",
       " 'mathdef': 22849,\n",
       " 'spills': 8694,\n",
       " 'removed': 4268,\n",
       " 'assesses': 19763,\n",
       " 'Reactant': 28892,\n",
       " 'innovation': 1421,\n",
       " 'USB': 7127,\n",
       " 'Raspberries': 28888,\n",
       " 'portals': 17385,\n",
       " 'liability': 6773,\n",
       " 'championship': 22506,\n",
       " 'timers': 20324,\n",
       " 'lucid': 27067,\n",
       " 'ISS': 14185,\n",
       " 'arrests': 24139,\n",
       " 'owing': 24730,\n",
       " 'cash': 3353,\n",
       " 'rental': 5668,\n",
       " 'lifetime': 4518,\n",
       " 'uncooked': 16746,\n",
       " 'Operational': 18618,\n",
       " 'located': 1296,\n",
       " 'ACA': 23350,\n",
       " '3print': 27838,\n",
       " 'rustling': 4909,\n",
       " 'Keyword': 13003,\n",
       " 'Governor': 15661,\n",
       " 'suppress': 12022,\n",
       " 'shop': 2699,\n",
       " 'Processor': 10664,\n",
       " 'Attribute': 18420,\n",
       " 'fine': 2316,\n",
       " 'Weasley': 13065,\n",
       " 'pursuit': 4265,\n",
       " 'hopes': 7233,\n",
       " 'refrigeration': 21463,\n",
       " 'iterated': 22791,\n",
       " 'Browser': 15098,\n",
       " 'widespread': 2548,\n",
       " 'lore': 24624,\n",
       " 'cashback': 17926,\n",
       " \"'-'\": 25150,\n",
       " 'prides': 17391,\n",
       " 'journals': 13579,\n",
       " 'Jan': 16264,\n",
       " 'suggested': 4301,\n",
       " 'Simplicity': 14646,\n",
       " 'paying': 3659,\n",
       " 'anxiety': 1380,\n",
       " 'zoos': 16131,\n",
       " 'Proposition': 23903,\n",
       " 'shortcomings': 14435,\n",
       " 'dictatorship': 14303,\n",
       " 'infant': 24545,\n",
       " 'News': 6209,\n",
       " 'Infinity': 12658,\n",
       " 'Shifting': 22280,\n",
       " 'loans': 5045,\n",
       " 'Obtuse': 28737,\n",
       " 'Francisco': 3780,\n",
       " 'fluctuate': 8761,\n",
       " 'Consumption': 13347,\n",
       " '61': 9531,\n",
       " 'LDL': 20718,\n",
       " 'VALUES': 29190,\n",
       " 'Vacation': 17858,\n",
       " 'mitts': 21351,\n",
       " 'incisions': 26934,\n",
       " 'composted': 26553,\n",
       " 'Eurasia': 25597,\n",
       " 'connecting': 3469,\n",
       " 'cylindrical': 15328,\n",
       " 'piles': 19064,\n",
       " 'preferring': 21425,\n",
       " 'shard': 27405,\n",
       " 'autocrat': 17904,\n",
       " 'Continual': 23496,\n",
       " 'flees': 26792,\n",
       " 'Antioxidants': 27965,\n",
       " 'boosted': 22474,\n",
       " 'enforces': 24380,\n",
       " 'Investigating': 28508,\n",
       " 'domesticated': 11908,\n",
       " 'serotonin': 14962,\n",
       " 'blur': 15275,\n",
       " 'hoot': 22739,\n",
       " 'pilgrimage': 21409,\n",
       " 'popular': 424,\n",
       " 'growing': 1200,\n",
       " '2022': 6870,\n",
       " 'Ohio': 16974,\n",
       " 'whereby': 17523,\n",
       " 'Grief': 28405,\n",
       " 'Let': 1214,\n",
       " 'towers': 12585,\n",
       " 'Maine': 15166,\n",
       " 'duplications': 29765,\n",
       " 'loaf': 11951,\n",
       " 'wasn': 4407,\n",
       " '__name__': 13438,\n",
       " 'Break': 4773,\n",
       " 'Clara': 15103,\n",
       " 'theaters': 11750,\n",
       " 'Winning': 22360,\n",
       " 'Criticism': 28186,\n",
       " 'Utilize': 3385,\n",
       " 'Eco': 7192,\n",
       " 'boycotts': 26442,\n",
       " 'blazed': 24175,\n",
       " ':![': 25286,\n",
       " 'scattering': 12005,\n",
       " 'spectacle': 15509,\n",
       " 'Relativity': 11841,\n",
       " 'visualizing': 13697,\n",
       " '3G': 15589,\n",
       " 'Gregoire': 25674,\n",
       " 'melatonin': 22852,\n",
       " 'Crimson': 28185,\n",
       " 'reverse': 3422,\n",
       " 'above5': 29286,\n",
       " 'la1': 24604,\n",
       " 'teachings': 9972,\n",
       " 'unsustainable': 11758,\n",
       " 'Southern': 5931,\n",
       " 'target_sum': 21586,\n",
       " 'chromosomes': 8638,\n",
       " 'heatmap': 19993,\n",
       " 'Eastern': 5926,\n",
       " 'softly': 8816,\n",
       " 'Derivatives': 23533,\n",
       " 'centerpieces': 22503,\n",
       " 'padding': 5906,\n",
       " 'interpret': 2130,\n",
       " 'cups': 2115,\n",
       " 'April': 3992,\n",
       " 'Blender': 11531,\n",
       " 'bookbinding': 26433,\n",
       " 'fluff': 22696,\n",
       " 'teaching': 2296,\n",
       " 'remedies': 15478,\n",
       " 'wreaking': 27657,\n",
       " 'summit': 8568,\n",
       " 'tide': 8439,\n",
       " 'gravitation': 10310,\n",
       " 'Recursive': 22240,\n",
       " 'amongst': 7543,\n",
       " 'blouse': 15804,\n",
       " '/?': 27738,\n",
       " 'examined': 10947,\n",
       " 'tirelessly': 5316,\n",
       " 'Bull': 18442,\n",
       " 'McDonald': 18593,\n",
       " 'Austen': 8235,\n",
       " 'lightbulb': 14854,\n",
       " 'c1': 15284,\n",
       " 'cmTherefore': 29566,\n",
       " 'deleted': 12760,\n",
       " 'poured': 12852,\n",
       " 'Slides': 20876,\n",
       " 'Vendor': 22339,\n",
       " 'Lucas': 13010,\n",
       " 'intricately': 14358,\n",
       " 'frameworks': 5097,\n",
       " 'wished': 9382,\n",
       " 'orientations': 22910,\n",
       " 'Environmentally': 12357,\n",
       " 'misplaced': 18136,\n",
       " 'corpus': 8169,\n",
       " 'satisfy': 7495,\n",
       " '2017': 5632,\n",
       " 'defendant': 17154,\n",
       " 'Vienna': 20938,\n",
       " 'lithosphere': 21318,\n",
       " 'readmission': 27321,\n",
       " 'luminosity': 17307,\n",
       " 'Fats': 23591,\n",
       " 'procedure': 6245,\n",
       " '(*)': 13301,\n",
       " 'knelt': 27011,\n",
       " 'headed': 7477,\n",
       " 'TTS': 17044,\n",
       " 'Bibliography': 28031,\n",
       " 'engine': 1232,\n",
       " 'alive': 3271,\n",
       " 'Contractor': 16201,\n",
       " 'parties': 1957,\n",
       " 'Intense': 17725,\n",
       " 'ambient_light': 24129,\n",
       " 'Venezuela': 14240,\n",
       " 'breakfast': 2287,\n",
       " 'APA': 10836,\n",
       " 'necklace': 8411,\n",
       " 'NLU': 12375,\n",
       " 'mats': 20063,\n",
       " 'oppressed': 21381,\n",
       " 'Marxism': 22123,\n",
       " 'Exposition': 19451,\n",
       " 'charitable': 9727,\n",
       " 'retail': 3438,\n",
       " '1951': 12612,\n",
       " 'all_combinations': 20981,\n",
       " 'f2': 26757,\n",
       " 'Elephant3': 21947,\n",
       " 'GA': 23623,\n",
       " 'play': 543,\n",
       " 'defrost': 22593,\n",
       " 'AZ': 25309,\n",
       " 'paws': 11975,\n",
       " 'Physical': 2917,\n",
       " 'pharmacist': 27235,\n",
       " 'Familia': 28328,\n",
       " 'mascot': 11431,\n",
       " 'subarray': 17461,\n",
       " 'Manipulation': 23784,\n",
       " 'curves': 9167,\n",
       " 'fake': 4212,\n",
       " 'Bias': 6373,\n",
       " 'Industry': 8856,\n",
       " 'Consuming': 10409,\n",
       " 'Are': 2487,\n",
       " 'centimeter': 21053,\n",
       " 'delimiter': 26641,\n",
       " 'manufacturer': 5143,\n",
       " 'Theater': 17844,\n",
       " 'amphibian': 10917,\n",
       " 'annum': 26355,\n",
       " 'Dividing': 19420,\n",
       " 'if': 116,\n",
       " 'ignorance': 18082,\n",
       " 'Deploy': 9679,\n",
       " 'Dispose': 16219,\n",
       " 'ts': 23177,\n",
       " 'washing': 3347,\n",
       " 'adjective': 2772,\n",
       " '6So': 21759,\n",
       " 'mol': 9062,\n",
       " 'persona': 12267,\n",
       " 'liable': 18117,\n",
       " 'E7': 19427,\n",
       " 'Davis': 20579,\n",
       " 'pessimistic': 22936,\n",
       " 'Aperture': 25341,\n",
       " 'traceability': 25051,\n",
       " 'contents': 6522,\n",
       " 'confidently': 8506,\n",
       " 'modelmodel': 27124,\n",
       " 'parsley': 6242,\n",
       " 'guarded': 11927,\n",
       " 'Perseverance': 12115,\n",
       " 'survive': 2758,\n",
       " 'minced': 4259,\n",
       " 'Edition': 23561,\n",
       " 'knocked': 15953,\n",
       " 'church': 11624,\n",
       " 'peril': 21404,\n",
       " 'aristocratic': 24138,\n",
       " 'Waterproof': 18744,\n",
       " 'blockbuster': 24177,\n",
       " 'Auriel': 23400,\n",
       " 'Transaction': 17849,\n",
       " 'mimics': 20076,\n",
       " 'Unpredictability': 26228,\n",
       " 'ConclusionA': 25493,\n",
       " 'belongs': 4245,\n",
       " 'biological': 5212,\n",
       " 'Geothermal': 14172,\n",
       " 'hairdryer': 26852,\n",
       " 'celsius_to_fahrenheit': 29524,\n",
       " 'afternoon': 3939,\n",
       " 'war': 1770,\n",
       " 'Carnival': 28099,\n",
       " 'bobbing': 29459,\n",
       " 'army': 6030,\n",
       " 'ab': 29279,\n",
       " 'clutch': 13478,\n",
       " 'Makes': 20748,\n",
       " 'potted': 21420,\n",
       " 'reorganizing': 19130,\n",
       " 'Randomness': 28885,\n",
       " 'prescriptive': 19082,\n",
       " 'Recurrent': 11099,\n",
       " 'conditions': 564,\n",
       " 'strategy': 752,\n",
       " 'resonates': 7494,\n",
       " 'seamless': 3256,\n",
       " 'combustion': 8166,\n",
       " 'emigration': 29783,\n",
       " 'infographics': 6235,\n",
       " 'cybersecurity': 6634,\n",
       " 'addicted': 24114,\n",
       " 'recordings': 12866,\n",
       " 'scars': 23053,\n",
       " 'Intelligence': 1871,\n",
       " 'Jolly': 25768,\n",
       " 'universal': 5245,\n",
       " 'Venice': 14658,\n",
       " 'mainstream': 17312,\n",
       " 'Glassdoor': 20659,\n",
       " 'Attending': 21815,\n",
       " 'award': 9146,\n",
       " 'Dehydration': 23529,\n",
       " ')?': 12603,\n",
       " 'acidic': 8489,\n",
       " 'representational': 20209,\n",
       " 'documents': 1760,\n",
       " 'trampoline': 17493,\n",
       " 'cocoa': 7296,\n",
       " 'Chasing': 23464,\n",
       " 'nursery': 18157,\n",
       " 'PTSD': 14214,\n",
       " 'basic': 927,\n",
       " 'hoses': 26898,\n",
       " '0b': 27750,\n",
       " 'fission': 9916,\n",
       " 'Static': 16342,\n",
       " 'expands': 7305,\n",
       " 'antics': 22416,\n",
       " 'deities': 14748,\n",
       " 'tenderness': 20313,\n",
       " 'availability_X': 29403,\n",
       " 'posters': 10545,\n",
       " 'province': 15466,\n",
       " 'River': 3534,\n",
       " 'ciabatta': 26510,\n",
       " 'hearings': 26878,\n",
       " 'coexistence': 26527,\n",
       " 'Toy': 13056,\n",
       " 'advancing': 6027,\n",
       " 'moving': 1537,\n",
       " 'essence': 3629,\n",
       " 'Olivia': 11316,\n",
       " 'response': 805,\n",
       " 'beers': 22457,\n",
       " 'internal': 2254,\n",
       " 'Works': 19714,\n",
       " 'Methodology': 19567,\n",
       " 'ounces': 7408,\n",
       " 'praise': 8311,\n",
       " 'sfumato': 24910,\n",
       " 'shared': 1366,\n",
       " 'dripping': 15350,\n",
       " 'Sunday': 8729,\n",
       " 'transistor': 15534,\n",
       " 'Kansas': 13786,\n",
       " 'grapple': 21235,\n",
       " '1813': 25210,\n",
       " 'discussing': 3355,\n",
       " 'libraries': 4364,\n",
       " 'NOAA': 16964,\n",
       " 'Inquiry': 22048,\n",
       " 'clientele': 29558,\n",
       " 'brand': 694,\n",
       " 'oxides': 9946,\n",
       " 'outlets': 8201,\n",
       " 'persuading': 24759,\n",
       " 'Purpose': 7364,\n",
       " 'Strategies': 7368,\n",
       " 'Astronauts': 21812,\n",
       " 'behold': 7546,\n",
       " 'Louisa': 28596,\n",
       " 'destined': 14753,\n",
       " 'Sacramento': 26055,\n",
       " 'Reusability': 26035,\n",
       " '1910': 25214,\n",
       " 'server': 1657,\n",
       " 'circuitry': 21063,\n",
       " 'Business': 3462,\n",
       " 'Delete': 6959,\n",
       " 'easily': 717,\n",
       " 'Efficiency': 3936,\n",
       " 'personally': 7575,\n",
       " 'yards': 12320,\n",
       " 'seashells': 13246,\n",
       " '58': 9662,\n",
       " 'considers': 13897,\n",
       " '&&': 17538,\n",
       " 'colours': 22530,\n",
       " '1632': 25204,\n",
       " 'fall': 1842,\n",
       " 'waterfalls': 12044,\n",
       " 'rephrased': 24849,\n",
       " 'dividend': 9907,\n",
       " 'Readability': 28894,\n",
       " 'Electric': 4639,\n",
       " 'la': 9327,\n",
       " 'Religious': 28910,\n",
       " 'JPEG': 20708,\n",
       " 'catfish': 26482,\n",
       " 'olive': 2266,\n",
       " 'ATP': 6311,\n",
       " 'add': 469,\n",
       " 'Bake': 4606,\n",
       " 'blissful': 29453,\n",
       " 'prehensile': 27280,\n",
       " 'Ariana': 27974,\n",
       " 'decaying': 24315,\n",
       " '(\"\\\\': 25153,\n",
       " 'refrigerator': 4554,\n",
       " 'F': 1086,\n",
       " 'milliseconds': 24666,\n",
       " '181': 23286,\n",
       " 'earphones': 26704,\n",
       " 'upheld': 25089,\n",
       " 'footprint': 1416,\n",
       " 'elevator': 12200,\n",
       " 'developer': 4229,\n",
       " 'automate': 2506,\n",
       " 'rotator': 23041,\n",
       " 'debilitating': 26625,\n",
       " 'begin': 1921,\n",
       " 'regulations': 1680,\n",
       " 'MySQL': 10024,\n",
       " 'Elegance': 28280,\n",
       " 'dwellers': 18015,\n",
       " 'income': 991,\n",
       " 'Changing': 7895,\n",
       " ...}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_fil_src_tokenizer.get_vocab(with_added_tokens = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f30901",
   "metadata": {},
   "source": [
    "#### .get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "11181cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_fil_src_tokenizer.get_vocab_size(with_added_tokens = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ef1930",
   "metadata": {},
   "source": [
    "#### .encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a133bd76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoding(num_tokens=13, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_src_text = eng_fil_src_tokenizer.encode(\n",
    "    sequence = \"Describe what you would see if you went to the Grand Canyon.\"\n",
    ")\n",
    "\n",
    "tokenized_src_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f81dd69",
   "metadata": {},
   "source": [
    "##### .tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "da1f52f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Describe',\n",
       " 'what',\n",
       " 'you',\n",
       " 'would',\n",
       " 'see',\n",
       " 'if',\n",
       " 'you',\n",
       " 'went',\n",
       " 'to',\n",
       " 'the',\n",
       " 'Grand',\n",
       " 'Canyon',\n",
       " '.']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_src_text.tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff067dca",
   "metadata": {},
   "source": [
    "##### .ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c98f923f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[240, 152, 29, 80, 340, 116, 29, 1379, 8, 6, 4881, 6072, 4]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_src_text.ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad90b932",
   "metadata": {},
   "source": [
    "##### .attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "15202b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_src_text.attention_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6e8d8f",
   "metadata": {},
   "source": [
    "#### .token_to_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "169db8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sos_token = eng_fil_src_tokenizer.token_to_id(\n",
    "    token = \"[SOS]\"\n",
    ")\n",
    "\n",
    "sos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4d62d4ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eos_token = eng_fil_src_tokenizer.token_to_id(\n",
    "    token = \"[EOS]\"\n",
    ")\n",
    "\n",
    "eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9086d807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_token = eng_fil_src_tokenizer.token_to_id(\n",
    "    token = \"[PAD]\"\n",
    ")\n",
    "\n",
    "pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8c61f487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_num_padding_tokens = config[\"seq_len\"] - len(tokenized_src_text.ids) - 2\n",
    "enc_num_padding_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f78fa5f",
   "metadata": {},
   "source": [
    "#### **ENCODER INPUT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c70dfd41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   2,  240,  152,   29,   80,  340,  116,   29, 1379,    8,    6, 4881,\n",
       "        6072,    4,    3,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "encoder_input = torch.cat(\n",
    "            [\n",
    "                torch.tensor([sos_token], dtype = torch.int64),\n",
    "                torch.tensor(tokenized_src_text.ids, dtype = torch.int64),\n",
    "                torch.tensor([eos_token], dtype = torch.int64),\n",
    "                torch.tensor([pad_token] * enc_num_padding_tokens, dtype = torch.int64),\n",
    "            ],\n",
    "            dim = 0,\n",
    "        ) \n",
    "\n",
    "encoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2e4c97c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([350])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881cb110",
   "metadata": {},
   "source": [
    "#### **ENCODER MASK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fadba300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_mask = (encoder_input != pad_token).unsqueeze(0).unsqueeze(0).int()\n",
    "encoder_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "96fc9971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 350])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a66f121",
   "metadata": {},
   "source": [
    "#### .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4b8b9629",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_fil_src_tokenizer.save(\"path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc35cbf",
   "metadata": {},
   "source": [
    "#### .decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ca2b6280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[SOS] Describe what you would see if you went to the Grand Canyon . [EOS] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_fil_src_tokenizer.decode(encoder_input.tolist(), \n",
    "                             skip_special_tokens = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16026f7a",
   "metadata": {},
   "source": [
    "### target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ab984d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tokenizers.Tokenizer at 0x2251d650890>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_fil_tgt_tokenizer = get_or_build_tokenizer(\n",
    "    config = config,\n",
    "    ds = eng_fil_data,\n",
    "    lang = \"tagalog\"\n",
    ")\n",
    "\n",
    "eng_fil_tgt_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da58586",
   "metadata": {},
   "source": [
    "#### .get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "17c12239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'16π': 29352,\n",
       " 'Janeiro': 16693,\n",
       " 'potluck': 21008,\n",
       " 'Explore': 24642,\n",
       " 'magwasak': 28465,\n",
       " 'sand': 26265,\n",
       " 'cool': 6240,\n",
       " 'paggapas': 26060,\n",
       " 'Concord': 21312,\n",
       " 'here': 15107,\n",
       " 'Monte': 17436,\n",
       " 'Bengal': 15983,\n",
       " 'keyword': 1361,\n",
       " 'Usain': 23318,\n",
       " 'x1': 4516,\n",
       " 'pamahalaang': 11757,\n",
       " 'Mahaba': 11081,\n",
       " 'laban': 755,\n",
       " 'intercept': 6129,\n",
       " 'rebolusyong': 11244,\n",
       " 'Nurse': 24993,\n",
       " 'Chinatown': 24551,\n",
       " '754': 29447,\n",
       " 'kabataang': 6547,\n",
       " 'tk': 21134,\n",
       " 'singaw': 3355,\n",
       " 'daang': 5103,\n",
       " 'distributor': 20598,\n",
       " 'lasa': 873,\n",
       " 'macroeconomics': 19610,\n",
       " 'Kahalagahan': 5285,\n",
       " 'tingga': 22518,\n",
       " 'Galahad': 18156,\n",
       " 'Munich': 15485,\n",
       " 'simpleng': 555,\n",
       " 'nakadapo': 25974,\n",
       " 'smart': 2322,\n",
       " 'toothbrush': 8655,\n",
       " 'Parthenon': 23161,\n",
       " 'pagkakabukod': 6322,\n",
       " 'pagtitiwala': 5070,\n",
       " 'Party': 4795,\n",
       " 'almond': 4439,\n",
       " 'tagal': 2678,\n",
       " 'ideya': 241,\n",
       " 'Cut': 15415,\n",
       " 'land': 15710,\n",
       " 'activated': 9169,\n",
       " 'Magento': 16712,\n",
       " 'binaliktad': 18410,\n",
       " '>\");': 18956,\n",
       " 'right': 4095,\n",
       " 'pagpapaalala': 18729,\n",
       " 'Capital': 12754,\n",
       " 'iniksyon': 23669,\n",
       " 'stepped': 29090,\n",
       " '1941': 10790,\n",
       " 'magkakalapit': 28441,\n",
       " 'salapi': 13448,\n",
       " 'atmosphere': 18395,\n",
       " 'kandidato': 1793,\n",
       " 'Electric': 11845,\n",
       " 'nagdidirekta': 16381,\n",
       " 'paghihimagsik': 12046,\n",
       " 'pulmonary': 17911,\n",
       " 'reticulum': 26242,\n",
       " 'Cosmic': 19033,\n",
       " 'magbigkis': 22128,\n",
       " 'pinakamasamang': 7793,\n",
       " 'galak': 17657,\n",
       " 'milyang': 28576,\n",
       " 'Peb': 20370,\n",
       " 'kawani': 3327,\n",
       " 'To': 3944,\n",
       " 'Redundancy': 27514,\n",
       " 'siyentipiko': 1131,\n",
       " 'Michael': 4626,\n",
       " 'compostable': 17617,\n",
       " 'not': 6889,\n",
       " 'Locke': 18216,\n",
       " '\"]:': 29279,\n",
       " 'aampon': 5724,\n",
       " 'career': 9662,\n",
       " 'Makokontrol': 24885,\n",
       " 'porcupine': 17906,\n",
       " 'Hyperledger': 20190,\n",
       " 'mangahulugan': 6557,\n",
       " 'estate': 5666,\n",
       " 'inilalapat': 8089,\n",
       " 'naglalakbay': 1849,\n",
       " 'Magmungkahi': 760,\n",
       " 'greenhouse': 804,\n",
       " 'nagpatakbo': 28647,\n",
       " 'Elián': 29834,\n",
       " 'friendly': 933,\n",
       " 'tutor': 10778,\n",
       " 'Lie': 27172,\n",
       " 'predisposition': 22391,\n",
       " 'teknikal': 1350,\n",
       " 'baron': 27849,\n",
       " 'breach': 27883,\n",
       " 'heograpiko': 28181,\n",
       " 'mantsa': 4120,\n",
       " 'demand': 1236,\n",
       " 'nakasalalay': 1570,\n",
       " 'binibigkas': 7743,\n",
       " 'law': 10065,\n",
       " 'barkong': 17590,\n",
       " 'Rubber': 19283,\n",
       " 'spend': 29074,\n",
       " 'hatid': 14608,\n",
       " 'stressor': 14798,\n",
       " 'Sikaping': 25161,\n",
       " 'Celsius': 2191,\n",
       " 'pagtutugma': 8372,\n",
       " 'mapupungay': 23843,\n",
       " 'Bhutan': 26715,\n",
       " 'tumambay': 29191,\n",
       " 'ikukumpara': 15669,\n",
       " 'oatmeal': 10720,\n",
       " 'Emily': 1936,\n",
       " 'extinct': 20626,\n",
       " 'halaya': 18502,\n",
       " 'umusbong': 11023,\n",
       " 'makamandag': 19644,\n",
       " 'Hobbes': 22899,\n",
       " 'maabala': 23775,\n",
       " 'Chromecast': 29707,\n",
       " 'bibisitahin': 10034,\n",
       " '__init__': 7532,\n",
       " 'korporasyong': 25749,\n",
       " '---------------------------------------|': 29310,\n",
       " 'ventilator': 29227,\n",
       " 'Vinci': 7840,\n",
       " 'map': 7391,\n",
       " 'inutang': 28258,\n",
       " 'scale': 3091,\n",
       " 'Pagkalugi': 23131,\n",
       " 'samantalahin': 4724,\n",
       " 'fraud': 28129,\n",
       " 'Pananagutan': 7025,\n",
       " 'pepperoni': 17883,\n",
       " 'Thunderbolt': 20440,\n",
       " 'kasanayan': 244,\n",
       " 'marunong': 5681,\n",
       " 'GCD': 7017,\n",
       " 'predictable': 9758,\n",
       " 'Seraphina': 25151,\n",
       " 'pagdedebate': 24016,\n",
       " 'Kumplikado': 14932,\n",
       " 'desperadong': 16913,\n",
       " 'elections': 23563,\n",
       " 'cafe': 4843,\n",
       " '3m': 21226,\n",
       " 'iunat': 15138,\n",
       " 'paumanhin': 3729,\n",
       " 'nandiyan': 7482,\n",
       " 'Joomla': 24784,\n",
       " 'kampeonato': 20723,\n",
       " 'Isinasaad': 17393,\n",
       " 'kapwa': 2423,\n",
       " 'nagkokonekta': 9718,\n",
       " 'tagapayo': 3956,\n",
       " 'Makakahanap': 13179,\n",
       " 'umuugong': 15922,\n",
       " 'Ginalugad': 16033,\n",
       " 'manggagawang': 4857,\n",
       " 'talamak': 5706,\n",
       " 'themed': 15329,\n",
       " 'Response': 21665,\n",
       " 'bubuti': 25401,\n",
       " 'pagdaan': 8493,\n",
       " 'maitayo': 19635,\n",
       " 'Tales': 20436,\n",
       " 'kabuluhan': 10241,\n",
       " 'subjective': 4725,\n",
       " 'makahuli': 19638,\n",
       " 'bakas': 5484,\n",
       " 'dict2': 20589,\n",
       " 'breathable': 17600,\n",
       " 'transparency': 2836,\n",
       " 'fountain': 12243,\n",
       " 'Isulong': 4762,\n",
       " 'appealing': 8190,\n",
       " 'measure': 11442,\n",
       " 'structures': 24213,\n",
       " 'hangang': 1817,\n",
       " 'suliranin': 12708,\n",
       " 'talaba': 29132,\n",
       " 'napipigilan': 17082,\n",
       " 'Sabha': 21685,\n",
       " 'modelo': 132,\n",
       " 'hayaan': 2992,\n",
       " 'Virtual': 3148,\n",
       " 'Nagresulta': 10831,\n",
       " 'smith': 29064,\n",
       " 'Bride': 21286,\n",
       " 'itulak': 3948,\n",
       " 'Resort': 25106,\n",
       " 'Independence': 16684,\n",
       " 'distribusyon': 7124,\n",
       " 'humahamon': 11975,\n",
       " 'sinubok': 26289,\n",
       " 'Isabelle': 19132,\n",
       " 'crepe': 14583,\n",
       " 'company': 8581,\n",
       " 'makukulay': 4314,\n",
       " 'kuwarta': 5579,\n",
       " 'Ferris': 19076,\n",
       " 'Halina': 20177,\n",
       " 'Balloon': 29578,\n",
       " 'kalmado': 2057,\n",
       " 'Ulitin': 2786,\n",
       " 'Regulasyon': 10842,\n",
       " 'dalawahang': 28008,\n",
       " 'Mapapabilis': 27233,\n",
       " 'kasamahan': 1827,\n",
       " 'ikatlong': 2221,\n",
       " 'sumisid': 10532,\n",
       " 'dataframe': 25474,\n",
       " 'ibinuka': 18518,\n",
       " 'malalaking': 456,\n",
       " 'Vermont': 25271,\n",
       " 'nilikha': 2041,\n",
       " 'Mughal': 14957,\n",
       " 'drainage': 18464,\n",
       " \"=['\": 24432,\n",
       " 'nagtakdang': 28659,\n",
       " 'common': 7851,\n",
       " 'akusahan': 27789,\n",
       " 'hunt': 6245,\n",
       " 'gilagid': 19495,\n",
       " 'first_name': 11151,\n",
       " '1794': 26543,\n",
       " 'Gohemoth': 29933,\n",
       " 'lumagda': 18591,\n",
       " 'Hiring': 13954,\n",
       " '>.': 16585,\n",
       " 'Factory': 26923,\n",
       " 'County': 17331,\n",
       " 'genera': 25567,\n",
       " 'nananagot': 26005,\n",
       " 'carbonate': 15601,\n",
       " 'Cy': 26841,\n",
       " 'Mga': 67,\n",
       " 'fresh': 11153,\n",
       " 'pusang': 11493,\n",
       " 'Gatsby': 3562,\n",
       " 'Pagsasayaw': 20355,\n",
       " 'Deferred': 26852,\n",
       " 'nagre': 7144,\n",
       " 'ilalarawan': 10232,\n",
       " 'coolant': 16243,\n",
       " 'SARS': 18311,\n",
       " 'ipinakilalang': 23691,\n",
       " 'logarithm': 8892,\n",
       " 'tradisyonalismo': 29180,\n",
       " 'Paghahati': 16746,\n",
       " 'nahahati': 1934,\n",
       " 'Heading': 17371,\n",
       " 'insekto': 3461,\n",
       " 'ipasa': 9195,\n",
       " 'edge': 5786,\n",
       " 'pagtatapon': 3452,\n",
       " 'Siyentipiko': 16802,\n",
       " 'pagkagat': 24022,\n",
       " 'resibo': 13057,\n",
       " 'Inilabas': 8980,\n",
       " 'benepisyo': 343,\n",
       " '{': 643,\n",
       " 'teleportasyon': 24244,\n",
       " 'trophic': 21140,\n",
       " 'epektong': 6944,\n",
       " 'fixed': 9497,\n",
       " 'Start': 10848,\n",
       " 'Karl': 19139,\n",
       " '2X': 17277,\n",
       " 'Peas': 21628,\n",
       " 'CaCl2': 26765,\n",
       " 'Force': 13944,\n",
       " 'Without': 27740,\n",
       " 'bbc': 27853,\n",
       " 'napakalaki': 3828,\n",
       " 'Year': 14047,\n",
       " 'makaharap': 13765,\n",
       " 'pastry': 9099,\n",
       " 'tabak': 17971,\n",
       " 'oats': 6501,\n",
       " 'dumadaan': 3721,\n",
       " 'after': 16197,\n",
       " 'params': 26138,\n",
       " 'nakasanayan': 20871,\n",
       " 'Nasisiyahan': 8551,\n",
       " 'dinisenyong': 28047,\n",
       " 'kaguluhang': 16984,\n",
       " 'Isalin': 3319,\n",
       " 'Carta': 14391,\n",
       " 'ASL': 18961,\n",
       " 'plano': 440,\n",
       " 'Natawa': 23098,\n",
       " 'larynx': 23749,\n",
       " 'Isinasaalang': 7820,\n",
       " 'nagkikita': 19702,\n",
       " 'bubuo': 3992,\n",
       " 'Alcatraz': 18051,\n",
       " 'magreklamo': 28456,\n",
       " 'char': 3839,\n",
       " 'Susi': 15008,\n",
       " 'salit': 15289,\n",
       " '√((-': 26469,\n",
       " 'radio': 7595,\n",
       " 'Mapagkukunan': 9616,\n",
       " 'bubble': 6294,\n",
       " 'Pamumuhunan': 12173,\n",
       " 'Student': 15547,\n",
       " 'rehistro': 22418,\n",
       " 'tugma': 4564,\n",
       " 'Nilapitan': 23105,\n",
       " 'tumutulong': 695,\n",
       " '1939': 8023,\n",
       " 'maipatupad': 10453,\n",
       " 'analitikal': 14062,\n",
       " 'nagpapaligsahan': 28641,\n",
       " 'Tawanan': 27646,\n",
       " 'grains': 17668,\n",
       " 'quarter': 5412,\n",
       " 'Bryant': 18078,\n",
       " 'recyclable': 10113,\n",
       " 'materials': 13773,\n",
       " 'napipilitang': 10479,\n",
       " 'oyayi': 15793,\n",
       " 'Pagpatay': 20354,\n",
       " 'authentication': 5144,\n",
       " 'Ibaba': 11857,\n",
       " 'gumuguhong': 25581,\n",
       " '6s': 21233,\n",
       " 'word1': 21173,\n",
       " 'tape': 5129,\n",
       " 'Huang': 24737,\n",
       " 'palma': 17866,\n",
       " 'ISP': 11066,\n",
       " 'umaga': 1640,\n",
       " 'Géron': 26984,\n",
       " 'nagsiwalat': 15766,\n",
       " 'capitalize': 12222,\n",
       " 'Droga': 26877,\n",
       " 'password_strength': 22354,\n",
       " 'kagalang': 5445,\n",
       " 'Diced': 26862,\n",
       " 'nagkukulang': 28626,\n",
       " 'Natigilan': 21577,\n",
       " 'naipakita': 19719,\n",
       " 'Gardens': 20155,\n",
       " 'webpage': 4480,\n",
       " 'Impact': 24756,\n",
       " 'pinagkakatiwalaan': 8500,\n",
       " 'babala': 4049,\n",
       " 'Binibigyang': 2485,\n",
       " 'Pagkakaiba': 6659,\n",
       " 'lason': 8095,\n",
       " 'Hosting': 24736,\n",
       " 'Manu': 24891,\n",
       " 'veggie': 18898,\n",
       " 'pagse': 5193,\n",
       " 'koala': 14167,\n",
       " 'kaligtasan': 763,\n",
       " 'CV': 8964,\n",
       " 'Environmental': 10571,\n",
       " 'Tinatawag': 12490,\n",
       " 'lastName': 22099,\n",
       " 'nami': 20877,\n",
       " 'NN': 14457,\n",
       " 'kumonekta': 1492,\n",
       " 'pagsipa': 26096,\n",
       " 'banal': 6291,\n",
       " 'McCarthy': 19184,\n",
       " 'kalokohan': 12575,\n",
       " 'ihain': 2499,\n",
       " '`/': 23356,\n",
       " 'Magkita': 27208,\n",
       " 'palawit': 20956,\n",
       " '\"[': 26472,\n",
       " 'daga': 3945,\n",
       " 'Bersyon': 24493,\n",
       " 'pagpili': 697,\n",
       " 'ginugol': 3582,\n",
       " 'dalamhati': 18449,\n",
       " 'libra': 12942,\n",
       " 'ipagpatuloy': 3277,\n",
       " 'naipon': 7146,\n",
       " 'facing': 18479,\n",
       " 'bone': 25393,\n",
       " 'community': 13672,\n",
       " '150': 3925,\n",
       " 'Chi': 21303,\n",
       " 'gonna': 15100,\n",
       " 'tulog': 2330,\n",
       " 'numeric': 10968,\n",
       " 'ikabubuti': 13314,\n",
       " 'Ring': 12472,\n",
       " 'chives': 17614,\n",
       " 'Parlamento': 27428,\n",
       " 'dinadaanan': 12227,\n",
       " '25lbs': 22634,\n",
       " 'editor': 4736,\n",
       " 'nakatanggap': 3915,\n",
       " 'ulan': 812,\n",
       " 'uulit': 3799,\n",
       " 'plastic': 1584,\n",
       " 'topping': 7007,\n",
       " 'total_substrings': 26391,\n",
       " 'aalab': 16193,\n",
       " 'kabisera': 3444,\n",
       " '75': 2755,\n",
       " 'Bolt': 13120,\n",
       " 'tingi': 11524,\n",
       " 'magpapadali': 13761,\n",
       " 'Senso': 27562,\n",
       " 'holder': 25602,\n",
       " 'nahaharap': 1943,\n",
       " 'Insert': 11068,\n",
       " 'Paano': 469,\n",
       " 'klinika': 9507,\n",
       " 'lambat': 12939,\n",
       " 'pinasimulan': 17151,\n",
       " 'OCR': 20334,\n",
       " 'nakakalimutan': 10952,\n",
       " ')*': 15944,\n",
       " 'Kelvin': 13574,\n",
       " 'footer': 6616,\n",
       " 'Money': 10174,\n",
       " 'pangkalusugan': 422,\n",
       " 'Spotify': 13630,\n",
       " 'Avengers': 7719,\n",
       " 'nagmartsa': 22223,\n",
       " '1870': 21209,\n",
       " 'kwelyo': 19589,\n",
       " 'Sushi': 18342,\n",
       " 'summarizer': 24225,\n",
       " 'balloon': 6353,\n",
       " 'ammonium': 25340,\n",
       " 'Immutability': 27043,\n",
       " '1920': 15361,\n",
       " 'organisa': 7990,\n",
       " 'Pagmemerkado': 9457,\n",
       " '---': 6057,\n",
       " 'logarithmic': 13341,\n",
       " 'getElementById': 21949,\n",
       " 'titigil': 8810,\n",
       " 'canopy': 7288,\n",
       " 'Booth': 26733,\n",
       " 'Kongreso': 6741,\n",
       " 'GUI': 8680,\n",
       " 'Pagbili': 12458,\n",
       " 'magalit': 16327,\n",
       " 'Capybara': 19013,\n",
       " '10001': 24352,\n",
       " 'Kantahan': 16054,\n",
       " 'maaprubahan': 22121,\n",
       " 'kredensyal': 7977,\n",
       " 'Provider': 14021,\n",
       " 'Ginugol': 6587,\n",
       " 'mapatawad': 25881,\n",
       " 'obj_color': 28739,\n",
       " 'Gherardini': 22869,\n",
       " 'Nagdaragdag': 10177,\n",
       " 'Tommy': 7442,\n",
       " '88': 10334,\n",
       " 'masunuring': 23854,\n",
       " 'chatbot': 1059,\n",
       " 'isolation': 16298,\n",
       " '6371': 26599,\n",
       " 'Bora': 21284,\n",
       " 'presentation': 8375,\n",
       " '______': 16187,\n",
       " 'upper_limit': 29218,\n",
       " 'baked': 11374,\n",
       " 'pagdukot': 28773,\n",
       " 'ginagalawan': 10048,\n",
       " 'nabubuo': 4063,\n",
       " 'Maingat': 4833,\n",
       " 'nakikiramay': 9904,\n",
       " 'sunflower': 14801,\n",
       " 'Pare': 14485,\n",
       " '127': 13900,\n",
       " 'umuwi': 5989,\n",
       " 'reseta': 12073,\n",
       " 'mungkahing': 19691,\n",
       " 'Hesus': 22897,\n",
       " 'species': 724,\n",
       " 'activities': 25322,\n",
       " 'stimulation': 29093,\n",
       " 'Nabigo': 18232,\n",
       " 'Translate': 16825,\n",
       " 'transportasyon': 454,\n",
       " 'matitigas': 15186,\n",
       " 'malagim': 17765,\n",
       " 'Nakarating': 13594,\n",
       " 'napunan': 18685,\n",
       " 'maaayos': 18595,\n",
       " '69': 10333,\n",
       " 'pagboluntaryo': 13801,\n",
       " 'paggalugad': 1479,\n",
       " 'mammal': 1838,\n",
       " 'PEMDAS': 19230,\n",
       " 'shaped': 29033,\n",
       " 'iginiit': 13312,\n",
       " 'iangkop': 8745,\n",
       " 'henerasyong': 21980,\n",
       " 'ridge': 26250,\n",
       " 'streak': 29097,\n",
       " 'impormasyon': 97,\n",
       " 'wastong': 828,\n",
       " 'nagaganap': 2660,\n",
       " 'Umakyat': 13641,\n",
       " 'candies': 25415,\n",
       " 'tango': 16527,\n",
       " 'Task': 12486,\n",
       " 'kabisa': 19565,\n",
       " 'JJ': 24781,\n",
       " 'presensya': 2098,\n",
       " 'panghabambuhay': 6568,\n",
       " 'pinakamatamis': 17149,\n",
       " 'proposisyon': 15843,\n",
       " 'antibiotic': 10864,\n",
       " 'Channel': 18089,\n",
       " 'pariralang': 968,\n",
       " 'Revised': 25110,\n",
       " 'chronological': 23477,\n",
       " 'paggastos': 2959,\n",
       " 'isinakripisyo': 25693,\n",
       " 'nakakumpleto': 20866,\n",
       " 'ln': 15160,\n",
       " 'nakakatawa': 6383,\n",
       " '(\"%': 24331,\n",
       " 'napakalalim': 18680,\n",
       " 'Node': 6597,\n",
       " 'liner': 13750,\n",
       " 'pagtatae': 13806,\n",
       " 'sasalubungin': 18821,\n",
       " 'Express': 13547,\n",
       " 'Alexandria': 24447,\n",
       " 'handa': 1296,\n",
       " 'panghihimasok': 11229,\n",
       " 'natumba': 23975,\n",
       " 'pinangarap': 8504,\n",
       " 'jargon': 7464,\n",
       " 'Natakot': 14964,\n",
       " 'Paglutas': 6282,\n",
       " 'Inilathala': 15447,\n",
       " 'nagpapasaya': 9899,\n",
       " 'is': 2315,\n",
       " 'mabait': 2184,\n",
       " 'nilalanghap': 10963,\n",
       " 'Beat': 22721,\n",
       " 'Numbers': 27352,\n",
       " 'maaapektuhan': 16326,\n",
       " 'duty': 28064,\n",
       " 'makasagot': 28501,\n",
       " 'scalene': 18823,\n",
       " 'systolic': 29124,\n",
       " 'nagtitiwala': 7233,\n",
       " '7': 113,\n",
       " 'my_list': 5685,\n",
       " 'maglibot': 18600,\n",
       " 'nagsa': 25956,\n",
       " 'tumahimik': 17237,\n",
       " 'inihandang': 6481,\n",
       " 'Paraan': 5568,\n",
       " 'Alert': 22685,\n",
       " '82': 9429,\n",
       " 'Gettysburg': 7178,\n",
       " 'sanitize': 29012,\n",
       " 'aalsa': 14533,\n",
       " 'bumbero': 10037,\n",
       " 'komprehensibo': 7297,\n",
       " 'Handmaid': 29968,\n",
       " 'uwi': 11025,\n",
       " 'pumapatak': 18788,\n",
       " 'konsumo': 22085,\n",
       " 'crop': 6538,\n",
       " 'pagdedeposito': 22302,\n",
       " 'prejudice': 26198,\n",
       " 'transcription': 29182,\n",
       " 'Ikatlong': 14913,\n",
       " '02': 10329,\n",
       " 'icebreaker': 28212,\n",
       " 'kasal': 4179,\n",
       " 'kumitil': 20743,\n",
       " 'D4': 21326,\n",
       " 'graph': 2522,\n",
       " 'sigarilyo': 13851,\n",
       " 'pawis': 12059,\n",
       " 'pananakot': 10289,\n",
       " 'maghanap': 1148,\n",
       " 'Effective': 10351,\n",
       " 'makaligtas': 14679,\n",
       " 'sensitivity': 9938,\n",
       " 'nagpapalaganap': 17805,\n",
       " 'subtask': 24219,\n",
       " 'martsa': 28543,\n",
       " 'pagprograma': 13416,\n",
       " 'Extract': 29856,\n",
       " 'natitira': 3101,\n",
       " 'impresyon': 5961,\n",
       " 'Stand': 19304,\n",
       " 'uugnay': 3159,\n",
       " 'Eisenhower': 15424,\n",
       " '1869': 21208,\n",
       " 'Spirit': 18336,\n",
       " 'Creationism': 26832,\n",
       " 'digit': 1700,\n",
       " 'pangmaramihang': 13031,\n",
       " 'panturista': 8257,\n",
       " 'suweldong': 18868,\n",
       " 'Gym': 24698,\n",
       " 'makipagkilala': 25856,\n",
       " 'Katulong': 24806,\n",
       " 'y1': 4621,\n",
       " 'binatikos': 27860,\n",
       " 'response': 6219,\n",
       " 'Sina': 7642,\n",
       " 'overhead': 8369,\n",
       " 'kaysa': 275,\n",
       " 'banyo': 6069,\n",
       " 'chime': 20553,\n",
       " 'Rate': 6177,\n",
       " 'demokratikong': 4051,\n",
       " 'magbabago': 7219,\n",
       " 'regulator': 17924,\n",
       " 'pagkakaiba': 202,\n",
       " 'kulang': 2760,\n",
       " 'Sparrow': 16159,\n",
       " 'D3': 19039,\n",
       " 'Bolshevik': 22732,\n",
       " 'Norwegian': 24989,\n",
       " 'Clear': 22766,\n",
       " 'success': 19918,\n",
       " 'panlaban': 24055,\n",
       " '—': 4588,\n",
       " 'pampulitika': 1996,\n",
       " 'Food': 8542,\n",
       " 'scene': 14776,\n",
       " 'skeleton': 12703,\n",
       " 'EOQ': 24617,\n",
       " 'katauhan': 12926,\n",
       " 'daliri': 3233,\n",
       " 'Magtrabaho': 12155,\n",
       " 'salamangka': 21059,\n",
       " 'Android': 3176,\n",
       " 'fly': 16264,\n",
       " 'matunaw': 3929,\n",
       " 'mitts': 20825,\n",
       " 'Camden': 24528,\n",
       " 'purple': 10992,\n",
       " 'matagpuan': 6426,\n",
       " 'copper': 27973,\n",
       " 'Gatas': 8977,\n",
       " 'Tax': 12850,\n",
       " 'Pilosopiya': 20375,\n",
       " 'Pagmamay': 15507,\n",
       " 'kaguluhan': 1573,\n",
       " 'Compact': 26817,\n",
       " 'bumibitag': 23448,\n",
       " 'tinatanggihan': 11799,\n",
       " 'Giza': 10811,\n",
       " 'bartender': 18404,\n",
       " 'liku': 19597,\n",
       " 'Chanel': 24543,\n",
       " 'Pilates': 19261,\n",
       " 'makasagisag': 28500,\n",
       " 'dalandan': 4010,\n",
       " 'reyna': 4819,\n",
       " 'sinuri': 11789,\n",
       " 'metapora': 1557,\n",
       " 'Onion': 23116,\n",
       " 'magpahusay': 28449,\n",
       " 'tinatagusan': 21131,\n",
       " 'São': 23286,\n",
       " 'goldpis': 17664,\n",
       " 'mapagbantay': 10932,\n",
       " 'hypotheses': 8087,\n",
       " 'zip_code': 29251,\n",
       " 'kalawakan': 1215,\n",
       " 'Argument': 24462,\n",
       " 'aparatong': 18387,\n",
       " 'holographic': 25603,\n",
       " 'Pagsubok': 5142,\n",
       " 'He': 11063,\n",
       " 'tumalikod': 13090,\n",
       " 'pardon': 26139,\n",
       " 'Indira': 27050,\n",
       " 'Revolution': 6178,\n",
       " 'nababalutan': 8231,\n",
       " 'friend': 18485,\n",
       " 'pollution': 9756,\n",
       " 'lapitan': 5111,\n",
       " 'acrylic': 16195,\n",
       " '2025': 21217,\n",
       " 'sustaining': 22491,\n",
       " 'inilulubog': 25659,\n",
       " 'mapagtagumpayan': 12012,\n",
       " 'panlabas': 1174,\n",
       " 'apelyido': 7842,\n",
       " 'magtaguyod': 16338,\n",
       " 'pagdanas': 26057,\n",
       " 'homonym': 28199,\n",
       " 'sorted_numbers': 18850,\n",
       " 'effort': 21906,\n",
       " 'palumpon': 13025,\n",
       " 'nakaligtas': 6316,\n",
       " 'today': 22520,\n",
       " 'population': 26193,\n",
       " 'Pagputok': 25009,\n",
       " 'alleles': 25335,\n",
       " 'teeth': 22507,\n",
       " 'pinangangasiwaan': 3512,\n",
       " 'Pagtanggi': 27408,\n",
       " 'genetics': 13297,\n",
       " 'Imposibleng': 24757,\n",
       " 'Kodak': 27133,\n",
       " '860': 29452,\n",
       " 'haydroliko': 28179,\n",
       " 'laganap': 4579,\n",
       " 'TX': 21725,\n",
       " 'industriyang': 6365,\n",
       " 'pinlano': 18772,\n",
       " 'pair': 16441,\n",
       " 'tile': 15332,\n",
       " 'Maliit': 7347,\n",
       " 'Elemento': 18135,\n",
       " 'okra': 28745,\n",
       " 'maunlad': 5355,\n",
       " 'kalendaryo': 3201,\n",
       " 'perspective': 20983,\n",
       " 'esophagus': 16925,\n",
       " '“': 2927,\n",
       " 'Pueblo': 23201,\n",
       " 'komunikasyon': 311,\n",
       " 'konkretong': 13744,\n",
       " '1632': 26535,\n",
       " 'puns': 22399,\n",
       " 'naharap': 19718,\n",
       " 'Eastern': 9594,\n",
       " 'diyamante': 19459,\n",
       " 'kapuwa': 28325,\n",
       " 'Je': 12786,\n",
       " 'triplet': 29184,\n",
       " 'lung': 25790,\n",
       " 'Setting': 9309,\n",
       " 'Canis': 18084,\n",
       " 'Levenshtein': 27168,\n",
       " 'karot': 4085,\n",
       " 'Code': 5092,\n",
       " 'ibigay': 1594,\n",
       " 'kinaya': 28347,\n",
       " '000000': 29319,\n",
       " 'Kalungkutan': 13167,\n",
       " 'pinakamataas': 960,\n",
       " 'Pagbibisikleta': 14973,\n",
       " 'inilalagay': 4178,\n",
       " 'Americas': 12406,\n",
       " 'Nagbigay': 6528,\n",
       " 'napagod': 18678,\n",
       " 'Pambungad': 19249,\n",
       " 'Estate': 20133,\n",
       " 'Nagbago': 24944,\n",
       " 'pagpisil': 28805,\n",
       " '1859': 29365,\n",
       " 'Clean': 19026,\n",
       " 'nakakabawas': 5269,\n",
       " 'Tumutugon': 13236,\n",
       " 'medisina': 3809,\n",
       " '16cm': 29350,\n",
       " 'cognitive': 4267,\n",
       " 'Ipalagay': 27071,\n",
       " 'kanila': 225,\n",
       " 'manuskrito': 17039,\n",
       " 'paperless': 24061,\n",
       " 'Montmartre': 21547,\n",
       " 'pahalang': 3982,\n",
       " 'Diana': 29787,\n",
       " 'followers': 28124,\n",
       " 'creativity': 27989,\n",
       " 'nagtataas': 11722,\n",
       " 'Tangkilikin': 4597,\n",
       " 'caterpillar': 16889,\n",
       " 'mortal': 13369,\n",
       " 'baywang': 13264,\n",
       " 'nagbabasa': 5627,\n",
       " 'Ikinalulugod': 14914,\n",
       " 'Synopsis': 25210,\n",
       " 'milk': 4121,\n",
       " 'ASCII': 10336,\n",
       " 'vowel_count': 16552,\n",
       " 'simula': 965,\n",
       " 'Hugasan': 7512,\n",
       " 'Basket': 18988,\n",
       " 'WA': 25277,\n",
       " 'nagbubuga': 28615,\n",
       " 'Amazing': 22691,\n",
       " 'workstation': 18908,\n",
       " 'affordability': 12859,\n",
       " '^(': 8185,\n",
       " 'Distribution': 22817,\n",
       " 'Gen': 17365,\n",
       " 'alternating': 13654,\n",
       " 'Haluing': 13553,\n",
       " 'Medikal': 9446,\n",
       " 'nadagdagan': 16377,\n",
       " 'viewfinder': 21160,\n",
       " 'bilangin': 8719,\n",
       " 'minded': 25905,\n",
       " 'tirahan': 781,\n",
       " 'perplexity': 26153,\n",
       " 'gamot': 950,\n",
       " 'marginalized': 9070,\n",
       " 'Gaming': 19088,\n",
       " 'Tumatanggap': 21747,\n",
       " 'itatakda': 22047,\n",
       " 'engage': 28077,\n",
       " 'Communications': 29723,\n",
       " 'Nakakagulat': 18244,\n",
       " 'Nagpaplano': 20313,\n",
       " 'hormones': 12905,\n",
       " 'atubiling': 3400,\n",
       " '(.)': 24333,\n",
       " 'pagbubunyag': 24014,\n",
       " 'hardinero': 11159,\n",
       " 'Logo': 13581,\n",
       " 'nota': 5587,\n",
       " 'patayin': 4721,\n",
       " 'makabagong': 1276,\n",
       " 'mabangis': 3795,\n",
       " 'akalain': 12860,\n",
       " 'transition': 8271,\n",
       " 'bugtong': 6675,\n",
       " 'nakataas': 8233,\n",
       " 'nabuhayan': 23898,\n",
       " 'read_csv': 19861,\n",
       " 'panandalian': 8929,\n",
       " 'Promoter': 25072,\n",
       " 'Iraq': 12785,\n",
       " 'stop_words': 29096,\n",
       " 'disadvantaged': 23540,\n",
       " 'magkakaibigan': 4940,\n",
       " 'isinaaktibo': 25692,\n",
       " 'nakaraan': 1818,\n",
       " 'C1': 17314,\n",
       " 'kumusta': 6691,\n",
       " 'SUMALI': 20406,\n",
       " 'has': 11407,\n",
       " 'virtualization': 11529,\n",
       " ':-': 17289,\n",
       " 'kusinilya': 25757,\n",
       " 'Cavaliers': 26783,\n",
       " 'pagkakataon': 289,\n",
       " 'napalaya': 28713,\n",
       " 'TF': 12192,\n",
       " 'Diploma': 24603,\n",
       " 'plus': 11487,\n",
       " 'println': 8376,\n",
       " 'loops': 18589,\n",
       " 'Makiramay': 24884,\n",
       " 'pinakanakamamatay': 18769,\n",
       " 'hakbang': 131,\n",
       " 'Debate': 22801,\n",
       " 'pangangalagang': 435,\n",
       " 'nasiraan': 20894,\n",
       " 'serye': 1318,\n",
       " 'lantad': 28383,\n",
       " 'Denial': 29776,\n",
       " 'nagngangalang': 1161,\n",
       " 'cobblestone': 25447,\n",
       " 'prinsipal': 18780,\n",
       " 'Cotton': 24578,\n",
       " 'kinunan': 14646,\n",
       " 'bulkan': 3522,\n",
       " 'Hannah': 22887,\n",
       " 'matatamis': 9373,\n",
       " 'HOUSE': 26986,\n",
       " 'enhanced': 28078,\n",
       " 'matatanggap': 11709,\n",
       " 'Warrior': 25280,\n",
       " 'umaawit': 5036,\n",
       " 'estilo': 4033,\n",
       " 'mushroom': 6632,\n",
       " '849': 26612,\n",
       " 'nakamit': 4717,\n",
       " 'sikreto': 6812,\n",
       " 'disassemble': 25492,\n",
       " 'memorya': 1460,\n",
       " 'xi': 29245,\n",
       " 'nagsilbi': 7478,\n",
       " 'Narito': 136,\n",
       " 'Present': 10840,\n",
       " 'itinatapon': 10902,\n",
       " 'mabibiling': 28426,\n",
       " 'CCTV': 29663,\n",
       " 'kalsada': 1250,\n",
       " 'Magreresulta': 20268,\n",
       " 'pampabigat': 24049,\n",
       " 'magbabayad': 12002,\n",
       " 'Waiter': 19338,\n",
       " 'Militar': 20293,\n",
       " 'isasaayos': 23696,\n",
       " 'Gneiss': 24684,\n",
       " 'MacOS': 27201,\n",
       " 'kalupitan': 9876,\n",
       " 'Napangiti': 11893,\n",
       " 'umulit': 5824,\n",
       " 'to': 690,\n",
       " 'Sichuan': 27574,\n",
       " 'nakapapawi': 8625,\n",
       " 'Ayos': 29561,\n",
       " 'kumagat': 12935,\n",
       " '1px': 17275,\n",
       " 'Oras': 2774,\n",
       " 'tinuklas': 19948,\n",
       " 'makaligtaan': 7574,\n",
       " 'piknik': 3479,\n",
       " 'maligo': 14683,\n",
       " '883': 24422,\n",
       " 'Partido': 11096,\n",
       " 'estadista': 18477,\n",
       " 'website': 186,\n",
       " 'recruit': 8800,\n",
       " 'Nalalapat': 13596,\n",
       " 'matamo': 16356,\n",
       " 'benepisyaryo': 18407,\n",
       " 'nagra': 28653,\n",
       " 'Magsimula': 879,\n",
       " 'lilim': 3348,\n",
       " 'Matataas': 21529,\n",
       " 'Bilyon': 18074,\n",
       " 'gumalaw': 5490,\n",
       " 'pahahalagahan': 14261,\n",
       " 'peeled': 24066,\n",
       " 'tagline': 4477,\n",
       " 'sinusubaybayang': 15878,\n",
       " 'Computers': 21311,\n",
       " 'naghaharing': 15202,\n",
       " 'Sawyer': 25139,\n",
       " 'kulantro': 25753,\n",
       " 'maghahanda': 28438,\n",
       " 'nuts': 5405,\n",
       " 'Pagsusulit': 25012,\n",
       " 'leg': 18582,\n",
       " 'guillotine': 25580,\n",
       " 'Chicken': 6828,\n",
       " 'katalinuhan': 1421,\n",
       " 'Plate': 18287,\n",
       " 'NER': 17443,\n",
       " 'gumagabay': 6951,\n",
       " 'bakasyunan': 23407,\n",
       " 'nakakabit': 5861,\n",
       " 'Equipment': 18139,\n",
       " 'natanggap': 3632,\n",
       " '97': 10547,\n",
       " 'Equatorial': 20132,\n",
       " '37': 4657,\n",
       " 'Orange': 5253,\n",
       " 'weather': 6651,\n",
       " 'Movement': 10377,\n",
       " 'Laki': 11077,\n",
       " 'Mukha': 13991,\n",
       " 'AND': 15965,\n",
       " 'sakupin': 7599,\n",
       " 'mapataas': 973,\n",
       " 'gumaganang': 7753,\n",
       " 'Pabahay': 13197,\n",
       " 'gerund': 14124,\n",
       " 'madamdamin': 7571,\n",
       " 'Sputnik': 18338,\n",
       " 'full': 5216,\n",
       " 'Penne': 18279,\n",
       " 'Ms': 14456,\n",
       " 'instincts': 14626,\n",
       " 'VIII': 15565,\n",
       " 'Nagsasalita': 27315,\n",
       " 'cryptocurrency': 5901,\n",
       " '18th': 29368,\n",
       " 'pagkamaramdamin': 22315,\n",
       " 'pagpapanatili': 486,\n",
       " 'malalanghap': 28509,\n",
       " 'Motor': 14956,\n",
       " 'exposure': 11398,\n",
       " 'isasalin': 28279,\n",
       " 'sipa': 9941,\n",
       " 'tinutuklasan': 12721,\n",
       " 'kagiliw': 12265,\n",
       " 'kompanya': 9052,\n",
       " 'Nagdagdag': 15486,\n",
       " 'spotlight': 24204,\n",
       " 'napisa': 17829,\n",
       " 'Aria': 9588,\n",
       " 'Achilles': 29489,\n",
       " 'Nevada': 14000,\n",
       " 'Biomass': 18996,\n",
       " 'security': 4561,\n",
       " ...}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_fil_tgt_tokenizer.get_vocab(with_added_tokens = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee99087d",
   "metadata": {},
   "source": [
    "#### .get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "81a1f773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_fil_tgt_tokenizer.get_vocab_size(with_added_tokens = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3a5d96",
   "metadata": {},
   "source": [
    "#### .encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "13527c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoding(num_tokens=13, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_tgt_text = eng_fil_tgt_tokenizer.encode(\n",
    "    sequence = ' Ilarawan kung ano ang makikita mo kung pupunta ka sa Grand Canyon.'\n",
    ")\n",
    "\n",
    "tokenized_tgt_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c86300f",
   "metadata": {},
   "source": [
    "##### .tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "48f10d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ilarawan',\n",
       " 'kung',\n",
       " 'ano',\n",
       " 'ang',\n",
       " 'makikita',\n",
       " 'mo',\n",
       " 'kung',\n",
       " 'pupunta',\n",
       " 'ka',\n",
       " 'sa',\n",
       " 'Grand',\n",
       " 'Canyon',\n",
       " '.']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_tgt_text.tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77b244b",
   "metadata": {},
   "source": [
    "##### .ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d765ffb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[260, 27, 256, 9, 1028, 66, 27, 4868, 100, 5, 4662, 5827, 7]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_tgt_text.ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800bc79d",
   "metadata": {},
   "source": [
    "##### .attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "085fa3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_tgt_text.attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "25f3b117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_num_padding_tokens = config[\"seq_len\"] - len(tokenized_tgt_text.ids) - 1\n",
    "dec_num_padding_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa8dca5",
   "metadata": {},
   "source": [
    "#### **DECODER INPUT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "eafe38fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   2,  260,   27,  256,    9, 1028,   66,   27, 4868,  100,    5, 4662,\n",
       "        5827,    7,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input = torch.cat(\n",
    "            [\n",
    "                torch.tensor([sos_token], dtype = torch.int64),\n",
    "                torch.tensor(tokenized_tgt_text.ids, dtype = torch.int64),\n",
    "                torch.tensor([pad_token] * dec_num_padding_tokens, dtype = torch.int64),\n",
    "            ],\n",
    "            dim = 0,\n",
    "        )\n",
    "decoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9edfaf8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([350])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1e6a12",
   "metadata": {},
   "source": [
    "#### **DECODER MASK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c0a1679c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0, 0,  ..., 0, 0, 0],\n",
       "         [1, 1, 0,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.dataset import causal_mask\n",
    "\n",
    "decoder_mask = (decoder_input != pad_token).unsqueeze(0).int() & causal_mask(decoder_input.size(0))\n",
    "decoder_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "27a6c7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 350, 350])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4629aa91",
   "metadata": {},
   "source": [
    "#### .decode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa0f6e0",
   "metadata": {},
   "source": [
    "- The output for the decoder is `shifted-right` (added [SOS])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "37e2b868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[SOS] Ilarawan kung ano ang makikita mo kung pupunta ka sa Grand Canyon . [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_fil_tgt_tokenizer.decode(decoder_input.tolist(), \n",
    "                             skip_special_tokens = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7859a5",
   "metadata": {},
   "source": [
    "## label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc592407",
   "metadata": {},
   "source": [
    "### **LABEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "574fdb11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 260,   27,  256,    9, 1028,   66,   27, 4868,  100,    5, 4662, 5827,\n",
       "           7,    3,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = torch.cat(\n",
    "            [\n",
    "                torch.tensor(tokenized_tgt_text.ids, dtype = torch.int64),\n",
    "                torch.tensor([eos_token], dtype = torch.int64),\n",
    "                torch.tensor([pad_token] * dec_num_padding_tokens, dtype = torch.int64),\n",
    "            ],\n",
    "            dim = 0,\n",
    "        )\n",
    "\n",
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd213f5e",
   "metadata": {},
   "source": [
    "### .decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1d075558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ilarawan kung ano ang makikita mo kung pupunta ka sa Grand Canyon . [EOS] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_fil_tgt_tokenizer.decode(label.tolist(), \n",
    "                             skip_special_tokens = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98da1208",
   "metadata": {},
   "source": [
    "# **get_bundled_input_and_mask()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0508ab11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train import get_bundled_input_and_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b96b19c",
   "metadata": {},
   "source": [
    "## **ENCODER INPUT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83b9ca74",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_and_mask = get_bundled_input_and_mask(\n",
    "    sos_token = sos_token,\n",
    "    eos_token = eos_token,\n",
    "    pad_token = pad_token,\n",
    "    tokenized_src_text = tokenized_src_text,\n",
    "    enc_num_padding_tokens = enc_num_padding_tokens\n",
    ")\n",
    "\n",
    "encoder_input, encoder_mask = encoder_input_and_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6fe3cafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   2,  240,  152,   29,   80,  340,  116,   29, 1379,    8,    6, 4881,\n",
       "        6072,    4,    3,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75513879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([350])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036ccbcb",
   "metadata": {},
   "source": [
    "## **ENCODER MASK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "231a191d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9340e578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 350])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caddf50",
   "metadata": {},
   "source": [
    "## **DECODER INPUT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "366bdb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input_and_mask = get_bundled_input_and_mask(\n",
    "    sos_token = sos_token,\n",
    "    pad_token = pad_token,\n",
    "    eos_token = eos_token,\n",
    "    tokenized_tgt_text = tokenized_tgt_text,\n",
    "    dec_num_padding_tokens = dec_num_padding_tokens\n",
    ")\n",
    "\n",
    "decoder_input, decoder_mask = decoder_input_and_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "738fcea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   2,  260,   27,  256,    9, 1028,   66,   27, 4868,  100,    5, 4662,\n",
       "        5827,    7,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1d6b234e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([350])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad769ea",
   "metadata": {},
   "source": [
    "## **DECODER MASK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fe8a4aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0, 0,  ..., 0, 0, 0],\n",
       "         [1, 1, 0,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "51ab08c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 350, 350])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa0ceb4",
   "metadata": {},
   "source": [
    "# **get_model() -> Transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b8f42019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7246735e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): Encoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x EncoderBlock(\n",
       "        (self_attention_block): MultiHeadAttentionBlock(\n",
       "          (w_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_k): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_v): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_o): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward_block): FeedForwardBlock(\n",
       "          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (residual_connections): ModuleList(\n",
       "          (0-1): 2 x ResidualConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNormalization()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNormalization()\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x DecoderBlock(\n",
       "        (self_attention_block): MultiHeadAttentionBlock(\n",
       "          (w_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_k): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_v): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_o): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (cross_attention_block): MultiHeadAttentionBlock(\n",
       "          (w_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_k): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_v): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_o): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward_block): FeedForwardBlock(\n",
       "          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (residual_connections): ModuleList(\n",
       "          (0-2): 3 x ResidualConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNormalization()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNormalization()\n",
       "  )\n",
       "  (src_embed): InputEmbeddings(\n",
       "    (embedding): Embedding(30000, 512)\n",
       "  )\n",
       "  (tgt_embed): InputEmbeddings(\n",
       "    (embedding): Embedding(30000, 512)\n",
       "  )\n",
       "  (src_pos): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (tgt_pos): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (projection_layer): ProjectionLayer(\n",
       "    (proj): Linear(in_features=512, out_features=30000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import device\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "model = get_model(\n",
    "    config = config,\n",
    "    vocab_src_len = eng_fil_src_tokenizer.get_vocab_size(),\n",
    "    vocab_tgt_len = eng_fil_tgt_tokenizer.get_vocab_size()\n",
    ").to(device)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ad61f50b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "src.model.Transformer"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "398c2a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('encoder.layers.0.self_attention_block.w_q.weight',\n",
       "              tensor([[-0.0651, -0.0644, -0.0467,  ..., -0.0197,  0.0674, -0.0147],\n",
       "                      [-0.0437,  0.0225,  0.0072,  ...,  0.0409, -0.0559, -0.0642],\n",
       "                      [-0.0299, -0.0045, -0.0492,  ..., -0.0454, -0.0519,  0.0244],\n",
       "                      ...,\n",
       "                      [ 0.0404,  0.0404,  0.0701,  ...,  0.0191,  0.0164,  0.0339],\n",
       "                      [-0.0507, -0.0274, -0.0642,  ..., -0.0217,  0.0421, -0.0128],\n",
       "                      [ 0.0565, -0.0170, -0.0552,  ..., -0.0199,  0.0032,  0.0305]])),\n",
       "             ('encoder.layers.0.self_attention_block.w_k.weight',\n",
       "              tensor([[ 0.0622,  0.0594,  0.0558,  ..., -0.0683,  0.0518, -0.0060],\n",
       "                      [ 0.0561,  0.0092,  0.0465,  ..., -0.0171,  0.0711, -0.0700],\n",
       "                      [-0.0730, -0.0415,  0.0068,  ..., -0.0181,  0.0536,  0.0108],\n",
       "                      ...,\n",
       "                      [-0.0040,  0.0498,  0.0600,  ..., -0.0718, -0.0043,  0.0222],\n",
       "                      [ 0.0438,  0.0547, -0.0680,  ...,  0.0465,  0.0627, -0.0569],\n",
       "                      [-0.0375, -0.0406, -0.0207,  ...,  0.0002,  0.0321,  0.0664]])),\n",
       "             ('encoder.layers.0.self_attention_block.w_v.weight',\n",
       "              tensor([[ 0.0457,  0.0091, -0.0533,  ...,  0.0071, -0.0110,  0.0138],\n",
       "                      [-0.0605, -0.0478,  0.0734,  ...,  0.0076, -0.0529, -0.0310],\n",
       "                      [ 0.0534,  0.0054,  0.0116,  ...,  0.0671,  0.0745, -0.0094],\n",
       "                      ...,\n",
       "                      [-0.0451, -0.0048, -0.0524,  ..., -0.0359,  0.0038,  0.0287],\n",
       "                      [ 0.0605, -0.0397, -0.0697,  ..., -0.0293,  0.0738,  0.0638],\n",
       "                      [-0.0378, -0.0391,  0.0493,  ...,  0.0206, -0.0191, -0.0078]])),\n",
       "             ('encoder.layers.0.self_attention_block.w_o.weight',\n",
       "              tensor([[-0.0653,  0.0276, -0.0588,  ..., -0.0612,  0.0469,  0.0523],\n",
       "                      [ 0.0169,  0.0422, -0.0762,  ..., -0.0383,  0.0115, -0.0056],\n",
       "                      [-0.0508,  0.0612, -0.0609,  ...,  0.0539, -0.0368,  0.0480],\n",
       "                      ...,\n",
       "                      [ 0.0203, -0.0721,  0.0328,  ..., -0.0501, -0.0333,  0.0454],\n",
       "                      [-0.0594, -0.0326, -0.0344,  ..., -0.0084, -0.0048,  0.0103],\n",
       "                      [-0.0515, -0.0164, -0.0727,  ...,  0.0072,  0.0178, -0.0265]])),\n",
       "             ('encoder.layers.0.feed_forward_block.linear_1.weight',\n",
       "              tensor([[-0.0114, -0.0004, -0.0443,  ...,  0.0393,  0.0097,  0.0377],\n",
       "                      [-0.0070,  0.0463,  0.0386,  ..., -0.0470, -0.0016,  0.0033],\n",
       "                      [-0.0301, -0.0190,  0.0383,  ..., -0.0165, -0.0303,  0.0053],\n",
       "                      ...,\n",
       "                      [ 0.0300,  0.0276, -0.0128,  ...,  0.0469,  0.0050, -0.0344],\n",
       "                      [ 0.0118, -0.0045,  0.0350,  ..., -0.0428,  0.0350, -0.0317],\n",
       "                      [ 0.0293,  0.0370,  0.0235,  ...,  0.0137, -0.0167,  0.0355]])),\n",
       "             ('encoder.layers.0.feed_forward_block.linear_1.bias',\n",
       "              tensor([-0.0063,  0.0030,  0.0197,  ...,  0.0088, -0.0383,  0.0275])),\n",
       "             ('encoder.layers.0.feed_forward_block.linear_2.weight',\n",
       "              tensor([[-0.0005, -0.0200, -0.0331,  ..., -0.0338,  0.0318, -0.0059],\n",
       "                      [-0.0331,  0.0108,  0.0171,  ..., -0.0482, -0.0147, -0.0245],\n",
       "                      [-0.0309, -0.0153, -0.0467,  ...,  0.0039,  0.0351,  0.0395],\n",
       "                      ...,\n",
       "                      [ 0.0081, -0.0428, -0.0352,  ...,  0.0186,  0.0413, -0.0286],\n",
       "                      [-0.0332, -0.0407,  0.0178,  ...,  0.0349, -0.0088,  0.0056],\n",
       "                      [ 0.0040, -0.0389, -0.0011,  ..., -0.0066, -0.0187,  0.0237]])),\n",
       "             ('encoder.layers.0.feed_forward_block.linear_2.bias',\n",
       "              tensor([-2.0738e-03, -1.4652e-02,  7.3538e-03, -7.0560e-03,  7.5933e-03,\n",
       "                       9.8433e-03, -5.0870e-03, -1.8568e-02, -1.4161e-02, -1.6737e-02,\n",
       "                       4.6402e-03,  5.9096e-03, -1.6094e-02, -1.4010e-02, -1.6362e-02,\n",
       "                      -1.5119e-02,  1.7898e-02, -7.7976e-04, -2.1298e-02,  1.1333e-02,\n",
       "                      -5.5649e-03, -7.2036e-03,  4.7390e-03,  1.6074e-02, -1.2728e-02,\n",
       "                       1.7289e-02,  1.4469e-02, -6.4121e-03,  1.2154e-04, -1.7765e-02,\n",
       "                       1.0132e-03, -2.0051e-02, -3.1352e-05, -1.1959e-02,  1.3820e-02,\n",
       "                      -7.4888e-04, -2.0502e-03,  1.3121e-02,  1.8648e-02, -1.7136e-02,\n",
       "                      -1.9188e-02, -1.2912e-02, -8.2574e-03,  2.0911e-02, -2.5224e-03,\n",
       "                      -1.9917e-02,  2.1334e-02, -1.1014e-02, -2.1674e-02,  9.6093e-03,\n",
       "                       7.4715e-03,  1.5541e-02,  1.9625e-02, -2.0382e-02, -1.6784e-03,\n",
       "                       1.4759e-02, -9.5088e-04, -1.4243e-02, -7.0543e-04,  7.7538e-03,\n",
       "                      -2.1591e-02, -7.4848e-03,  7.2543e-03,  6.8218e-03,  3.0616e-03,\n",
       "                       1.0799e-02, -2.3688e-03,  1.5208e-02, -1.9957e-02,  1.6081e-02,\n",
       "                       7.1403e-05, -2.0345e-02, -1.7632e-02, -9.3743e-03, -1.4100e-02,\n",
       "                       1.3305e-02, -8.4083e-03, -1.2271e-02, -1.0897e-02,  5.5722e-03,\n",
       "                       3.4441e-03, -1.5313e-04,  1.9394e-02, -2.1321e-02,  8.4292e-03,\n",
       "                      -1.9586e-02, -9.1676e-03,  4.6088e-03,  4.0455e-03,  2.0676e-03,\n",
       "                       1.8209e-02, -1.4659e-02, -6.1061e-03,  4.6482e-03,  1.4791e-02,\n",
       "                      -8.7061e-03,  1.7668e-02, -1.9249e-02, -1.8004e-02,  4.3916e-03,\n",
       "                      -1.2766e-02,  2.0986e-02,  5.5389e-03, -1.1920e-03,  1.1228e-02,\n",
       "                       1.8217e-02, -6.8992e-03,  1.1403e-02,  1.8423e-03, -9.2184e-03,\n",
       "                       1.2803e-02,  1.0171e-02,  2.1671e-02, -1.8235e-02, -1.7629e-02,\n",
       "                      -1.1240e-02,  1.2853e-02,  1.5638e-02, -1.8893e-02,  6.0090e-03,\n",
       "                      -9.3178e-03,  1.3063e-02, -6.9421e-04, -1.4032e-02,  4.5483e-03,\n",
       "                      -1.6622e-02,  1.3896e-02,  6.2612e-04,  1.9009e-02, -9.3620e-03,\n",
       "                       6.6229e-03, -1.3717e-02, -1.8847e-02,  1.7849e-02, -1.1689e-02,\n",
       "                       1.5087e-03, -2.1706e-02,  1.2298e-02, -1.1708e-02, -1.8113e-02,\n",
       "                      -2.1801e-02, -3.6694e-03,  9.6694e-03,  1.4126e-02,  1.7201e-02,\n",
       "                       2.0968e-02,  9.6126e-03,  6.6412e-03,  2.1830e-02, -1.0878e-02,\n",
       "                       4.0638e-03,  7.9458e-03, -9.5321e-03, -1.0028e-02, -2.8581e-03,\n",
       "                      -1.4531e-02, -2.0599e-02,  9.7396e-03,  9.7084e-03,  3.5734e-03,\n",
       "                       6.9411e-03,  1.1827e-02,  2.0747e-02,  1.2035e-02, -1.4900e-02,\n",
       "                       1.6604e-02, -4.9887e-03, -1.7024e-02,  1.2401e-02,  1.2699e-02,\n",
       "                      -6.1400e-03, -7.0662e-03, -1.0070e-02,  1.1138e-02,  7.1093e-03,\n",
       "                      -1.0095e-02,  4.3895e-03, -7.2077e-03, -1.2842e-03,  5.3086e-03,\n",
       "                      -9.2444e-03,  1.3381e-02,  2.2075e-02,  1.1792e-02,  7.9133e-03,\n",
       "                      -2.0594e-02,  1.7989e-02, -1.7276e-02, -1.2303e-02,  1.0075e-02,\n",
       "                      -8.9768e-03,  1.7741e-03, -7.3905e-03,  5.4326e-04, -1.2735e-02,\n",
       "                      -6.8725e-04,  1.0868e-02,  4.8453e-03,  6.7677e-03,  1.6081e-02,\n",
       "                      -2.1571e-02,  1.9430e-02,  1.5483e-02, -1.9556e-02,  1.9923e-02,\n",
       "                      -1.6377e-02, -2.1005e-02,  1.7930e-02,  1.4768e-02,  1.1158e-02,\n",
       "                       1.3987e-02,  4.3915e-03,  2.0478e-03, -1.6306e-02,  1.2555e-02,\n",
       "                       6.9010e-03, -1.2296e-02, -1.5296e-02,  1.7225e-02,  1.1077e-02,\n",
       "                       1.0445e-02,  1.5535e-02, -1.8200e-02,  8.3694e-03,  9.2426e-03,\n",
       "                       1.1760e-02,  9.8432e-03,  1.0367e-02,  1.1037e-02,  8.0721e-03,\n",
       "                       2.5472e-03, -1.3462e-02, -3.0296e-03, -1.4941e-02,  1.5251e-02,\n",
       "                       5.9339e-03, -1.1412e-02,  1.9924e-02,  1.3643e-03, -1.9152e-02,\n",
       "                      -1.7671e-02,  1.3159e-02,  1.9342e-02,  1.2877e-02, -1.4573e-02,\n",
       "                       1.8229e-02,  2.1832e-02,  1.2263e-02, -1.2990e-02,  7.9464e-03,\n",
       "                      -1.3655e-02,  4.6687e-03,  7.3278e-03, -1.8163e-02, -1.6448e-02,\n",
       "                      -1.0255e-02, -1.2428e-02,  1.4619e-02, -4.5709e-03,  2.1722e-02,\n",
       "                      -1.9978e-02, -1.5508e-02, -1.2646e-02,  1.3073e-02, -1.6117e-02,\n",
       "                      -1.5656e-02, -1.0116e-03,  2.8403e-03,  1.8739e-02, -5.2359e-03,\n",
       "                       1.4250e-02,  1.9706e-02, -1.6951e-04,  9.9277e-03,  1.4867e-02,\n",
       "                      -7.4659e-03, -9.7272e-03,  2.0035e-02, -1.0288e-02, -1.2099e-02,\n",
       "                       1.0519e-02, -1.3140e-03, -1.9174e-02,  1.5766e-03,  9.8533e-03,\n",
       "                       2.0851e-03,  1.6672e-02, -1.9724e-02, -6.6763e-03,  7.2189e-03,\n",
       "                      -1.2034e-02, -1.2101e-02,  1.4285e-02, -8.8756e-03, -1.9485e-02,\n",
       "                      -3.4295e-03,  3.7372e-03, -2.2014e-02,  5.9978e-03, -8.5685e-03,\n",
       "                       1.2045e-02, -1.8923e-02, -1.2123e-02, -5.2915e-03, -5.5027e-03,\n",
       "                      -1.5487e-02, -1.7868e-03,  1.8301e-02, -1.7930e-02, -1.5953e-02,\n",
       "                       1.6779e-02, -1.7247e-02,  1.4876e-02, -1.2480e-02, -1.3683e-02,\n",
       "                       6.1655e-03, -3.7240e-03,  1.7244e-02,  1.6784e-02,  7.2904e-03,\n",
       "                      -1.6058e-02, -1.6551e-02,  1.2500e-02, -1.9906e-02, -2.0750e-02,\n",
       "                      -2.7094e-03, -2.5326e-03,  2.1462e-03, -1.7515e-02,  1.9418e-02,\n",
       "                      -1.7746e-02,  9.5615e-03, -1.4173e-02, -1.2194e-03,  1.5414e-02,\n",
       "                      -1.7453e-02, -8.9456e-03, -2.2406e-03, -1.5225e-03,  6.5475e-03,\n",
       "                      -1.1942e-02,  1.4178e-02, -6.6669e-03,  1.1358e-02,  1.4612e-02,\n",
       "                       5.0846e-03,  1.1428e-03,  1.4933e-02, -6.1250e-03,  1.0133e-02,\n",
       "                      -9.4677e-03,  1.1703e-02, -1.4400e-02, -7.1510e-03,  2.0009e-02,\n",
       "                      -1.2349e-02,  4.8086e-04,  1.8633e-02,  1.0420e-02,  6.3276e-03,\n",
       "                       2.0512e-02,  6.5425e-03, -4.6131e-03, -6.8749e-04,  1.8583e-02,\n",
       "                       1.7477e-02,  2.1204e-02,  1.2807e-02,  1.3736e-03, -8.2618e-03,\n",
       "                      -1.4361e-02,  1.7909e-02,  7.8986e-03,  1.4340e-04, -2.9686e-03,\n",
       "                      -9.9579e-03,  2.0504e-03, -1.4122e-02, -1.6938e-02, -1.7517e-02,\n",
       "                      -9.7189e-03,  1.3606e-02, -6.2259e-03, -1.2648e-02, -1.2198e-02,\n",
       "                       5.2937e-03, -1.6032e-02, -1.3593e-02, -1.4782e-02, -2.0994e-02,\n",
       "                       9.6725e-03,  1.9147e-03, -1.2605e-02,  1.5303e-02,  1.3562e-02,\n",
       "                      -3.5492e-03,  1.2122e-02, -1.6384e-02,  1.4695e-02,  2.3987e-03,\n",
       "                       3.4096e-03,  1.3538e-02,  1.7961e-02,  1.5442e-02, -6.2515e-03,\n",
       "                      -6.6719e-03, -1.3361e-02,  2.2047e-02, -1.0671e-02, -1.0671e-02,\n",
       "                      -7.5716e-03,  1.3520e-02,  9.6606e-03, -1.7466e-02, -1.2930e-02,\n",
       "                      -4.7623e-03,  1.2424e-02,  2.2017e-02, -6.9026e-03,  3.5706e-03,\n",
       "                       1.5364e-02, -7.0559e-03, -1.5029e-02, -1.0356e-02,  7.5383e-03,\n",
       "                      -1.2369e-02, -1.2636e-02,  6.4676e-03, -1.9338e-03, -2.0375e-02,\n",
       "                       1.7102e-02,  5.6010e-03,  1.3951e-02, -4.9730e-03, -3.9934e-03,\n",
       "                      -8.0016e-03, -1.8645e-02, -7.9850e-03, -9.5065e-03,  5.6487e-03,\n",
       "                      -9.8819e-03, -1.4419e-02, -3.0020e-03, -2.6036e-03,  1.0166e-02,\n",
       "                       2.6991e-03, -1.2476e-02,  5.6492e-03,  1.8123e-02,  1.3973e-02,\n",
       "                       2.5326e-03,  2.0678e-02,  2.1095e-02,  7.0539e-04, -1.9218e-02,\n",
       "                       1.3056e-02,  1.2478e-02,  1.4430e-02,  9.4667e-04, -2.0958e-02,\n",
       "                       1.7355e-02, -1.3099e-02,  1.0249e-02, -4.6948e-03,  2.1285e-02,\n",
       "                       1.5570e-02, -1.3201e-02, -1.3367e-02,  2.1680e-03,  1.3303e-02,\n",
       "                       1.3734e-02,  1.0101e-02,  1.7534e-02, -6.6466e-03, -1.7959e-02,\n",
       "                      -3.0633e-03, -1.1614e-02, -1.1461e-02,  4.0315e-03, -1.1454e-02,\n",
       "                      -1.9690e-02, -7.6845e-03,  6.4735e-03, -8.2801e-03, -1.7640e-02,\n",
       "                      -1.9933e-02, -6.3749e-03, -4.2831e-03, -5.8729e-04, -1.9019e-02,\n",
       "                      -9.3131e-03, -3.3720e-03,  7.2846e-03,  4.2372e-03,  1.5308e-02,\n",
       "                       7.9324e-03, -1.9713e-02, -7.9572e-03,  1.7239e-02, -3.3619e-04,\n",
       "                      -2.0463e-02,  9.9406e-03,  8.2006e-03, -4.3247e-03, -1.2149e-02,\n",
       "                      -1.9555e-02,  1.1352e-02,  7.2813e-03,  2.9338e-03, -9.5301e-04,\n",
       "                      -1.0802e-02,  6.1751e-03])),\n",
       "             ('encoder.layers.0.residual_connections.0.norm.alpha',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('encoder.layers.0.residual_connections.0.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('encoder.layers.0.residual_connections.1.norm.alpha',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('encoder.layers.0.residual_connections.1.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('encoder.layers.1.self_attention_block.w_q.weight',\n",
       "              tensor([[ 0.0534, -0.0627,  0.0145,  ...,  0.0083,  0.0181, -0.0388],\n",
       "                      [-0.0568, -0.0673,  0.0270,  ...,  0.0399, -0.0080, -0.0316],\n",
       "                      [-0.0693, -0.0193,  0.0705,  ...,  0.0045,  0.0743,  0.0510],\n",
       "                      ...,\n",
       "                      [-0.0287,  0.0694, -0.0445,  ..., -0.0302, -0.0453, -0.0733],\n",
       "                      [-0.0511,  0.0576, -0.0582,  ..., -0.0470, -0.0498,  0.0704],\n",
       "                      [-0.0626, -0.0267,  0.0245,  ...,  0.0554,  0.0185,  0.0738]])),\n",
       "             ('encoder.layers.1.self_attention_block.w_k.weight',\n",
       "              tensor([[-0.0054,  0.0561,  0.0297,  ...,  0.0377, -0.0299, -0.0297],\n",
       "                      [ 0.0188, -0.0265,  0.0746,  ...,  0.0130, -0.0634,  0.0193],\n",
       "                      [-0.0444, -0.0636,  0.0466,  ..., -0.0580,  0.0039, -0.0647],\n",
       "                      ...,\n",
       "                      [ 0.0419, -0.0130, -0.0371,  ...,  0.0435, -0.0189,  0.0138],\n",
       "                      [-0.0118, -0.0294, -0.0294,  ..., -0.0612,  0.0406, -0.0045],\n",
       "                      [ 0.0719, -0.0583, -0.0524,  ...,  0.0552, -0.0552, -0.0543]])),\n",
       "             ('encoder.layers.1.self_attention_block.w_v.weight',\n",
       "              tensor([[-0.0478, -0.0561,  0.0223,  ..., -0.0120, -0.0059,  0.0376],\n",
       "                      [ 0.0017, -0.0611,  0.0401,  ..., -0.0461, -0.0013, -0.0035],\n",
       "                      [-0.0227,  0.0340, -0.0435,  ..., -0.0357,  0.0323, -0.0705],\n",
       "                      ...,\n",
       "                      [ 0.0502,  0.0585, -0.0111,  ..., -0.0206, -0.0186, -0.0401],\n",
       "                      [-0.0716,  0.0723,  0.0653,  ...,  0.0179,  0.0478, -0.0392],\n",
       "                      [-0.0601, -0.0090, -0.0353,  ..., -0.0195,  0.0137, -0.0535]])),\n",
       "             ('encoder.layers.1.self_attention_block.w_o.weight',\n",
       "              tensor([[-0.0651, -0.0709,  0.0376,  ...,  0.0695, -0.0761,  0.0006],\n",
       "                      [ 0.0012,  0.0017,  0.0240,  ...,  0.0725, -0.0179,  0.0372],\n",
       "                      [-0.0356, -0.0564,  0.0397,  ..., -0.0048,  0.0462,  0.0066],\n",
       "                      ...,\n",
       "                      [-0.0422,  0.0622,  0.0726,  ...,  0.0495,  0.0549,  0.0142],\n",
       "                      [-0.0110,  0.0508, -0.0278,  ..., -0.0221, -0.0599,  0.0480],\n",
       "                      [-0.0451,  0.0630,  0.0070,  ..., -0.0754, -0.0544, -0.0112]])),\n",
       "             ('encoder.layers.1.feed_forward_block.linear_1.weight',\n",
       "              tensor([[ 0.0481, -0.0080,  0.0245,  ...,  0.0169, -0.0312, -0.0289],\n",
       "                      [-0.0112, -0.0475,  0.0302,  ...,  0.0013, -0.0024,  0.0173],\n",
       "                      [ 0.0146, -0.0346,  0.0334,  ...,  0.0091, -0.0310, -0.0168],\n",
       "                      ...,\n",
       "                      [-0.0109, -0.0053,  0.0221,  ...,  0.0349, -0.0219,  0.0020],\n",
       "                      [ 0.0332,  0.0055,  0.0090,  ..., -0.0464,  0.0002,  0.0400],\n",
       "                      [ 0.0415,  0.0252,  0.0468,  ...,  0.0329,  0.0353,  0.0154]])),\n",
       "             ('encoder.layers.1.feed_forward_block.linear_1.bias',\n",
       "              tensor([-0.0263,  0.0321,  0.0248,  ..., -0.0013,  0.0084,  0.0100])),\n",
       "             ('encoder.layers.1.feed_forward_block.linear_2.weight',\n",
       "              tensor([[ 0.0253, -0.0471,  0.0125,  ..., -0.0056,  0.0163, -0.0079],\n",
       "                      [ 0.0257,  0.0050, -0.0376,  ..., -0.0212, -0.0247,  0.0310],\n",
       "                      [ 0.0187, -0.0129, -0.0425,  ...,  0.0231, -0.0079, -0.0435],\n",
       "                      ...,\n",
       "                      [-0.0130,  0.0468, -0.0296,  ..., -0.0159, -0.0187,  0.0206],\n",
       "                      [-0.0271, -0.0347,  0.0477,  ..., -0.0475, -0.0457, -0.0089],\n",
       "                      [-0.0298, -0.0256, -0.0070,  ...,  0.0251,  0.0190, -0.0153]])),\n",
       "             ('encoder.layers.1.feed_forward_block.linear_2.bias',\n",
       "              tensor([ 9.1492e-03, -8.0904e-03,  2.2076e-02, -4.4046e-03,  7.5253e-03,\n",
       "                       1.0601e-02, -1.7131e-02, -1.9439e-02, -3.3129e-03,  2.9577e-03,\n",
       "                       1.1463e-02,  9.0649e-03,  5.1237e-03,  7.4893e-03, -5.4753e-03,\n",
       "                       1.2271e-02, -2.0799e-02,  1.0556e-02, -3.0076e-03,  1.5195e-02,\n",
       "                      -1.4844e-03,  9.6744e-03,  1.3360e-02,  3.8981e-03, -2.0733e-03,\n",
       "                       1.8165e-02, -2.1489e-02,  1.5790e-02, -8.1448e-03, -4.7299e-03,\n",
       "                       3.7737e-03, -1.7558e-03,  1.0877e-02, -1.2012e-02, -2.1050e-02,\n",
       "                       2.0636e-02,  1.2241e-02,  7.8556e-03,  1.5150e-02,  1.1394e-04,\n",
       "                       1.8229e-02,  2.6820e-03, -7.7248e-03, -2.1337e-02,  1.2912e-02,\n",
       "                      -8.7414e-03,  1.9738e-02,  9.3356e-03,  1.4195e-02, -1.0126e-02,\n",
       "                      -2.1416e-02, -1.1379e-02, -1.3206e-02, -2.2093e-02, -1.9865e-02,\n",
       "                      -1.9327e-02,  1.8652e-02, -1.0392e-02,  1.0134e-02,  1.1704e-02,\n",
       "                      -1.4119e-02,  7.8361e-03, -1.6218e-02,  1.6016e-03, -1.4762e-02,\n",
       "                      -6.1657e-03,  7.3575e-04, -1.7520e-02,  1.9009e-02,  7.8504e-03,\n",
       "                      -1.7814e-02,  2.5982e-03, -1.7452e-02,  1.6718e-02,  1.5646e-02,\n",
       "                       1.3179e-02,  5.1996e-03, -1.3410e-02,  1.6679e-02, -1.5695e-02,\n",
       "                      -1.2453e-02, -2.2084e-02, -3.3407e-03,  7.1216e-03,  2.5608e-03,\n",
       "                       1.3935e-02, -2.0572e-02, -1.1809e-02,  1.3871e-02,  1.0650e-02,\n",
       "                       3.4382e-03,  6.5053e-03, -1.6468e-03, -2.1795e-02, -1.8368e-02,\n",
       "                      -3.0434e-03, -1.1953e-02,  2.0447e-02,  1.5822e-02, -8.9281e-03,\n",
       "                       1.9585e-02,  2.0838e-02, -9.6377e-03, -2.1692e-02,  1.7247e-02,\n",
       "                      -1.5783e-02,  1.7379e-02,  1.6585e-02,  1.2240e-02, -1.9855e-02,\n",
       "                       1.9021e-02,  1.9372e-02, -1.5297e-02,  2.1767e-02,  7.7139e-03,\n",
       "                      -1.3454e-02,  1.9240e-02, -1.0746e-02,  8.0870e-03, -3.5308e-03,\n",
       "                       1.9279e-02,  2.1275e-02, -4.8815e-03,  1.2459e-03,  1.7867e-02,\n",
       "                       9.5612e-03, -1.0798e-02, -1.2490e-02, -1.4049e-02,  1.0120e-03,\n",
       "                       1.5290e-02, -5.4831e-03, -7.1589e-03,  2.2016e-02,  1.6012e-02,\n",
       "                       2.1085e-02,  1.4665e-02, -1.5571e-02, -5.4364e-03, -3.2292e-03,\n",
       "                       7.5680e-03,  1.0776e-02,  1.0092e-04,  1.4070e-02,  2.1046e-02,\n",
       "                      -2.1121e-02, -1.8886e-02, -8.0635e-03, -1.7864e-02, -4.0645e-03,\n",
       "                       1.3325e-02, -9.4702e-03,  1.6314e-02, -1.2890e-02,  7.3369e-03,\n",
       "                      -1.3943e-02,  1.3351e-02,  3.4582e-03,  1.1280e-02,  1.4638e-02,\n",
       "                       1.7076e-02,  1.7011e-03, -7.4462e-03, -6.4821e-03, -2.0076e-03,\n",
       "                      -1.9578e-02,  1.8408e-02, -1.1301e-02, -4.5801e-03, -1.9748e-02,\n",
       "                      -5.0801e-03, -4.6724e-03, -6.9002e-03,  3.4744e-03,  2.1019e-02,\n",
       "                       1.7840e-03,  7.1656e-03, -5.8618e-03,  2.2318e-03, -2.1128e-02,\n",
       "                      -8.0006e-03, -1.1299e-02, -1.3898e-02,  1.9648e-02,  9.8623e-03,\n",
       "                      -6.5819e-03,  2.0547e-02,  1.0716e-02,  3.3777e-03,  1.9484e-02,\n",
       "                       4.7215e-03, -1.8035e-02,  9.4027e-04,  3.9619e-03, -1.9821e-02,\n",
       "                       7.5478e-03,  5.6979e-03, -7.9811e-03, -9.5607e-03,  1.7660e-02,\n",
       "                      -2.3396e-03, -9.3554e-03,  1.5773e-02, -6.6650e-03, -3.8375e-03,\n",
       "                      -3.4563e-03, -2.1310e-02,  9.8607e-03, -1.3747e-02, -1.6648e-04,\n",
       "                      -8.1353e-03, -1.2131e-02,  1.1916e-02, -7.7433e-03,  1.1074e-02,\n",
       "                       1.3316e-02,  7.0175e-03, -1.5175e-02, -1.7876e-03, -2.5834e-03,\n",
       "                      -1.4288e-02, -2.9244e-03, -6.6287e-03,  1.9586e-02, -2.1218e-03,\n",
       "                       7.7354e-03, -1.7280e-02,  1.7315e-02,  4.0557e-03, -1.6627e-03,\n",
       "                      -1.5286e-03, -1.3118e-03,  6.8347e-03, -1.8692e-02,  2.0600e-02,\n",
       "                       1.8456e-02,  1.6809e-02, -1.0422e-02,  5.3680e-03,  5.1886e-04,\n",
       "                      -4.0996e-03, -1.4898e-02,  8.3467e-03,  1.5245e-02, -2.1068e-02,\n",
       "                      -2.7991e-03, -2.8219e-04, -3.0689e-03,  8.3332e-03, -3.9358e-03,\n",
       "                      -1.5110e-02,  8.0955e-03,  4.2174e-03, -2.0759e-03, -1.6588e-02,\n",
       "                      -4.4512e-04, -4.9980e-03, -2.0393e-02, -1.1147e-02, -1.0964e-02,\n",
       "                       2.0516e-02, -1.5949e-02, -2.0281e-02, -8.3492e-03, -7.2478e-03,\n",
       "                      -2.0750e-02, -1.7069e-02, -3.6912e-03, -6.8054e-03, -1.6252e-02,\n",
       "                       1.3607e-02, -3.8000e-03, -1.1879e-02,  2.6811e-03, -7.3301e-03,\n",
       "                      -5.7627e-03,  9.7122e-03, -1.5214e-03,  8.9349e-03, -3.0199e-03,\n",
       "                      -5.6170e-03, -2.5873e-04,  1.9213e-02,  1.8373e-02, -2.0268e-02,\n",
       "                      -4.6792e-03,  1.3534e-02, -1.5258e-02, -9.1168e-03, -1.2412e-02,\n",
       "                      -3.0291e-03, -1.5753e-02,  2.5328e-03,  1.4146e-02,  5.7751e-04,\n",
       "                      -1.8538e-02,  1.2566e-02, -1.9672e-02,  5.8323e-04,  1.3713e-02,\n",
       "                       1.6906e-02, -1.6521e-02,  1.2370e-02, -1.2478e-02,  2.0145e-02,\n",
       "                       6.0596e-03,  7.0617e-03, -1.6729e-02,  4.6920e-03,  1.4457e-02,\n",
       "                      -7.0665e-03, -1.0242e-02,  1.8133e-02, -2.0113e-03, -1.9559e-02,\n",
       "                       1.5161e-02, -3.1348e-03,  3.4549e-03,  4.1759e-03,  1.8812e-02,\n",
       "                      -1.6015e-02,  4.5627e-03,  2.1873e-02, -8.9195e-03,  1.7321e-02,\n",
       "                      -1.7747e-02, -5.0772e-03,  1.4476e-02, -2.1315e-02,  1.8262e-02,\n",
       "                      -1.7739e-02,  8.5099e-03, -1.3974e-03,  6.3466e-03, -1.8027e-02,\n",
       "                       2.2025e-02,  1.9278e-02,  3.9422e-03,  4.5981e-03,  9.9607e-03,\n",
       "                      -1.5017e-02,  9.0032e-03, -6.1768e-03,  1.9660e-02, -5.6166e-03,\n",
       "                      -4.4151e-03,  1.3677e-02,  9.5697e-03,  1.3424e-02,  1.2784e-02,\n",
       "                      -1.9347e-02,  1.1523e-02,  1.8039e-02, -1.9710e-03, -1.3898e-02,\n",
       "                       6.1725e-03,  1.2207e-02,  4.4590e-03,  2.0845e-02, -1.7451e-02,\n",
       "                       1.5223e-02,  3.2113e-03, -3.9446e-03, -1.8412e-02, -1.5795e-03,\n",
       "                       1.5722e-02,  1.5691e-02,  1.9972e-02,  4.6241e-04,  2.0691e-02,\n",
       "                       4.3989e-03,  2.2057e-02, -5.2925e-03,  1.1591e-02,  4.0887e-03,\n",
       "                       2.2988e-03, -4.5298e-03,  7.4017e-03,  8.0325e-03,  6.2024e-03,\n",
       "                      -3.8611e-03,  1.9500e-02, -2.0411e-02, -1.9928e-02, -1.9496e-02,\n",
       "                       7.3788e-03,  8.3299e-03, -1.8176e-02,  3.5321e-03, -8.8574e-03,\n",
       "                       9.8075e-03,  2.1346e-02, -1.4302e-02,  1.9686e-02,  3.4831e-03,\n",
       "                      -9.1720e-03,  2.1336e-03,  1.9900e-02, -1.9814e-02,  1.3147e-02,\n",
       "                      -1.0564e-02,  3.4421e-03, -1.0476e-02, -3.9950e-03, -8.2760e-03,\n",
       "                      -7.4888e-03,  1.6035e-02, -1.7222e-02, -1.2202e-02, -2.8391e-03,\n",
       "                      -2.0004e-02,  1.5537e-02, -1.8350e-02,  8.6158e-03,  2.0283e-02,\n",
       "                       7.2074e-03,  1.2037e-02,  2.0569e-03, -8.4791e-05, -1.0111e-02,\n",
       "                       2.7702e-03,  4.2251e-03, -2.6777e-03, -8.2020e-03,  6.3925e-03,\n",
       "                      -6.6542e-03, -9.3216e-03, -1.7030e-02,  4.7466e-05,  2.1365e-02,\n",
       "                       8.5935e-03,  2.0351e-02,  2.2280e-03, -2.0241e-02,  2.8246e-03,\n",
       "                       2.6090e-03,  1.8219e-02, -3.5305e-03, -7.1370e-03, -1.0260e-02,\n",
       "                      -2.0570e-02, -8.2494e-03,  1.6046e-02,  6.3460e-03, -1.2961e-02,\n",
       "                      -2.5278e-03, -1.7332e-02,  8.5594e-03, -2.1240e-02,  1.6307e-02,\n",
       "                      -1.5246e-03, -1.2482e-02, -2.1662e-02,  3.8008e-03, -2.2056e-02,\n",
       "                      -6.5927e-03,  7.3854e-03,  1.9626e-02, -1.9864e-03, -1.9060e-02,\n",
       "                       1.1263e-02, -8.3881e-03,  7.4618e-05,  1.5308e-02, -7.4577e-03,\n",
       "                      -3.6927e-04,  3.2065e-03, -1.8378e-02, -8.0406e-03, -3.8545e-04,\n",
       "                       1.4609e-02, -1.3559e-02,  4.0815e-03,  2.7843e-03,  5.2410e-03,\n",
       "                       8.2271e-03, -1.6073e-02,  1.8038e-02, -4.6085e-03,  7.9003e-04,\n",
       "                       2.1247e-02, -8.7732e-03, -7.3754e-03,  3.4786e-03,  2.0401e-02,\n",
       "                      -6.4405e-03, -1.4019e-02, -9.8601e-03,  1.6383e-02, -9.5720e-04,\n",
       "                       1.2716e-02, -1.2003e-02, -6.8462e-03,  2.1731e-02, -2.0780e-02,\n",
       "                      -1.0256e-02,  7.4248e-03,  3.1262e-03, -1.2943e-02,  1.0049e-02,\n",
       "                      -1.7951e-02, -9.1568e-03,  1.8474e-02,  1.2910e-02,  6.5403e-04,\n",
       "                      -9.2948e-03,  4.9036e-04,  6.0875e-04,  9.9504e-03, -7.5526e-03,\n",
       "                      -5.5991e-03, -1.6698e-02])),\n",
       "             ('encoder.layers.1.residual_connections.0.norm.alpha',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('encoder.layers.1.residual_connections.0.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('encoder.layers.1.residual_connections.1.norm.alpha',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('encoder.layers.1.residual_connections.1.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('encoder.layers.2.self_attention_block.w_q.weight',\n",
       "              tensor([[-0.0640,  0.0312, -0.0542,  ...,  0.0019,  0.0685,  0.0371],\n",
       "                      [ 0.0360, -0.0075, -0.0711,  ...,  0.0600,  0.0521,  0.0131],\n",
       "                      [ 0.0496, -0.0718, -0.0341,  ..., -0.0407, -0.0331,  0.0194],\n",
       "                      ...,\n",
       "                      [ 0.0428,  0.0416, -0.0270,  ...,  0.0010,  0.0291, -0.0466],\n",
       "                      [ 0.0362, -0.0647,  0.0758,  ..., -0.0548, -0.0353,  0.0306],\n",
       "                      [ 0.0498, -0.0129, -0.0403,  ...,  0.0116, -0.0679, -0.0360]])),\n",
       "             ('encoder.layers.2.self_attention_block.w_k.weight',\n",
       "              tensor([[-0.0620, -0.0275,  0.0230,  ..., -0.0523,  0.0722, -0.0237],\n",
       "                      [ 0.0734, -0.0292,  0.0223,  ..., -0.0284, -0.0468,  0.0586],\n",
       "                      [ 0.0272,  0.0191, -0.0435,  ...,  0.0583,  0.0204, -0.0643],\n",
       "                      ...,\n",
       "                      [ 0.0427, -0.0607, -0.0327,  ..., -0.0460, -0.0726,  0.0669],\n",
       "                      [-0.0334,  0.0053, -0.0241,  ...,  0.0023,  0.0374, -0.0194],\n",
       "                      [ 0.0229,  0.0139, -0.0416,  ...,  0.0154, -0.0288, -0.0599]])),\n",
       "             ('encoder.layers.2.self_attention_block.w_v.weight',\n",
       "              tensor([[-0.0143,  0.0513, -0.0108,  ..., -0.0280,  0.0731,  0.0433],\n",
       "                      [-0.0668, -0.0625,  0.0046,  ...,  0.0647, -0.0745,  0.0166],\n",
       "                      [ 0.0708,  0.0012,  0.0762,  ..., -0.0408, -0.0232, -0.0013],\n",
       "                      ...,\n",
       "                      [-0.0310, -0.0288, -0.0105,  ..., -0.0125, -0.0756,  0.0502],\n",
       "                      [ 0.0699,  0.0481, -0.0158,  ..., -0.0696, -0.0746, -0.0328],\n",
       "                      [ 0.0524, -0.0399, -0.0742,  ...,  0.0370, -0.0031,  0.0460]])),\n",
       "             ('encoder.layers.2.self_attention_block.w_o.weight',\n",
       "              tensor([[-0.0442,  0.0013, -0.0530,  ..., -0.0322, -0.0740,  0.0764],\n",
       "                      [ 0.0241, -0.0044,  0.0253,  ..., -0.0332, -0.0101, -0.0223],\n",
       "                      [ 0.0657,  0.0620, -0.0293,  ..., -0.0251,  0.0182,  0.0213],\n",
       "                      ...,\n",
       "                      [-0.0757, -0.0184, -0.0732,  ..., -0.0003, -0.0123, -0.0225],\n",
       "                      [-0.0402, -0.0631, -0.0278,  ..., -0.0687,  0.0201, -0.0312],\n",
       "                      [-0.0202, -0.0181,  0.0141,  ..., -0.0429,  0.0313,  0.0468]])),\n",
       "             ('encoder.layers.2.feed_forward_block.linear_1.weight',\n",
       "              tensor([[ 0.0127, -0.0338, -0.0225,  ..., -0.0244, -0.0327,  0.0307],\n",
       "                      [ 0.0462, -0.0091, -0.0045,  ...,  0.0280, -0.0429, -0.0186],\n",
       "                      [-0.0341, -0.0467,  0.0471,  ...,  0.0249,  0.0436, -0.0193],\n",
       "                      ...,\n",
       "                      [-0.0469,  0.0192, -0.0061,  ...,  0.0410,  0.0228,  0.0277],\n",
       "                      [ 0.0033,  0.0328, -0.0128,  ..., -0.0374,  0.0446, -0.0169],\n",
       "                      [ 0.0171, -0.0461,  0.0329,  ..., -0.0097, -0.0476, -0.0062]])),\n",
       "             ('encoder.layers.2.feed_forward_block.linear_1.bias',\n",
       "              tensor([-0.0307,  0.0108,  0.0187,  ...,  0.0126,  0.0348, -0.0146])),\n",
       "             ('encoder.layers.2.feed_forward_block.linear_2.weight',\n",
       "              tensor([[ 0.0360,  0.0239, -0.0302,  ..., -0.0299,  0.0065,  0.0280],\n",
       "                      [-0.0385, -0.0061,  0.0242,  ...,  0.0067, -0.0089, -0.0147],\n",
       "                      [ 0.0056,  0.0144, -0.0318,  ...,  0.0033, -0.0379,  0.0420],\n",
       "                      ...,\n",
       "                      [ 0.0028, -0.0158, -0.0379,  ..., -0.0209, -0.0098, -0.0330],\n",
       "                      [ 0.0082,  0.0318,  0.0244,  ..., -0.0198,  0.0381, -0.0118],\n",
       "                      [-0.0217, -0.0215,  0.0396,  ...,  0.0097,  0.0250,  0.0462]])),\n",
       "             ('encoder.layers.2.feed_forward_block.linear_2.bias',\n",
       "              tensor([-1.9259e-02,  5.2717e-03,  1.6396e-02, -1.6688e-02, -1.9094e-02,\n",
       "                      -6.6219e-03,  3.1967e-03,  9.7322e-03,  2.5756e-03, -1.7647e-03,\n",
       "                       6.7839e-03,  5.7014e-03,  2.0984e-03, -1.0405e-02, -1.2698e-02,\n",
       "                       1.2291e-02,  1.6175e-02,  8.7556e-04, -2.1387e-02, -2.3795e-03,\n",
       "                      -1.6353e-02, -1.1170e-02,  2.0491e-02,  2.0156e-02, -1.0145e-02,\n",
       "                      -8.7049e-03, -1.1921e-02, -2.0771e-02, -8.9388e-03,  2.5271e-03,\n",
       "                       1.2274e-02, -1.0469e-04,  1.9636e-02,  1.7592e-02, -9.7753e-03,\n",
       "                       9.4869e-04,  1.4567e-02, -1.8990e-03,  1.2999e-02,  2.7925e-03,\n",
       "                      -1.2169e-02,  1.5955e-02,  2.0678e-02,  1.5475e-02,  1.5006e-02,\n",
       "                       1.1524e-02, -2.7188e-03,  1.3921e-02,  1.9056e-02,  1.6181e-04,\n",
       "                       1.3982e-02, -7.4481e-03, -3.7586e-03, -2.1745e-03,  3.8174e-03,\n",
       "                      -1.1650e-03, -3.2412e-03,  2.1017e-02,  6.1348e-03, -6.7867e-03,\n",
       "                      -1.6416e-02,  1.2105e-02,  2.0640e-02, -7.9739e-03,  1.3660e-02,\n",
       "                      -1.4520e-02, -8.6087e-03,  1.0932e-02,  2.1328e-02,  4.7076e-03,\n",
       "                       6.6961e-03, -1.5025e-02,  9.5845e-03, -1.4400e-02, -1.4630e-02,\n",
       "                       1.9572e-02, -5.6688e-03, -1.8308e-02,  6.1258e-03, -6.6571e-03,\n",
       "                      -1.8834e-02,  1.0957e-03,  1.7540e-02,  2.0991e-02, -3.8012e-03,\n",
       "                      -9.9434e-03, -2.7435e-03,  3.1777e-03, -1.5762e-02, -1.0366e-02,\n",
       "                      -1.8734e-02,  1.7078e-03,  9.4948e-03,  2.0615e-02, -1.9715e-02,\n",
       "                       2.1151e-02, -5.4484e-03, -2.2075e-02, -1.3869e-02, -1.5699e-02,\n",
       "                       1.7487e-02, -1.2896e-02, -7.4978e-03, -1.0177e-02, -1.2355e-02,\n",
       "                      -3.5695e-03, -2.1585e-02, -8.9117e-03, -2.1715e-02,  1.1408e-03,\n",
       "                      -1.0537e-02,  4.2329e-04, -1.6360e-02,  2.9366e-04, -9.3253e-03,\n",
       "                      -7.4267e-03, -1.5435e-02, -6.3976e-03, -1.8787e-02, -1.5004e-02,\n",
       "                      -1.6058e-02,  6.1080e-03, -1.1430e-02,  1.3538e-02,  1.5077e-02,\n",
       "                       5.6347e-03, -1.1531e-02, -1.8674e-02, -1.5589e-02, -1.8791e-02,\n",
       "                       1.3380e-02, -1.0237e-02,  1.6757e-02,  1.3023e-02,  2.1268e-02,\n",
       "                       4.5836e-03,  3.4279e-03,  1.7518e-02, -3.6251e-03, -9.6956e-03,\n",
       "                      -1.4503e-02,  1.6960e-02,  1.2530e-02, -1.1669e-03,  1.5415e-03,\n",
       "                      -2.1384e-02, -8.8037e-03,  1.8312e-02, -1.9893e-02,  6.0224e-03,\n",
       "                      -1.2738e-02, -4.4380e-03, -1.3160e-02, -1.0584e-02,  1.1771e-02,\n",
       "                       7.4182e-03, -1.0073e-02, -9.4208e-03, -2.0347e-03, -2.9905e-03,\n",
       "                       2.0773e-02,  9.8791e-03,  2.1175e-02, -4.6625e-04,  9.7922e-03,\n",
       "                       1.1716e-02,  6.0061e-03, -9.5745e-04, -1.6281e-02, -9.9238e-03,\n",
       "                       1.4121e-02,  1.9183e-02, -7.1428e-03, -1.4044e-02,  9.9646e-03,\n",
       "                       1.3275e-03, -2.1993e-02,  7.2510e-03, -7.1076e-04, -1.4094e-02,\n",
       "                      -2.1893e-02,  1.5691e-03,  2.5938e-03,  2.1032e-02, -1.6048e-02,\n",
       "                      -2.0686e-02, -1.2693e-02,  1.4297e-02,  1.2326e-02, -2.1880e-02,\n",
       "                      -1.1929e-02,  8.2916e-05,  6.3024e-03,  2.0336e-02, -2.4264e-03,\n",
       "                       1.8762e-02,  9.7166e-03, -1.4394e-02, -1.5225e-02,  2.1807e-02,\n",
       "                       1.3327e-02, -1.9588e-02, -1.6042e-02, -1.4824e-02, -1.0850e-02,\n",
       "                      -6.0372e-03, -1.1230e-03, -2.0461e-02, -9.2288e-03,  6.5277e-03,\n",
       "                       1.0913e-02,  6.3612e-03, -2.1220e-02, -1.8210e-02, -1.4922e-02,\n",
       "                      -1.2607e-02,  1.2869e-02, -8.2130e-03, -6.4442e-03, -1.5783e-02,\n",
       "                       1.7525e-03,  6.8185e-03,  6.7505e-03, -1.5819e-02,  1.2281e-02,\n",
       "                       1.6174e-02,  1.0534e-03, -5.6109e-03,  2.8705e-03,  2.8059e-04,\n",
       "                       1.5183e-02,  1.6908e-02, -7.1600e-03,  7.0074e-03, -4.9409e-03,\n",
       "                       1.5663e-02,  1.2859e-02, -1.1090e-02, -7.7255e-03,  1.7124e-02,\n",
       "                       1.2825e-02, -1.6297e-02,  3.8119e-03, -2.1212e-02, -1.5787e-02,\n",
       "                       1.7179e-03, -2.0934e-02,  8.1300e-03, -8.7367e-03, -1.1837e-02,\n",
       "                       2.5635e-03, -4.0933e-03,  1.8103e-02, -1.6841e-02,  1.3281e-02,\n",
       "                       1.8166e-03,  8.0578e-03, -1.5617e-02, -1.9961e-02, -1.8436e-02,\n",
       "                      -1.9376e-02, -3.6010e-03, -2.7571e-03, -5.2677e-03, -6.5679e-03,\n",
       "                       1.3394e-02, -1.7416e-02,  1.1451e-02, -6.5311e-03,  1.9977e-02,\n",
       "                       1.1357e-02,  1.8404e-02,  1.4903e-02, -4.1942e-03,  1.7927e-02,\n",
       "                       2.4262e-03, -3.4225e-03,  9.4377e-03,  1.5405e-02, -8.3749e-03,\n",
       "                      -1.4133e-02,  1.2152e-02,  1.7021e-02, -5.1466e-03, -1.2335e-02,\n",
       "                      -1.7057e-02, -8.8603e-04,  1.3118e-02,  1.3891e-02,  9.9603e-03,\n",
       "                      -1.4953e-02,  5.8021e-03,  1.9780e-03,  2.8862e-03, -2.0959e-02,\n",
       "                       8.1947e-03,  2.8151e-03, -1.6943e-03,  5.6706e-03, -1.7538e-02,\n",
       "                      -7.8408e-03,  1.1171e-02, -2.7466e-03, -1.4066e-03,  2.0887e-02,\n",
       "                      -2.8306e-03,  1.5617e-03,  6.8256e-04,  1.4230e-02,  1.4571e-02,\n",
       "                       1.4372e-02,  1.8863e-02,  4.1837e-04, -9.0712e-04,  1.0173e-02,\n",
       "                      -9.5320e-03,  1.2819e-02, -1.7946e-02,  1.1739e-02, -3.3897e-03,\n",
       "                      -8.2414e-04, -3.8871e-03,  6.4727e-03, -1.3302e-03, -4.6348e-03,\n",
       "                      -6.1051e-03,  1.1067e-02, -9.6829e-03, -1.9151e-02,  9.5929e-03,\n",
       "                      -1.3382e-02,  1.4845e-03, -1.1112e-02,  2.1226e-02,  9.3120e-03,\n",
       "                       1.7036e-05, -1.6852e-02, -7.6812e-03, -7.8016e-03, -7.5444e-04,\n",
       "                      -1.8494e-02, -1.1137e-02, -2.0937e-02,  8.7040e-03,  1.0806e-02,\n",
       "                       1.1403e-02, -9.2577e-03,  9.0266e-03, -1.0732e-02,  1.9805e-02,\n",
       "                      -1.1894e-03, -1.7956e-02,  1.2967e-02, -7.1147e-03, -1.3506e-02,\n",
       "                      -1.8380e-03, -3.5875e-03, -6.3202e-03,  2.6712e-03,  7.9031e-04,\n",
       "                      -6.1625e-03,  2.1683e-02, -1.3596e-02, -9.0620e-03, -9.7106e-03,\n",
       "                       1.3330e-02,  9.0716e-03,  7.5929e-03, -1.2994e-02,  7.4198e-03,\n",
       "                       1.1049e-02,  1.7840e-02, -1.7011e-02,  1.5375e-02, -1.0208e-02,\n",
       "                       1.4141e-02, -1.9439e-02,  2.1073e-03, -1.4540e-02, -1.7376e-02,\n",
       "                       6.9141e-03, -8.8151e-03,  2.0326e-02, -1.7507e-02,  5.2201e-04,\n",
       "                      -8.8181e-03, -2.1415e-02, -4.2971e-03, -1.8384e-02, -3.6205e-03,\n",
       "                       4.6632e-03,  1.1910e-02,  1.7429e-02,  8.8972e-03, -1.3973e-02,\n",
       "                       1.7906e-02,  1.0465e-02, -1.9903e-02, -1.7730e-02,  6.4735e-03,\n",
       "                      -9.8285e-03,  1.5120e-02, -6.2457e-03, -1.1284e-02, -8.4741e-03,\n",
       "                       2.4954e-03, -1.2483e-02, -4.9057e-03, -5.8035e-03, -1.1994e-02,\n",
       "                       1.5093e-02,  1.1793e-02,  8.4797e-03, -8.4910e-03, -3.5570e-03,\n",
       "                       3.3509e-03,  6.8451e-03, -1.6795e-03, -1.6879e-02, -9.5380e-03,\n",
       "                       1.7029e-02,  7.6845e-03,  8.7384e-03, -5.3821e-03, -5.3431e-04,\n",
       "                       3.6694e-03, -2.1982e-03,  2.1829e-02, -9.2854e-03,  9.1395e-03,\n",
       "                      -5.1321e-03,  3.0476e-03, -1.9772e-02, -1.7163e-02,  1.8749e-02,\n",
       "                      -2.0249e-02,  1.5840e-02,  1.5693e-02, -8.1400e-03, -4.3856e-03,\n",
       "                      -5.8187e-03,  1.2880e-02, -1.4892e-02,  9.7984e-04,  8.7554e-03,\n",
       "                      -1.1861e-02, -1.2240e-02, -4.9684e-03, -1.5303e-02, -3.6254e-03,\n",
       "                      -9.9865e-03,  1.9185e-02,  1.2461e-02, -1.1687e-02, -2.3004e-03,\n",
       "                      -1.7176e-02,  8.2734e-03,  1.3357e-02,  8.3445e-03, -1.5047e-02,\n",
       "                       2.0941e-02,  1.6658e-02,  4.6303e-03,  1.7666e-02, -5.6248e-03,\n",
       "                      -1.4534e-02, -1.6604e-04,  4.0539e-03,  2.1928e-02, -8.1214e-03,\n",
       "                      -1.4549e-03,  1.9258e-02, -1.0996e-02, -8.3810e-03,  2.4579e-03,\n",
       "                       4.0514e-03, -2.0217e-02,  1.9673e-02, -6.4191e-03,  2.8205e-03,\n",
       "                      -9.7228e-03, -7.8810e-03,  1.3654e-02,  2.9898e-03,  7.6707e-03,\n",
       "                      -1.8129e-02,  1.5092e-03,  5.9728e-03, -2.1581e-02, -1.1675e-02,\n",
       "                       1.3224e-02, -9.3237e-03, -1.9193e-02, -4.9038e-03, -1.1644e-02,\n",
       "                       5.5033e-03,  3.5192e-03, -3.1772e-03,  1.6919e-03,  1.1602e-02,\n",
       "                       1.2773e-02,  7.5497e-03, -1.7580e-02, -1.5550e-02,  7.4516e-03,\n",
       "                       1.1439e-02, -4.3396e-03,  5.3331e-03, -3.3547e-03,  4.0726e-03,\n",
       "                      -1.8581e-02, -1.8747e-02])),\n",
       "             ('encoder.layers.2.residual_connections.0.norm.alpha',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('encoder.layers.2.residual_connections.0.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('encoder.layers.2.residual_connections.1.norm.alpha',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('encoder.layers.2.residual_connections.1.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('encoder.layers.3.self_attention_block.w_q.weight',\n",
       "              tensor([[-0.0250, -0.0134, -0.0332,  ...,  0.0226,  0.0476, -0.0398],\n",
       "                      [ 0.0764,  0.0125, -0.0353,  ...,  0.0673,  0.0560, -0.0645],\n",
       "                      [-0.0664,  0.0398, -0.0246,  ...,  0.0015,  0.0237, -0.0572],\n",
       "                      ...,\n",
       "                      [-0.0340, -0.0414, -0.0496,  ..., -0.0037, -0.0272,  0.0537],\n",
       "                      [ 0.0591,  0.0720, -0.0110,  ...,  0.0706, -0.0427,  0.0407],\n",
       "                      [ 0.0201, -0.0165,  0.0175,  ...,  0.0275, -0.0092,  0.0276]])),\n",
       "             ('encoder.layers.3.self_attention_block.w_k.weight',\n",
       "              tensor([[-0.0607, -0.0517,  0.0063,  ..., -0.0107,  0.0377, -0.0018],\n",
       "                      [ 0.0349, -0.0331,  0.0651,  ..., -0.0477,  0.0207,  0.0140],\n",
       "                      [-0.0093,  0.0049, -0.0066,  ..., -0.0664, -0.0061, -0.0398],\n",
       "                      ...,\n",
       "                      [ 0.0248,  0.0425,  0.0388,  ..., -0.0750, -0.0274, -0.0758],\n",
       "                      [ 0.0720, -0.0190, -0.0293,  ..., -0.0566,  0.0471, -0.0380],\n",
       "                      [-0.0572,  0.0123,  0.0437,  ...,  0.0652, -0.0339, -0.0589]])),\n",
       "             ('encoder.layers.3.self_attention_block.w_v.weight',\n",
       "              tensor([[-0.0077,  0.0144, -0.0297,  ..., -0.0059, -0.0221, -0.0668],\n",
       "                      [ 0.0698, -0.0509, -0.0428,  ..., -0.0649,  0.0653, -0.0298],\n",
       "                      [ 0.0424,  0.0680,  0.0182,  ..., -0.0104,  0.0597, -0.0056],\n",
       "                      ...,\n",
       "                      [ 0.0552, -0.0673, -0.0082,  ..., -0.0729,  0.0607,  0.0134],\n",
       "                      [-0.0213,  0.0371, -0.0140,  ..., -0.0048,  0.0687,  0.0729],\n",
       "                      [ 0.0250, -0.0053, -0.0021,  ...,  0.0344, -0.0263,  0.0743]])),\n",
       "             ('encoder.layers.3.self_attention_block.w_o.weight',\n",
       "              tensor([[ 0.0418, -0.0350,  0.0249,  ...,  0.0515, -0.0599, -0.0689],\n",
       "                      [ 0.0423,  0.0355, -0.0323,  ..., -0.0168,  0.0035,  0.0299],\n",
       "                      [-0.0702,  0.0662, -0.0216,  ...,  0.0058,  0.0114, -0.0665],\n",
       "                      ...,\n",
       "                      [ 0.0220, -0.0310, -0.0087,  ...,  0.0504, -0.0017,  0.0567],\n",
       "                      [-0.0593, -0.0174,  0.0269,  ...,  0.0424, -0.0221, -0.0509],\n",
       "                      [ 0.0667, -0.0206, -0.0445,  ..., -0.0071,  0.0045,  0.0221]])),\n",
       "             ('encoder.layers.3.feed_forward_block.linear_1.weight',\n",
       "              tensor([[ 0.0481,  0.0447,  0.0314,  ...,  0.0090,  0.0444,  0.0183],\n",
       "                      [ 0.0212, -0.0175, -0.0314,  ...,  0.0296,  0.0373, -0.0473],\n",
       "                      [ 0.0483,  0.0394, -0.0057,  ...,  0.0333, -0.0314,  0.0232],\n",
       "                      ...,\n",
       "                      [ 0.0283, -0.0097, -0.0049,  ...,  0.0210, -0.0472, -0.0466],\n",
       "                      [ 0.0281, -0.0473,  0.0476,  ..., -0.0460, -0.0052, -0.0002],\n",
       "                      [ 0.0397,  0.0358,  0.0036,  ...,  0.0082,  0.0012,  0.0303]])),\n",
       "             ('encoder.layers.3.feed_forward_block.linear_1.bias',\n",
       "              tensor([ 0.0419, -0.0301,  0.0036,  ..., -0.0056, -0.0192, -0.0148])),\n",
       "             ('encoder.layers.3.feed_forward_block.linear_2.weight',\n",
       "              tensor([[ 0.0026, -0.0305,  0.0447,  ..., -0.0391,  0.0180,  0.0084],\n",
       "                      [-0.0040, -0.0193, -0.0362,  ...,  0.0348,  0.0160,  0.0389],\n",
       "                      [ 0.0458, -0.0353, -0.0057,  ..., -0.0457,  0.0078,  0.0170],\n",
       "                      ...,\n",
       "                      [ 0.0024,  0.0345,  0.0391,  ...,  0.0426,  0.0113, -0.0017],\n",
       "                      [-0.0192, -0.0475,  0.0242,  ..., -0.0174, -0.0279,  0.0127],\n",
       "                      [-0.0421, -0.0455, -0.0329,  ...,  0.0150, -0.0319,  0.0415]])),\n",
       "             ('encoder.layers.3.feed_forward_block.linear_2.bias',\n",
       "              tensor([ 2.1586e-02,  9.2488e-03, -1.8127e-02,  9.6974e-03,  2.0005e-02,\n",
       "                      -5.7476e-03, -1.8227e-02,  6.3886e-03, -1.0979e-02, -1.3187e-02,\n",
       "                      -3.6842e-03, -1.3801e-02, -1.9457e-02,  4.1917e-03,  4.4568e-03,\n",
       "                       1.8054e-02,  1.3384e-02,  2.0638e-02, -1.9713e-02, -5.8337e-03,\n",
       "                       7.9953e-03,  4.3476e-03, -1.3513e-02,  1.1496e-02, -1.4081e-03,\n",
       "                      -1.8281e-02, -1.5002e-02, -6.6608e-03, -6.5485e-03,  5.5066e-03,\n",
       "                       2.0645e-02,  6.2659e-03, -8.0640e-03,  4.9815e-03, -1.4675e-02,\n",
       "                       1.9511e-02,  1.6715e-02,  2.0716e-02, -1.2773e-02,  7.4315e-03,\n",
       "                       1.4276e-03,  5.3195e-03, -1.8405e-02,  9.0262e-03,  1.9665e-02,\n",
       "                       1.2665e-02, -1.0460e-02,  1.7920e-02, -1.3391e-02,  6.2546e-03,\n",
       "                       1.7129e-02,  1.6423e-02, -6.5775e-03,  3.9523e-03,  1.5396e-02,\n",
       "                      -1.5677e-02, -9.4789e-03,  1.7380e-02, -1.7271e-02, -1.7679e-02,\n",
       "                      -4.5905e-03, -6.3512e-03,  2.0393e-02,  1.8212e-02, -1.2227e-02,\n",
       "                      -1.3441e-02, -2.1883e-02, -1.3446e-02, -1.4251e-02, -1.3660e-02,\n",
       "                      -2.7186e-03,  7.3394e-04,  1.7850e-03,  1.6013e-02, -1.0912e-02,\n",
       "                      -2.1928e-02,  7.6177e-03,  5.5731e-03,  1.5255e-02,  7.6976e-04,\n",
       "                       8.1333e-03,  1.0200e-02,  1.0266e-02,  1.3352e-02,  4.4573e-03,\n",
       "                       8.6585e-03, -2.8144e-03,  5.6687e-03, -2.1855e-02, -9.1132e-03,\n",
       "                       2.6605e-03,  1.0590e-02,  1.7470e-02, -1.0038e-03,  9.9060e-03,\n",
       "                      -1.6141e-02, -1.3913e-02,  1.9155e-02,  1.9190e-02, -2.0994e-02,\n",
       "                      -6.5632e-03,  3.6686e-03,  7.2191e-03, -3.1079e-03, -1.5078e-02,\n",
       "                      -1.5116e-02,  7.0077e-04,  1.3140e-03, -6.7308e-03, -8.8695e-03,\n",
       "                      -1.1730e-03, -1.4974e-02,  4.5710e-04,  2.0677e-02,  4.8631e-03,\n",
       "                       5.0843e-03, -4.7441e-03,  4.8346e-03, -5.9666e-04, -7.1520e-03,\n",
       "                      -1.7501e-02,  2.0120e-02, -1.5373e-02, -1.5585e-02,  1.8658e-02,\n",
       "                       9.7384e-03, -1.8844e-02, -9.4043e-03,  1.8841e-02,  4.0100e-04,\n",
       "                      -7.6301e-03,  1.2508e-02, -1.8180e-02, -1.5291e-03, -1.4496e-02,\n",
       "                      -1.9571e-02, -1.8802e-03,  2.2780e-04,  1.2241e-02, -5.3593e-03,\n",
       "                      -1.7723e-02,  2.1351e-02,  9.6281e-03, -1.4750e-02, -2.8356e-04,\n",
       "                       2.1139e-02, -4.2689e-03, -2.0579e-02,  1.8166e-02,  1.7087e-02,\n",
       "                       1.1668e-02, -9.8633e-03, -1.3471e-02, -1.0810e-02, -1.3076e-02,\n",
       "                       5.1782e-03,  8.0513e-03,  1.1031e-03,  8.2415e-03,  1.8068e-02,\n",
       "                       6.0525e-03, -5.1327e-03, -2.1422e-02,  1.5851e-02, -8.5246e-03,\n",
       "                      -3.4752e-03, -5.4827e-04,  2.0059e-02, -1.5830e-02, -8.4415e-03,\n",
       "                       8.9027e-03,  1.6906e-02, -1.6998e-03, -1.8248e-02,  1.9375e-02,\n",
       "                       2.0588e-02, -2.0741e-02, -3.4040e-03,  1.5918e-02,  3.2325e-03,\n",
       "                      -3.9552e-03, -1.5969e-04,  7.8074e-03,  1.5282e-02,  1.1740e-02,\n",
       "                      -1.3777e-02, -7.9035e-03, -1.9584e-02,  1.6280e-02,  1.3445e-02,\n",
       "                      -1.4571e-02,  1.0761e-02,  1.2190e-02, -2.1328e-03,  2.1217e-02,\n",
       "                      -1.8166e-02,  1.2315e-02, -1.9065e-02, -1.6832e-02, -1.6065e-04,\n",
       "                       2.6611e-03,  1.3312e-02, -1.1604e-02,  3.0455e-03,  1.4084e-02,\n",
       "                       1.9389e-02, -4.9641e-03,  1.3039e-02,  4.6199e-03,  7.0139e-03,\n",
       "                      -9.3150e-03, -7.4748e-03, -1.1723e-02, -1.8143e-02, -2.7720e-04,\n",
       "                       1.3246e-02,  2.1705e-02,  2.0361e-02,  1.2007e-02, -5.1131e-03,\n",
       "                      -1.6983e-03,  1.2590e-02, -4.7159e-03,  3.2477e-04, -2.0187e-02,\n",
       "                       2.0726e-02, -9.3575e-03,  1.7178e-02,  9.6306e-04,  1.5227e-02,\n",
       "                      -1.5524e-02,  1.9120e-02, -1.6484e-02,  1.3347e-02, -2.0550e-02,\n",
       "                       9.7711e-03,  1.6039e-02, -1.4903e-02, -1.6307e-02,  3.7577e-03,\n",
       "                       3.5929e-03,  2.0484e-02, -1.5839e-02,  1.5098e-02,  1.4749e-02,\n",
       "                      -1.6330e-02, -6.2293e-03,  3.6892e-03, -2.9487e-03, -7.6917e-03,\n",
       "                       5.6376e-03, -1.8117e-02,  1.2067e-02,  9.3644e-03, -6.5945e-03,\n",
       "                      -5.2816e-03, -1.5730e-02,  2.3534e-03, -1.0425e-02,  1.6415e-02,\n",
       "                      -6.0427e-03,  3.8517e-03, -1.9752e-03,  1.3992e-02,  2.1418e-02,\n",
       "                       1.2837e-02,  1.8961e-02,  1.4887e-02,  1.4072e-02, -6.3171e-03,\n",
       "                      -1.3471e-02, -7.0924e-03, -1.6075e-02, -4.4728e-03, -1.9811e-02,\n",
       "                      -9.2327e-03,  4.2751e-03,  6.4192e-05, -1.2631e-02, -2.1148e-02,\n",
       "                       5.9069e-03,  1.3637e-02, -1.0170e-02, -2.3644e-03,  1.1346e-02,\n",
       "                       1.4950e-03, -1.8756e-02,  4.2724e-03,  2.2063e-02, -2.1201e-02,\n",
       "                       1.9878e-02, -1.7473e-02,  1.6872e-02, -1.1044e-02,  1.8676e-02,\n",
       "                       1.7987e-02,  1.1357e-02, -1.0382e-03, -4.4845e-03, -1.1876e-02,\n",
       "                       1.1073e-02, -1.8456e-02,  5.3990e-03,  6.0062e-03,  1.7071e-02,\n",
       "                      -1.5457e-02, -2.0597e-03, -2.0810e-02, -1.1202e-02, -1.5387e-02,\n",
       "                      -1.9523e-02,  1.9540e-02, -7.9223e-03, -1.6347e-02, -1.1655e-02,\n",
       "                      -1.5207e-03,  7.4984e-03, -1.2515e-02,  6.2223e-03, -1.4125e-03,\n",
       "                      -1.1693e-02, -1.6003e-02, -1.4168e-02, -1.0060e-02, -4.4915e-03,\n",
       "                       3.2610e-03, -8.7632e-03,  4.3668e-03,  2.0428e-02, -1.9455e-03,\n",
       "                      -4.4903e-03,  1.2750e-02,  5.1460e-03, -1.7519e-02, -2.0303e-02,\n",
       "                       1.1271e-02,  2.2041e-04, -2.4141e-03,  1.7166e-02, -1.2134e-02,\n",
       "                       1.2940e-02, -3.9510e-03,  1.2941e-02,  8.0882e-03,  8.4974e-03,\n",
       "                       2.9906e-03,  1.5234e-02,  4.6443e-03, -1.7049e-02, -1.1443e-02,\n",
       "                       1.3522e-02,  9.7425e-03, -1.4998e-02,  1.9195e-02, -9.8004e-03,\n",
       "                      -1.4461e-02,  1.2197e-02,  1.1576e-02, -9.0519e-03,  1.5442e-02,\n",
       "                       8.4485e-03, -1.7696e-02,  1.3954e-02, -2.8944e-03, -1.0910e-02,\n",
       "                       1.3306e-02,  1.6236e-02,  2.0163e-02,  1.0959e-02,  1.0712e-02,\n",
       "                       1.7728e-02,  1.7268e-03,  1.4032e-02,  1.9446e-02,  1.1883e-02,\n",
       "                      -9.6797e-03,  1.1365e-02, -1.2812e-02, -8.3002e-03, -1.0574e-02,\n",
       "                      -1.9785e-02, -3.0882e-03,  1.2073e-03, -1.1885e-04,  2.0603e-02,\n",
       "                      -1.0075e-02, -5.1215e-04, -2.1304e-02,  1.5549e-02, -1.0315e-02,\n",
       "                       8.9499e-03,  6.4676e-03,  1.7252e-02,  1.0891e-02,  2.0167e-02,\n",
       "                      -2.0799e-02, -1.7090e-03,  8.8892e-03,  9.3608e-03, -1.3781e-02,\n",
       "                      -5.5640e-03, -3.7131e-03,  5.9076e-04,  5.8220e-03, -2.2880e-03,\n",
       "                      -7.9993e-03,  1.3794e-02, -1.7409e-03, -1.8699e-02, -8.3726e-03,\n",
       "                      -1.9318e-03,  6.5554e-03, -1.8824e-02,  2.0237e-02, -3.9830e-03,\n",
       "                       1.8178e-02,  9.3948e-03, -1.1960e-02, -5.2376e-03,  1.8105e-03,\n",
       "                       1.6044e-02, -7.1465e-03, -7.9668e-03, -1.5922e-02, -1.9511e-02,\n",
       "                       7.5409e-03,  1.7801e-02,  8.1213e-03,  7.1553e-03,  9.2664e-03,\n",
       "                       5.4296e-04, -1.9436e-02, -6.6385e-03,  2.1524e-02, -2.0781e-02,\n",
       "                       1.5742e-02,  1.8810e-03, -2.0419e-02, -1.7482e-02,  1.3232e-02,\n",
       "                       1.0401e-02, -1.9044e-02,  1.7291e-02,  1.3658e-02, -3.2246e-03,\n",
       "                       2.0577e-02,  1.5703e-02,  6.3747e-03, -1.5036e-02,  8.2442e-03,\n",
       "                       1.4303e-02,  1.3317e-02,  1.9033e-02,  1.6572e-02, -2.0084e-02,\n",
       "                      -8.9497e-03, -1.8099e-02,  2.0193e-02, -1.9259e-03, -1.7190e-02,\n",
       "                       8.3352e-03,  1.2384e-02, -2.0740e-03, -6.8836e-03,  3.7682e-03,\n",
       "                       2.4319e-03,  7.8413e-03,  1.0858e-02,  1.3197e-02, -1.1548e-02,\n",
       "                      -2.1478e-02,  1.4272e-02,  4.7157e-03, -1.1904e-02, -1.9823e-02,\n",
       "                      -6.1901e-04, -2.0941e-02, -7.0483e-03,  1.0191e-02, -1.8400e-03,\n",
       "                      -1.5277e-02,  1.2734e-02, -7.6597e-03, -2.1569e-02, -1.5090e-02,\n",
       "                       6.1795e-03, -5.7916e-04,  7.2676e-03,  2.1848e-02, -1.1741e-03,\n",
       "                      -2.0321e-02, -2.1149e-02, -1.0032e-02,  1.0703e-02,  2.6865e-03,\n",
       "                      -8.4782e-03,  1.1839e-02,  6.7154e-03, -9.5319e-03, -7.8807e-03,\n",
       "                       2.1812e-02,  3.7096e-04, -1.8344e-02,  1.9215e-02,  1.5298e-03,\n",
       "                      -1.5574e-02,  1.5522e-02, -5.8772e-05,  1.3338e-02, -6.9887e-03,\n",
       "                       4.4392e-03, -4.6616e-03])),\n",
       "             ('encoder.layers.3.residual_connections.0.norm.alpha',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('encoder.layers.3.residual_connections.0.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('encoder.layers.3.residual_connections.1.norm.alpha',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('encoder.layers.3.residual_connections.1.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('encoder.layers.4.self_attention_block.w_q.weight',\n",
       "              tensor([[ 0.0353, -0.0737,  0.0407,  ..., -0.0315, -0.0406,  0.0626],\n",
       "                      [-0.0404,  0.0350,  0.0294,  ..., -0.0425, -0.0466,  0.0022],\n",
       "                      [ 0.0318,  0.0205,  0.0067,  ...,  0.0585, -0.0139, -0.0729],\n",
       "                      ...,\n",
       "                      [ 0.0620,  0.0741,  0.0275,  ...,  0.0278,  0.0125, -0.0569],\n",
       "                      [-0.0167,  0.0664, -0.0158,  ..., -0.0741, -0.0464, -0.0100],\n",
       "                      [-0.0552, -0.0107,  0.0050,  ..., -0.0281, -0.0403,  0.0220]])),\n",
       "             ('encoder.layers.4.self_attention_block.w_k.weight',\n",
       "              tensor([[-0.0681, -0.0046, -0.0393,  ..., -0.0352,  0.0335, -0.0345],\n",
       "                      [-0.0307, -0.0516,  0.0360,  ..., -0.0030, -0.0592,  0.0249],\n",
       "                      [ 0.0571, -0.0695, -0.0162,  ..., -0.0549,  0.0135, -0.0361],\n",
       "                      ...,\n",
       "                      [-0.0251, -0.0081,  0.0286,  ...,  0.0528,  0.0405, -0.0421],\n",
       "                      [ 0.0610, -0.0245,  0.0089,  ..., -0.0609, -0.0696, -0.0418],\n",
       "                      [ 0.0458, -0.0662, -0.0452,  ..., -0.0499, -0.0150, -0.0675]])),\n",
       "             ('encoder.layers.4.self_attention_block.w_v.weight',\n",
       "              tensor([[-2.0553e-02, -5.2551e-02, -7.3737e-02,  ...,  1.6062e-02,\n",
       "                        5.4113e-02, -7.2001e-02],\n",
       "                      [-9.5770e-05,  4.4470e-02,  6.2500e-03,  ..., -7.4534e-02,\n",
       "                       -1.0347e-02,  5.9091e-03],\n",
       "                      [-1.0946e-02,  3.7658e-02, -2.2756e-02,  ..., -3.6940e-02,\n",
       "                       -6.9575e-03, -3.9330e-02],\n",
       "                      ...,\n",
       "                      [-2.1516e-02,  6.7839e-02, -7.8296e-04,  ..., -6.3657e-02,\n",
       "                       -8.2067e-03, -6.9403e-02],\n",
       "                      [-6.6564e-02, -3.1590e-02, -7.2930e-02,  ...,  5.9392e-02,\n",
       "                        7.4724e-02, -1.0191e-02],\n",
       "                      [-1.9915e-02, -3.4825e-02,  6.6019e-02,  ..., -6.2894e-02,\n",
       "                        6.7312e-02, -6.0894e-02]])),\n",
       "             ('encoder.layers.4.self_attention_block.w_o.weight',\n",
       "              tensor([[ 0.0043,  0.0724,  0.0027,  ...,  0.0197, -0.0641, -0.0745],\n",
       "                      [ 0.0743,  0.0436,  0.0326,  ..., -0.0250, -0.0082,  0.0558],\n",
       "                      [ 0.0704,  0.0071,  0.0587,  ...,  0.0620,  0.0437, -0.0277],\n",
       "                      ...,\n",
       "                      [-0.0228,  0.0485, -0.0538,  ...,  0.0422, -0.0624,  0.0680],\n",
       "                      [ 0.0638,  0.0416,  0.0531,  ...,  0.0410,  0.0513,  0.0453],\n",
       "                      [-0.0606, -0.0379, -0.0548,  ..., -0.0351, -0.0569,  0.0630]])),\n",
       "             ('encoder.layers.4.feed_forward_block.linear_1.weight',\n",
       "              tensor([[-0.0435, -0.0233,  0.0042,  ...,  0.0079, -0.0024,  0.0060],\n",
       "                      [ 0.0312, -0.0327, -0.0055,  ..., -0.0408,  0.0411, -0.0140],\n",
       "                      [ 0.0028, -0.0339,  0.0205,  ..., -0.0044,  0.0161,  0.0022],\n",
       "                      ...,\n",
       "                      [ 0.0311, -0.0170, -0.0038,  ...,  0.0423, -0.0337,  0.0087],\n",
       "                      [-0.0319, -0.0309,  0.0097,  ..., -0.0136,  0.0434, -0.0113],\n",
       "                      [-0.0315,  0.0454, -0.0280,  ..., -0.0253,  0.0158, -0.0115]])),\n",
       "             ('encoder.layers.4.feed_forward_block.linear_1.bias',\n",
       "              tensor([ 0.0001,  0.0353, -0.0335,  ...,  0.0353, -0.0422,  0.0210])),\n",
       "             ('encoder.layers.4.feed_forward_block.linear_2.weight',\n",
       "              tensor([[-0.0108,  0.0173,  0.0130,  ...,  0.0339,  0.0474, -0.0270],\n",
       "                      [-0.0439,  0.0454,  0.0107,  ...,  0.0402, -0.0132, -0.0088],\n",
       "                      [-0.0368, -0.0298, -0.0215,  ..., -0.0001,  0.0163,  0.0212],\n",
       "                      ...,\n",
       "                      [ 0.0258, -0.0072, -0.0269,  ...,  0.0130, -0.0334,  0.0308],\n",
       "                      [ 0.0297, -0.0319, -0.0228,  ...,  0.0045, -0.0246,  0.0436],\n",
       "                      [-0.0347, -0.0112, -0.0130,  ..., -0.0477,  0.0412, -0.0348]])),\n",
       "             ('encoder.layers.4.feed_forward_block.linear_2.bias',\n",
       "              tensor([-1.1229e-02, -1.2267e-02,  3.3679e-03,  1.2624e-02,  1.4408e-02,\n",
       "                      -1.9446e-02, -6.7484e-03,  5.5676e-03,  1.6327e-02, -2.0479e-02,\n",
       "                       1.2997e-03, -1.7626e-02, -1.4429e-02,  1.9126e-03, -1.6714e-02,\n",
       "                      -2.1721e-02, -1.6676e-02, -1.7671e-03, -1.6437e-02, -7.1535e-03,\n",
       "                       2.2231e-03,  1.8229e-02,  7.5149e-03, -1.4035e-03,  1.0401e-02,\n",
       "                       1.3137e-02, -4.9627e-04, -5.9194e-04,  1.1918e-02,  4.6466e-03,\n",
       "                      -5.1390e-03, -8.8722e-03,  7.1405e-03, -1.5012e-02,  7.7834e-03,\n",
       "                       1.1391e-02, -1.9480e-03, -9.1925e-03, -8.0010e-03, -2.1748e-02,\n",
       "                      -1.5594e-02,  1.6527e-02, -2.0909e-02,  2.1065e-02,  2.3511e-03,\n",
       "                       1.2580e-02, -1.0306e-02,  1.4898e-03,  2.0548e-02, -7.3498e-03,\n",
       "                      -2.1860e-02,  1.6737e-02,  1.8693e-02, -8.6478e-03, -1.8910e-02,\n",
       "                       2.0328e-02, -1.3569e-02, -9.5754e-03, -8.2833e-03,  1.4323e-02,\n",
       "                      -1.2212e-02, -1.6057e-02, -4.3800e-03, -5.3287e-03, -2.0300e-02,\n",
       "                       1.7405e-02, -2.1495e-02,  2.1922e-02,  8.9923e-03,  1.7432e-02,\n",
       "                       1.6631e-02, -1.7606e-02,  4.2506e-03, -1.4175e-02,  3.4883e-04,\n",
       "                       1.8582e-02, -8.1556e-03,  1.0599e-03, -6.6882e-03,  2.1764e-02,\n",
       "                      -1.0327e-02, -1.4965e-02,  1.2552e-02, -5.7543e-03, -3.5107e-03,\n",
       "                       5.6424e-03, -1.2804e-02, -1.8574e-02, -2.6772e-05, -1.3303e-02,\n",
       "                      -6.2461e-03,  2.1517e-02, -1.9095e-02, -1.3118e-02, -3.3660e-04,\n",
       "                      -1.5889e-02,  2.0947e-02, -1.2730e-02,  4.6859e-03, -1.3318e-03,\n",
       "                      -6.0523e-03, -1.5281e-02,  2.2919e-03,  1.0327e-02, -2.0444e-02,\n",
       "                       4.8414e-04, -1.5578e-02,  1.5481e-02,  1.2829e-02,  1.4965e-02,\n",
       "                      -4.3261e-03, -4.5194e-03,  1.5288e-02,  3.7547e-03,  1.8328e-02,\n",
       "                       1.8025e-02, -8.1974e-03,  5.3430e-03, -1.9684e-02,  8.6543e-03,\n",
       "                       9.9607e-03, -3.4667e-03,  1.5015e-02, -2.5637e-03,  1.0395e-02,\n",
       "                       1.9061e-02, -4.5912e-03, -8.7570e-04,  1.1548e-02, -1.3317e-02,\n",
       "                       1.2536e-02,  2.6303e-03,  1.8858e-02, -1.0877e-02, -1.1202e-02,\n",
       "                       8.3637e-03, -1.3876e-02, -2.1312e-02,  1.1942e-02,  1.0193e-02,\n",
       "                       1.1728e-02,  4.4893e-03, -4.6254e-03, -5.0009e-03,  1.0581e-02,\n",
       "                       5.8829e-03, -8.2500e-03, -5.4618e-03, -6.3253e-03,  9.9600e-03,\n",
       "                      -1.4549e-02, -5.6471e-03, -2.1444e-02,  1.8490e-02,  1.0449e-02,\n",
       "                       1.3945e-02, -8.7288e-03, -1.6303e-03, -3.9074e-03, -1.7340e-02,\n",
       "                      -1.8310e-02, -1.2970e-03, -1.6224e-02, -1.9353e-02, -1.7604e-02,\n",
       "                       1.8942e-02, -8.1997e-03,  8.2605e-03, -1.9955e-02,  1.5599e-02,\n",
       "                       1.3835e-02, -1.8815e-02,  4.3506e-03, -7.5215e-03,  9.8625e-03,\n",
       "                      -9.7440e-03,  1.0432e-02, -9.5493e-03, -1.2828e-02, -1.6566e-03,\n",
       "                       7.4842e-03,  2.1190e-02, -6.2118e-03,  2.3148e-03,  5.9667e-03,\n",
       "                       2.0144e-02,  1.5182e-02,  1.6549e-03, -4.0914e-03, -4.4088e-03,\n",
       "                      -1.5525e-02,  1.0732e-02,  1.7600e-02, -1.6116e-03,  7.8078e-03,\n",
       "                      -4.1087e-03, -9.5444e-03, -6.8346e-03,  5.9136e-03, -9.9893e-03,\n",
       "                      -2.2061e-02,  1.9866e-02, -1.4682e-02, -9.4167e-03, -1.9607e-02,\n",
       "                      -1.6040e-02, -5.6395e-03,  6.0810e-03,  1.0904e-02,  1.3676e-02,\n",
       "                       5.3977e-03,  2.0071e-02, -1.4506e-02,  2.7446e-03, -1.1263e-02,\n",
       "                      -1.8094e-02,  6.2653e-03, -7.5462e-03, -1.3227e-02, -1.9403e-02,\n",
       "                      -5.2913e-03, -1.8817e-02,  9.1792e-03, -1.9189e-02,  1.5252e-02,\n",
       "                      -9.6777e-03, -2.0025e-02,  2.8933e-03, -1.5955e-02,  4.9054e-03,\n",
       "                       1.4399e-02, -2.0775e-02,  1.5414e-02, -3.8160e-03, -9.5498e-03,\n",
       "                       2.1592e-02,  9.3805e-03, -3.9495e-03, -2.0647e-02,  8.8659e-03,\n",
       "                      -1.9493e-02,  1.7923e-02, -1.8581e-02,  1.3149e-02, -9.0467e-03,\n",
       "                      -1.4099e-02, -1.1565e-03, -2.7988e-03, -1.1458e-02,  9.2080e-03,\n",
       "                      -1.1561e-02,  9.8623e-03, -2.0354e-02, -1.7928e-02, -1.2896e-02,\n",
       "                      -1.3985e-04,  1.7169e-02, -2.1623e-02,  2.0594e-02,  2.1420e-02,\n",
       "                      -1.7072e-02, -1.3951e-02, -8.9186e-03,  1.6238e-02,  1.6276e-02,\n",
       "                      -1.5699e-02, -1.3357e-02,  1.8109e-02, -2.2399e-03,  1.9177e-02,\n",
       "                       2.1963e-02, -1.3313e-02, -6.5412e-03,  3.4909e-03, -1.3515e-02,\n",
       "                      -1.2340e-02,  1.5579e-03,  4.2894e-03, -6.8124e-03, -5.0414e-03,\n",
       "                       1.6108e-02, -2.0280e-02,  3.7426e-03,  6.3882e-03,  5.2653e-03,\n",
       "                      -1.7579e-02, -6.1703e-03,  1.3825e-02, -1.5141e-02,  4.8945e-03,\n",
       "                      -1.4044e-02, -2.0941e-03, -5.2997e-03,  1.4910e-02, -7.0412e-03,\n",
       "                       1.6556e-02,  2.2096e-03, -8.0471e-03, -2.1651e-02,  1.3563e-02,\n",
       "                      -9.0853e-03,  1.5589e-02, -1.0805e-02, -5.9298e-03,  4.6881e-03,\n",
       "                       4.5812e-03,  1.0752e-02, -2.1495e-02,  1.0493e-02,  1.0194e-02,\n",
       "                      -1.5210e-02,  1.7348e-02,  1.0304e-02,  8.8169e-03, -1.6175e-02,\n",
       "                      -1.9444e-02, -3.2988e-03, -2.5061e-03, -4.3974e-03, -1.4309e-02,\n",
       "                      -2.4200e-03, -3.8152e-03,  9.1374e-03,  1.1898e-02,  1.8909e-02,\n",
       "                       1.3013e-02,  5.0625e-03,  5.0272e-03, -7.1450e-03,  1.7829e-02,\n",
       "                       1.1965e-02, -6.7569e-03,  2.0285e-03,  2.0572e-02, -1.6649e-02,\n",
       "                       1.3124e-02,  7.6431e-03,  8.2480e-03,  1.9239e-02,  2.0707e-02,\n",
       "                       1.6023e-02, -1.4464e-02, -1.1594e-02,  1.2483e-02,  5.6589e-03,\n",
       "                       1.8196e-02,  1.2428e-02, -1.3404e-02, -1.2495e-02, -1.3598e-02,\n",
       "                       1.6135e-02, -7.3569e-04, -1.3330e-02, -2.1130e-02,  1.9705e-02,\n",
       "                       1.7365e-02,  2.0198e-02, -1.6575e-02,  2.0795e-03,  3.5197e-03,\n",
       "                      -1.6740e-02,  2.0153e-02, -1.3826e-02, -9.0793e-03,  1.8678e-02,\n",
       "                       1.5750e-02, -2.0311e-02,  2.0252e-02, -1.0143e-02,  1.9433e-02,\n",
       "                       6.4166e-03, -1.1232e-02, -1.5434e-02, -1.7228e-02, -2.1289e-02,\n",
       "                      -2.7051e-03,  2.1215e-02, -1.0910e-02,  1.4500e-02, -5.3764e-03,\n",
       "                      -2.2063e-02,  1.0664e-03, -3.5504e-03,  3.2486e-03,  2.2079e-02,\n",
       "                      -4.7706e-03, -1.5197e-02, -1.7123e-02,  6.5528e-03,  4.5574e-04,\n",
       "                      -2.8677e-03,  6.3856e-04,  2.9599e-03,  1.1455e-02, -2.1415e-02,\n",
       "                       3.8306e-03, -1.8272e-02, -2.4906e-03,  7.1438e-03, -1.2462e-02,\n",
       "                       7.5415e-03, -5.1701e-03, -9.9986e-04, -1.9271e-02,  2.8972e-03,\n",
       "                       7.6849e-03, -1.4797e-02, -1.2670e-02,  7.0482e-03,  1.1451e-02,\n",
       "                      -1.8458e-03, -1.0229e-02,  1.1165e-03,  1.7513e-03,  5.3549e-03,\n",
       "                      -1.6027e-02,  4.7890e-03,  1.2482e-02,  1.1977e-02,  4.2041e-03,\n",
       "                      -2.1702e-02,  1.9953e-02, -7.8953e-03,  1.1896e-02, -1.2475e-02,\n",
       "                       1.6682e-02,  1.3377e-02, -5.4235e-03,  4.1167e-03, -1.0554e-02,\n",
       "                      -3.8455e-03, -2.3369e-03, -1.1154e-02, -7.9484e-03, -1.9646e-02,\n",
       "                      -2.1861e-02, -8.4065e-03, -2.0808e-02,  1.4547e-02, -2.0937e-02,\n",
       "                      -4.2446e-03,  1.4901e-02,  1.4847e-02,  9.9868e-04,  1.2366e-02,\n",
       "                       1.0846e-02,  1.4379e-02,  8.0580e-03, -1.6378e-02,  9.6743e-03,\n",
       "                      -3.8084e-03, -1.2329e-02, -1.2028e-02, -3.4219e-03, -1.5825e-02,\n",
       "                       2.6653e-03, -1.4739e-02, -1.0752e-02, -1.2607e-02,  1.8980e-02,\n",
       "                       2.1618e-02, -1.5814e-02,  1.6428e-02,  1.8501e-03,  1.9653e-02,\n",
       "                       2.1091e-03,  8.8742e-03,  9.9523e-03,  7.3798e-03,  7.5168e-03,\n",
       "                      -1.6322e-02,  1.5346e-02, -1.1943e-02, -1.0933e-02, -8.0804e-03,\n",
       "                       3.2797e-03, -4.2219e-03,  2.0339e-02,  1.1054e-02, -9.5999e-03,\n",
       "                      -6.4097e-03,  2.1727e-03, -2.1173e-02,  1.9438e-02, -1.7137e-02,\n",
       "                      -2.0650e-02,  1.2862e-02, -5.4064e-03,  4.6370e-03, -1.9834e-02,\n",
       "                      -1.3659e-02, -1.0719e-02,  1.1835e-02,  1.9947e-02,  1.6015e-02,\n",
       "                       1.1252e-02,  3.3013e-03,  1.6627e-02,  2.1324e-02,  1.7743e-02,\n",
       "                       1.6364e-02,  1.6115e-02, -7.1652e-03,  1.9361e-02,  2.0987e-02,\n",
       "                      -1.9313e-02, -2.1296e-02, -1.8233e-02,  1.5508e-02,  6.4474e-04,\n",
       "                       1.7257e-02,  1.9653e-02])),\n",
       "             ('encoder.layers.4.residual_connections.0.norm.alpha',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('encoder.layers.4.residual_connections.0.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('encoder.layers.4.residual_connections.1.norm.alpha',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('encoder.layers.4.residual_connections.1.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('encoder.layers.5.self_attention_block.w_q.weight',\n",
       "              tensor([[-0.0457,  0.0217, -0.0724,  ..., -0.0686,  0.0148, -0.0203],\n",
       "                      [ 0.0379,  0.0042, -0.0055,  ...,  0.0635,  0.0655,  0.0395],\n",
       "                      [ 0.0418,  0.0011, -0.0075,  ...,  0.0536,  0.0073, -0.0744],\n",
       "                      ...,\n",
       "                      [-0.0183,  0.0715, -0.0668,  ...,  0.0426,  0.0710, -0.0252],\n",
       "                      [-0.0142, -0.0401, -0.0595,  ...,  0.0233,  0.0298, -0.0546],\n",
       "                      [ 0.0203,  0.0201, -0.0178,  ..., -0.0134,  0.0518,  0.0308]])),\n",
       "             ('encoder.layers.5.self_attention_block.w_k.weight',\n",
       "              tensor([[-0.0217, -0.0442, -0.0680,  ..., -0.0556,  0.0002, -0.0750],\n",
       "                      [-0.0308,  0.0138,  0.0247,  ...,  0.0469,  0.0282,  0.0205],\n",
       "                      [ 0.0135, -0.0336, -0.0306,  ...,  0.0023, -0.0355,  0.0523],\n",
       "                      ...,\n",
       "                      [-0.0622,  0.0641, -0.0719,  ..., -0.0600, -0.0148, -0.0619],\n",
       "                      [ 0.0526, -0.0419,  0.0198,  ...,  0.0338, -0.0200,  0.0359],\n",
       "                      [-0.0038,  0.0203,  0.0025,  ...,  0.0646, -0.0531, -0.0231]])),\n",
       "             ('encoder.layers.5.self_attention_block.w_v.weight',\n",
       "              tensor([[-0.0393, -0.0100, -0.0268,  ..., -0.0233, -0.0141, -0.0136],\n",
       "                      [-0.0661,  0.0526, -0.0696,  ...,  0.0317,  0.0637, -0.0277],\n",
       "                      [-0.0580, -0.0064,  0.0332,  ..., -0.0154,  0.0732, -0.0274],\n",
       "                      ...,\n",
       "                      [-0.0159, -0.0015,  0.0409,  ...,  0.0251, -0.0201, -0.0134],\n",
       "                      [-0.0034, -0.0450,  0.0194,  ..., -0.0747,  0.0237, -0.0326],\n",
       "                      [ 0.0522,  0.0372,  0.0197,  ..., -0.0755,  0.0307,  0.0015]])),\n",
       "             ('encoder.layers.5.self_attention_block.w_o.weight',\n",
       "              tensor([[ 0.0666, -0.0293, -0.0214,  ...,  0.0543, -0.0366, -0.0298],\n",
       "                      [ 0.0119,  0.0213,  0.0182,  ..., -0.0396, -0.0542, -0.0365],\n",
       "                      [-0.0512, -0.0384,  0.0546,  ..., -0.0670,  0.0047, -0.0594],\n",
       "                      ...,\n",
       "                      [ 0.0746,  0.0448,  0.0295,  ...,  0.0649, -0.0292, -0.0525],\n",
       "                      [-0.0576,  0.0732,  0.0591,  ..., -0.0190,  0.0005,  0.0422],\n",
       "                      [-0.0738,  0.0525,  0.0194,  ...,  0.0230, -0.0576,  0.0279]])),\n",
       "             ('encoder.layers.5.feed_forward_block.linear_1.weight',\n",
       "              tensor([[-0.0253,  0.0133,  0.0188,  ..., -0.0231,  0.0077, -0.0463],\n",
       "                      [-0.0386, -0.0199,  0.0244,  ..., -0.0427,  0.0096, -0.0196],\n",
       "                      [ 0.0049, -0.0436,  0.0048,  ...,  0.0032,  0.0463, -0.0458],\n",
       "                      ...,\n",
       "                      [ 0.0335,  0.0124, -0.0428,  ...,  0.0061,  0.0402, -0.0416],\n",
       "                      [-0.0357, -0.0236, -0.0045,  ..., -0.0380, -0.0453,  0.0266],\n",
       "                      [-0.0056, -0.0195,  0.0234,  ...,  0.0380,  0.0407, -0.0376]])),\n",
       "             ('encoder.layers.5.feed_forward_block.linear_1.bias',\n",
       "              tensor([ 0.0385,  0.0233, -0.0104,  ..., -0.0178, -0.0239,  0.0327])),\n",
       "             ('encoder.layers.5.feed_forward_block.linear_2.weight',\n",
       "              tensor([[ 0.0034,  0.0338,  0.0404,  ..., -0.0179,  0.0402,  0.0409],\n",
       "                      [ 0.0352,  0.0213,  0.0137,  ...,  0.0455,  0.0030, -0.0194],\n",
       "                      [ 0.0254,  0.0352, -0.0303,  ..., -0.0049,  0.0410, -0.0446],\n",
       "                      ...,\n",
       "                      [-0.0210, -0.0351,  0.0019,  ..., -0.0018, -0.0053, -0.0406],\n",
       "                      [ 0.0074, -0.0073,  0.0137,  ...,  0.0168,  0.0054,  0.0107],\n",
       "                      [-0.0116,  0.0044,  0.0315,  ..., -0.0202,  0.0105,  0.0429]])),\n",
       "             ('encoder.layers.5.feed_forward_block.linear_2.bias',\n",
       "              tensor([ 1.8406e-02, -3.7960e-03,  2.5341e-03, -1.4924e-05, -5.0330e-03,\n",
       "                       9.1934e-03, -5.7802e-03,  1.3390e-02, -2.0068e-02,  2.0379e-02,\n",
       "                      -1.2189e-02, -1.4698e-02, -7.8930e-03, -1.3620e-02, -2.8918e-03,\n",
       "                      -1.2557e-02,  3.9206e-03,  4.2146e-03, -5.6281e-03,  1.1066e-02,\n",
       "                      -1.9144e-02, -1.7651e-02,  3.0973e-03, -1.7224e-02,  6.2655e-03,\n",
       "                       2.0066e-02, -9.9036e-03,  8.2470e-03, -8.2064e-04,  1.7675e-02,\n",
       "                      -9.4849e-03, -7.1944e-03, -5.1025e-03, -2.7027e-03,  5.6705e-03,\n",
       "                      -2.0172e-02,  1.3747e-03,  3.4041e-03, -9.1068e-03,  8.6000e-03,\n",
       "                       2.1409e-02,  1.6864e-02,  1.7006e-02, -1.1789e-02,  1.6303e-03,\n",
       "                       2.1570e-02, -1.6315e-02,  7.4657e-03, -5.6292e-03, -1.9641e-02,\n",
       "                      -7.1571e-03,  7.9164e-03,  7.7157e-03, -1.9665e-02, -6.3970e-03,\n",
       "                      -7.8920e-04,  1.2557e-02,  7.5710e-03,  2.2049e-03,  1.3516e-02,\n",
       "                      -1.5193e-02, -1.5592e-02, -1.4298e-02,  1.9750e-02, -1.0980e-02,\n",
       "                       9.0397e-04, -1.2424e-02, -6.0332e-03, -2.8918e-03, -1.7401e-02,\n",
       "                       7.4410e-03, -1.4583e-02,  2.7482e-03, -3.6984e-03,  7.9186e-03,\n",
       "                      -1.1285e-02, -3.1577e-03, -3.0599e-03, -2.2508e-03,  2.0775e-02,\n",
       "                      -3.4667e-03, -2.1702e-02,  8.2630e-03, -8.5317e-03, -7.2423e-03,\n",
       "                       1.9072e-02,  6.9762e-03, -1.5874e-02, -8.6786e-05,  2.1735e-02,\n",
       "                       1.7022e-02, -1.0116e-02, -7.8309e-03, -1.2808e-02, -7.0381e-03,\n",
       "                       1.4145e-02,  2.1785e-02,  8.4347e-03, -1.8618e-02, -6.1255e-03,\n",
       "                      -2.0971e-02, -1.7810e-02,  1.2262e-02, -1.9896e-02,  1.8530e-02,\n",
       "                       1.4648e-02,  7.9739e-03,  2.0534e-03, -1.8818e-02, -1.8020e-02,\n",
       "                      -1.5294e-02, -1.3086e-02, -1.2397e-02,  2.0974e-02,  8.3571e-03,\n",
       "                       8.6432e-03, -1.0519e-02,  5.6695e-03, -1.2590e-02,  2.1921e-02,\n",
       "                       5.7451e-03,  1.5714e-02,  2.3625e-03, -1.1295e-02, -7.8000e-03,\n",
       "                       4.0447e-03,  1.5428e-02,  1.4280e-02, -1.8445e-02,  1.3945e-02,\n",
       "                      -1.3637e-02, -1.6668e-02, -1.9023e-03, -3.4956e-03, -1.9664e-02,\n",
       "                       6.4763e-03, -1.9479e-02, -3.8559e-03, -2.0912e-04,  4.7966e-03,\n",
       "                      -1.3399e-04, -9.8213e-04,  7.2183e-04,  1.1730e-02, -1.5710e-02,\n",
       "                       2.0890e-02, -1.8880e-02,  1.3054e-02,  1.9572e-02, -1.2659e-03,\n",
       "                      -8.9630e-03,  1.5528e-02, -2.5017e-03,  1.8478e-02,  2.3941e-03,\n",
       "                      -9.9152e-04,  6.6379e-04,  6.3043e-03, -9.2716e-03,  1.1137e-02,\n",
       "                      -1.6200e-03,  4.0897e-03,  9.2880e-03,  1.4349e-02,  4.1432e-03,\n",
       "                      -1.1498e-02,  1.2249e-02, -1.1541e-02,  8.8324e-03, -1.7477e-02,\n",
       "                       1.3143e-02,  6.2946e-03, -7.6242e-03,  1.1814e-02,  7.1985e-03,\n",
       "                       3.3815e-03, -1.9340e-03, -1.4513e-02,  9.5472e-03, -1.4178e-02,\n",
       "                      -1.9751e-02,  1.2374e-02,  5.6737e-03,  3.6185e-03, -1.2186e-02,\n",
       "                       1.1256e-02, -3.5280e-03, -3.4431e-03, -1.7771e-02,  2.0299e-02,\n",
       "                       6.4656e-03,  1.4184e-02,  1.1406e-02,  1.7443e-02,  1.6821e-02,\n",
       "                      -2.0446e-02, -6.8762e-03, -1.7547e-02,  2.2012e-02,  1.2465e-02,\n",
       "                      -8.7723e-03,  9.1693e-03,  2.5792e-03,  2.0281e-02,  8.2843e-03,\n",
       "                       7.0275e-03, -1.0519e-02,  7.5270e-03,  1.8212e-02, -1.7814e-02,\n",
       "                      -1.7659e-02, -1.6901e-02, -1.1045e-02,  2.0742e-02, -1.9815e-02,\n",
       "                      -2.3742e-04,  1.7287e-02, -1.8559e-02, -5.6463e-03, -1.7075e-02,\n",
       "                       1.7486e-02,  2.1906e-02,  3.7136e-03,  7.6893e-03,  9.1617e-03,\n",
       "                       1.3793e-02, -1.3038e-02,  1.8948e-02,  2.0834e-02,  5.5724e-03,\n",
       "                       5.0722e-03,  1.0476e-02, -1.4304e-02,  1.1808e-02,  1.2530e-02,\n",
       "                      -3.0492e-03,  9.8907e-03, -2.1527e-02,  1.5417e-02, -2.7360e-03,\n",
       "                      -9.3941e-03, -5.9744e-03, -1.2713e-02, -1.4893e-02,  1.0247e-03,\n",
       "                       3.7953e-03, -2.0786e-02, -5.0926e-03, -9.6402e-03,  1.3320e-02,\n",
       "                       7.8818e-03,  1.1167e-02, -1.0630e-02, -6.8827e-03, -1.2480e-02,\n",
       "                      -2.0486e-02,  2.1896e-02,  8.1987e-03, -2.0302e-03,  1.3161e-02,\n",
       "                      -1.0315e-02, -2.1257e-02,  9.4287e-03,  1.1521e-02,  6.6371e-03,\n",
       "                      -4.4188e-03,  1.6087e-02,  1.1670e-02, -1.3863e-02, -8.3456e-03,\n",
       "                      -5.2561e-04,  1.9805e-02, -1.1089e-02,  5.4962e-03,  1.4488e-02,\n",
       "                       2.1654e-02, -1.5525e-02,  8.7105e-03,  1.0354e-02,  1.3912e-02,\n",
       "                      -1.3986e-02, -8.3172e-03, -1.0683e-02,  1.9330e-03, -6.5315e-03,\n",
       "                      -1.5710e-03,  1.1878e-02, -9.1781e-03, -1.1006e-02,  4.6664e-03,\n",
       "                       1.9647e-02, -1.6963e-04,  9.4084e-03,  2.0415e-03, -8.4091e-03,\n",
       "                       1.3238e-02, -1.7254e-02,  1.9573e-02,  1.2776e-02,  2.0791e-02,\n",
       "                       3.3946e-03,  8.4140e-03,  1.3337e-02, -2.0620e-02,  1.2361e-03,\n",
       "                      -1.4131e-02,  8.5257e-03, -1.6183e-02, -1.4722e-02,  1.7860e-02,\n",
       "                      -1.4128e-02,  1.7254e-02, -1.5782e-03, -1.2009e-02, -7.8062e-03,\n",
       "                      -7.8145e-03,  1.0493e-02, -1.7145e-02, -1.4230e-02, -6.1274e-03,\n",
       "                      -1.8393e-02, -4.0933e-03,  2.1922e-02, -1.7367e-02, -3.1587e-03,\n",
       "                      -9.6818e-03, -1.6722e-02, -1.4573e-02, -8.0119e-03,  1.3381e-02,\n",
       "                      -1.5963e-03,  4.3802e-03,  1.0546e-02,  1.2368e-02,  4.4671e-03,\n",
       "                      -5.5341e-03,  1.2601e-02, -7.0326e-03,  1.1335e-02, -1.8350e-02,\n",
       "                       1.9360e-02,  1.8418e-02, -1.8043e-02,  9.4694e-03, -2.4302e-03,\n",
       "                       3.7520e-03,  8.1352e-04, -1.1817e-02, -7.1585e-03,  6.4935e-03,\n",
       "                      -1.7626e-04,  1.3704e-02, -8.1571e-03,  2.1907e-02, -1.5697e-02,\n",
       "                       4.5252e-03,  8.7756e-03, -1.6645e-02, -1.0346e-03,  4.8675e-03,\n",
       "                      -1.5343e-02, -6.4695e-04,  2.0641e-02, -1.8649e-02,  1.9611e-02,\n",
       "                       3.2888e-03, -1.7688e-02,  1.6831e-03,  1.7816e-02, -1.8418e-02,\n",
       "                       7.1969e-04, -7.2946e-04,  7.6488e-03,  5.8948e-03, -1.0894e-02,\n",
       "                      -1.6776e-02,  7.1190e-03,  1.4824e-02, -4.0760e-03, -1.0840e-02,\n",
       "                       4.6965e-03,  1.3516e-02,  3.4761e-03,  1.5081e-02, -1.5689e-02,\n",
       "                       5.2269e-03, -1.1199e-02,  1.7328e-02, -1.0024e-02,  1.3811e-03,\n",
       "                       1.5761e-02, -2.0054e-02,  8.5277e-03,  3.9294e-03, -5.5855e-03,\n",
       "                      -1.9413e-02, -1.0161e-02, -1.4299e-02, -1.3821e-02, -4.5655e-03,\n",
       "                      -4.2232e-03, -6.8133e-03, -5.9410e-03,  1.8675e-02,  8.2224e-03,\n",
       "                      -1.2760e-02,  4.6713e-03, -8.5397e-03,  3.1666e-03, -1.3618e-02,\n",
       "                       1.6287e-02, -5.3128e-03, -1.3275e-02, -1.8358e-02, -1.1095e-02,\n",
       "                      -9.4219e-03,  9.1497e-03,  1.1539e-02,  5.1908e-03, -5.6735e-04,\n",
       "                       9.0747e-03, -1.0962e-02,  1.5760e-02, -1.2695e-02,  6.0499e-03,\n",
       "                       2.0967e-02,  1.3078e-02, -4.1339e-03, -6.2870e-03,  5.0582e-03,\n",
       "                       1.0079e-02,  1.5493e-02,  2.5087e-03, -1.7001e-03,  2.1608e-02,\n",
       "                      -1.3057e-02, -2.8793e-03, -1.8848e-02,  1.3996e-02,  1.4578e-02,\n",
       "                      -2.7589e-03,  7.0259e-04,  8.2900e-03,  1.0841e-02, -1.4088e-02,\n",
       "                       1.8237e-02, -6.8922e-03,  2.9990e-03,  2.1434e-02,  1.6441e-02,\n",
       "                       2.4092e-03, -2.0492e-02,  1.4623e-02,  1.8568e-02,  1.6186e-02,\n",
       "                      -2.7086e-03,  1.7558e-02, -1.6531e-02, -1.9351e-02, -1.6146e-02,\n",
       "                       9.7238e-05, -1.0172e-02, -2.0418e-02, -8.3699e-03, -1.2546e-02,\n",
       "                      -5.9287e-03,  5.3972e-03, -2.1918e-02, -4.0322e-03,  1.7376e-03,\n",
       "                      -1.4336e-02, -1.9791e-02,  8.6165e-03,  2.0452e-02, -1.2379e-02,\n",
       "                       7.5484e-03,  1.0572e-02,  7.9415e-03, -1.3559e-02, -1.0041e-03,\n",
       "                      -9.4215e-03, -6.6061e-03, -2.2082e-02, -2.0549e-03, -7.8438e-03,\n",
       "                       1.2213e-02,  1.2889e-02, -6.7211e-03,  1.3223e-02,  1.0171e-02,\n",
       "                       1.5365e-03, -1.9107e-02,  1.6705e-03,  2.1352e-02, -3.9686e-04,\n",
       "                       5.0538e-04, -2.0503e-04,  1.1202e-02, -1.5344e-02,  2.8011e-03,\n",
       "                       8.7831e-03, -6.8268e-03, -1.3879e-02, -2.1741e-02, -2.4770e-03,\n",
       "                       1.7264e-02, -2.0105e-02,  1.3023e-03, -7.8998e-03,  2.1818e-02,\n",
       "                       1.7448e-02, -1.4762e-02])),\n",
       "             ('encoder.layers.5.residual_connections.0.norm.alpha',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('encoder.layers.5.residual_connections.0.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('encoder.layers.5.residual_connections.1.norm.alpha',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('encoder.layers.5.residual_connections.1.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('encoder.norm.alpha',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('encoder.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('decoder.layers.0.self_attention_block.w_q.weight',\n",
       "              tensor([[ 0.0140, -0.0301, -0.0405,  ..., -0.0727, -0.0728,  0.0182],\n",
       "                      [-0.0394, -0.0320, -0.0161,  ...,  0.0587, -0.0075, -0.0025],\n",
       "                      [ 0.0138,  0.0081,  0.0096,  ..., -0.0217, -0.0348,  0.0461],\n",
       "                      ...,\n",
       "                      [ 0.0237, -0.0267, -0.0007,  ..., -0.0027, -0.0202,  0.0335],\n",
       "                      [ 0.0405,  0.0319, -0.0256,  ..., -0.0585,  0.0482, -0.0237],\n",
       "                      [-0.0735, -0.0132, -0.0207,  ..., -0.0742, -0.0270, -0.0407]])),\n",
       "             ('decoder.layers.0.self_attention_block.w_k.weight',\n",
       "              tensor([[-5.6741e-02,  3.6454e-02, -6.0909e-02,  ..., -3.7678e-02,\n",
       "                        7.5410e-02,  3.7899e-02],\n",
       "                      [-7.0648e-02,  2.2481e-02,  8.1203e-03,  ...,  7.0675e-02,\n",
       "                        2.5980e-05, -4.6238e-02],\n",
       "                      [-1.8201e-02,  6.1738e-02,  5.9837e-02,  ...,  1.3690e-02,\n",
       "                        6.7733e-02, -1.4029e-02],\n",
       "                      ...,\n",
       "                      [-5.5679e-02,  1.4162e-02,  3.8898e-02,  ..., -3.3673e-02,\n",
       "                        3.1296e-02,  5.6315e-04],\n",
       "                      [-5.6913e-02,  5.1498e-02,  6.5701e-03,  ...,  7.3181e-02,\n",
       "                        6.8836e-02, -6.2081e-02],\n",
       "                      [-1.6164e-02,  2.9476e-02, -7.2386e-02,  ...,  6.0626e-02,\n",
       "                       -6.9243e-02, -3.2521e-02]])),\n",
       "             ('decoder.layers.0.self_attention_block.w_v.weight',\n",
       "              tensor([[-0.0089, -0.0402, -0.0680,  ..., -0.0700, -0.0301, -0.0483],\n",
       "                      [ 0.0466,  0.0345, -0.0730,  ...,  0.0759,  0.0185,  0.0201],\n",
       "                      [-0.0048, -0.0121,  0.0046,  ...,  0.0526,  0.0187, -0.0362],\n",
       "                      ...,\n",
       "                      [ 0.0191, -0.0421, -0.0173,  ..., -0.0246, -0.0382, -0.0522],\n",
       "                      [ 0.0240,  0.0362, -0.0074,  ..., -0.0425,  0.0158,  0.0178],\n",
       "                      [ 0.0306,  0.0562, -0.0483,  ...,  0.0732, -0.0325,  0.0652]])),\n",
       "             ('decoder.layers.0.self_attention_block.w_o.weight',\n",
       "              tensor([[-0.0666,  0.0438,  0.0033,  ..., -0.0135, -0.0720,  0.0228],\n",
       "                      [ 0.0318,  0.0609,  0.0440,  ..., -0.0672, -0.0075, -0.0504],\n",
       "                      [ 0.0748, -0.0220,  0.0411,  ...,  0.0139,  0.0317,  0.0146],\n",
       "                      ...,\n",
       "                      [-0.0616, -0.0004, -0.0586,  ...,  0.0127, -0.0066,  0.0362],\n",
       "                      [ 0.0398, -0.0096,  0.0386,  ...,  0.0304, -0.0626,  0.0493],\n",
       "                      [ 0.0516, -0.0138,  0.0599,  ...,  0.0052,  0.0029,  0.0594]])),\n",
       "             ('decoder.layers.0.cross_attention_block.w_q.weight',\n",
       "              tensor([[ 5.5538e-02, -4.4092e-02,  4.3079e-02,  ...,  6.6501e-02,\n",
       "                       -4.1173e-02,  4.9968e-02],\n",
       "                      [-2.1719e-02,  2.8658e-02,  2.4092e-02,  ...,  1.7062e-03,\n",
       "                       -2.5147e-02,  5.2993e-02],\n",
       "                      [ 1.8102e-02,  4.7124e-02,  7.2808e-02,  ...,  3.1946e-02,\n",
       "                       -5.2711e-02, -3.2994e-02],\n",
       "                      ...,\n",
       "                      [ 2.7189e-02, -3.4216e-04, -2.8650e-02,  ..., -5.4762e-02,\n",
       "                       -6.1063e-02,  5.4981e-02],\n",
       "                      [-8.7373e-05,  4.5407e-02,  2.4746e-02,  ..., -2.7631e-02,\n",
       "                       -4.8033e-02, -5.9557e-02],\n",
       "                      [-6.4462e-02,  5.2496e-02,  7.1151e-02,  ..., -6.6271e-02,\n",
       "                       -4.5650e-02,  2.6422e-02]])),\n",
       "             ('decoder.layers.0.cross_attention_block.w_k.weight',\n",
       "              tensor([[ 0.0661,  0.0663,  0.0185,  ..., -0.0055,  0.0380, -0.0005],\n",
       "                      [ 0.0217,  0.0194,  0.0615,  ...,  0.0253,  0.0292,  0.0369],\n",
       "                      [ 0.0159, -0.0337, -0.0577,  ..., -0.0590,  0.0572,  0.0295],\n",
       "                      ...,\n",
       "                      [ 0.0581, -0.0219,  0.0184,  ...,  0.0056,  0.0741,  0.0145],\n",
       "                      [ 0.0241,  0.0745, -0.0102,  ..., -0.0200, -0.0369, -0.0042],\n",
       "                      [-0.0298, -0.0355, -0.0106,  ...,  0.0158,  0.0061,  0.0670]])),\n",
       "             ('decoder.layers.0.cross_attention_block.w_v.weight',\n",
       "              tensor([[-0.0073,  0.0381,  0.0324,  ..., -0.0060, -0.0592, -0.0183],\n",
       "                      [-0.0585,  0.0028, -0.0296,  ..., -0.0109,  0.0005, -0.0261],\n",
       "                      [-0.0692,  0.0296,  0.0410,  ...,  0.0620, -0.0385, -0.0231],\n",
       "                      ...,\n",
       "                      [-0.0152, -0.0625,  0.0139,  ..., -0.0510,  0.0438, -0.0514],\n",
       "                      [ 0.0050,  0.0123,  0.0347,  ..., -0.0490, -0.0072,  0.0110],\n",
       "                      [ 0.0157,  0.0490, -0.0281,  ..., -0.0431,  0.0387,  0.0648]])),\n",
       "             ('decoder.layers.0.cross_attention_block.w_o.weight',\n",
       "              tensor([[ 0.0298,  0.0111,  0.0583,  ..., -0.0324, -0.0436, -0.0146],\n",
       "                      [-0.0558, -0.0625,  0.0332,  ...,  0.0415, -0.0628,  0.0119],\n",
       "                      [-0.0069,  0.0294,  0.0504,  ..., -0.0093,  0.0244,  0.0670],\n",
       "                      ...,\n",
       "                      [-0.0316, -0.0731,  0.0623,  ..., -0.0108,  0.0023,  0.0717],\n",
       "                      [-0.0407,  0.0014, -0.0490,  ..., -0.0022,  0.0339,  0.0361],\n",
       "                      [-0.0315, -0.0019, -0.0490,  ..., -0.0482,  0.0512,  0.0742]])),\n",
       "             ('decoder.layers.0.feed_forward_block.linear_1.weight',\n",
       "              tensor([[-0.0159, -0.0216,  0.0394,  ..., -0.0371,  0.0424,  0.0166],\n",
       "                      [ 0.0325,  0.0055, -0.0278,  ...,  0.0007,  0.0350,  0.0050],\n",
       "                      [ 0.0156, -0.0090, -0.0170,  ...,  0.0419, -0.0127, -0.0031],\n",
       "                      ...,\n",
       "                      [ 0.0343, -0.0172,  0.0462,  ..., -0.0289,  0.0425,  0.0316],\n",
       "                      [ 0.0096, -0.0124,  0.0030,  ...,  0.0479, -0.0126, -0.0162],\n",
       "                      [-0.0480,  0.0345, -0.0111,  ...,  0.0163, -0.0019, -0.0042]])),\n",
       "             ('decoder.layers.0.feed_forward_block.linear_1.bias',\n",
       "              tensor([ 0.0145,  0.0014, -0.0369,  ...,  0.0308,  0.0357, -0.0347])),\n",
       "             ('decoder.layers.0.feed_forward_block.linear_2.weight',\n",
       "              tensor([[-0.0472,  0.0195, -0.0287,  ...,  0.0027, -0.0113, -0.0085],\n",
       "                      [ 0.0023,  0.0068, -0.0053,  ..., -0.0292,  0.0431,  0.0067],\n",
       "                      [-0.0323, -0.0421, -0.0074,  ...,  0.0198,  0.0270, -0.0359],\n",
       "                      ...,\n",
       "                      [ 0.0443,  0.0153,  0.0335,  ...,  0.0478, -0.0303,  0.0263],\n",
       "                      [-0.0088,  0.0391, -0.0348,  ...,  0.0079, -0.0020,  0.0374],\n",
       "                      [-0.0100,  0.0360,  0.0477,  ...,  0.0347, -0.0107, -0.0429]])),\n",
       "             ('decoder.layers.0.feed_forward_block.linear_2.bias',\n",
       "              tensor([ 7.6882e-03, -5.3982e-03, -1.9164e-02,  1.8521e-02, -6.0543e-03,\n",
       "                       1.7925e-02,  7.0279e-03, -1.1029e-02,  8.0793e-04, -2.2792e-03,\n",
       "                      -7.1271e-03,  1.9105e-05, -1.3927e-02, -1.2635e-02, -1.5816e-02,\n",
       "                       1.0259e-02, -1.6339e-04,  1.4164e-02, -1.5408e-02,  1.4348e-02,\n",
       "                      -9.8622e-03, -1.4879e-02, -1.0929e-03,  9.3500e-03,  1.7358e-02,\n",
       "                      -9.9368e-03, -1.8219e-03,  2.6891e-03,  1.4742e-02,  1.1278e-02,\n",
       "                      -1.4288e-02,  1.2611e-02, -2.0048e-02,  2.0480e-02, -6.5338e-03,\n",
       "                       1.2926e-02, -5.1064e-03,  3.5539e-03,  1.7749e-02, -2.0639e-02,\n",
       "                       1.1690e-02,  1.5697e-02,  1.1922e-02,  1.7368e-02,  9.1870e-03,\n",
       "                       1.8540e-02, -1.9196e-02,  7.7374e-03, -2.1110e-02,  2.5506e-03,\n",
       "                       5.3053e-03,  1.5863e-02, -2.2531e-04,  1.4476e-02, -1.5251e-04,\n",
       "                      -1.4744e-02, -8.7144e-03,  2.8672e-03,  6.7579e-03, -2.0455e-03,\n",
       "                      -3.7430e-03,  2.0459e-02, -7.5122e-03, -1.4474e-02, -2.6136e-04,\n",
       "                      -8.6240e-03,  1.5566e-02, -1.9375e-03, -1.7534e-03, -1.7225e-02,\n",
       "                      -2.6892e-03,  2.0732e-02, -6.6186e-03,  4.8392e-03,  1.3269e-02,\n",
       "                      -1.9996e-02, -9.9906e-03, -1.0772e-02,  1.2539e-02, -2.0991e-02,\n",
       "                      -2.0416e-02, -8.2313e-03, -2.5527e-03, -1.6965e-03,  1.1748e-02,\n",
       "                       1.3317e-02, -2.1253e-02, -2.1667e-03,  1.9756e-03,  5.6382e-03,\n",
       "                      -1.4705e-02,  7.3589e-04,  1.6102e-02, -4.8069e-04, -1.3327e-02,\n",
       "                      -3.1854e-03, -4.5458e-03,  1.3626e-02,  1.3299e-02,  1.9513e-02,\n",
       "                      -2.2388e-03,  8.7001e-03,  1.6643e-02,  1.0800e-02, -1.6488e-03,\n",
       "                      -5.3510e-04,  1.3239e-03, -1.9893e-02,  1.3962e-02, -3.1793e-03,\n",
       "                      -1.9511e-02,  6.6413e-03,  2.0072e-03, -6.8064e-03,  5.7956e-03,\n",
       "                      -1.6418e-02,  1.1057e-02,  7.3859e-03, -2.0097e-02, -9.5917e-03,\n",
       "                      -1.2558e-02,  1.7036e-02,  1.9285e-03, -1.9834e-02, -6.7056e-03,\n",
       "                       1.1940e-02, -9.6265e-03, -8.2346e-03, -1.9142e-02,  9.4417e-03,\n",
       "                      -1.9936e-02, -1.1967e-02, -1.3207e-02, -1.6942e-02, -1.6045e-04,\n",
       "                      -9.4903e-03,  4.1288e-03, -1.0051e-02, -1.3835e-02, -1.5998e-02,\n",
       "                      -6.3309e-03,  3.8015e-03, -2.1826e-02, -1.0326e-02,  2.1678e-02,\n",
       "                      -3.2156e-03, -4.4821e-03,  1.7362e-02, -1.7219e-02, -7.4314e-03,\n",
       "                      -1.5392e-02, -5.0259e-03, -1.7862e-02, -1.8135e-02,  3.0610e-04,\n",
       "                       2.9662e-03,  4.2062e-04, -6.6210e-03,  1.6503e-02, -1.4400e-02,\n",
       "                      -1.4625e-02, -1.2578e-02,  2.8537e-04,  1.5210e-02, -2.0541e-02,\n",
       "                      -9.2472e-04,  2.1123e-02, -2.1819e-02,  2.0273e-02, -2.0250e-02,\n",
       "                      -2.1193e-02,  7.9885e-03, -3.4326e-03,  5.3450e-05,  8.9760e-03,\n",
       "                      -8.4732e-03, -7.1067e-03, -7.8629e-03, -1.5900e-03,  7.1154e-03,\n",
       "                       7.9815e-03, -4.2543e-03,  2.5742e-03, -1.5819e-02, -4.7476e-03,\n",
       "                       2.1487e-02,  1.4609e-02, -4.2903e-03, -2.1289e-02, -1.4119e-02,\n",
       "                       8.7189e-03, -6.1235e-03, -8.2390e-03,  2.8425e-03, -6.5692e-04,\n",
       "                       9.6008e-03, -1.4599e-03, -1.3039e-02, -1.1694e-02, -4.8409e-03,\n",
       "                       8.2688e-03,  5.3251e-03, -1.5856e-02,  4.4017e-03,  1.6588e-02,\n",
       "                      -5.1239e-03, -1.3508e-02, -1.1841e-02, -2.1141e-02,  1.7695e-02,\n",
       "                       1.1546e-02, -2.1999e-02, -2.1149e-02,  2.9204e-03, -1.4941e-02,\n",
       "                       2.7173e-03, -1.3390e-02,  5.0759e-03, -8.5304e-03,  8.6017e-03,\n",
       "                      -3.3875e-03, -1.4630e-02, -1.1786e-02,  1.1264e-02,  1.8457e-02,\n",
       "                      -4.3075e-04,  2.1049e-03, -2.0339e-02, -1.7703e-02, -2.1070e-02,\n",
       "                      -1.9082e-02, -3.2864e-03, -1.8479e-02,  1.3182e-02, -1.8664e-02,\n",
       "                      -2.0229e-02, -1.3196e-02, -2.1286e-02, -2.1571e-02,  4.3990e-03,\n",
       "                      -1.1945e-02, -1.6622e-02,  1.1055e-02, -1.6846e-02,  8.8885e-03,\n",
       "                      -1.8001e-02,  1.5955e-02,  1.6575e-02,  1.1031e-02,  1.8359e-02,\n",
       "                      -2.1566e-02,  2.0673e-03, -6.4601e-03, -2.0131e-02,  5.5655e-03,\n",
       "                       8.6089e-03, -1.9288e-02,  1.9330e-02, -2.1956e-02, -7.4232e-05,\n",
       "                      -1.9536e-03,  9.7642e-03,  1.8252e-02, -8.3095e-04, -1.5376e-02,\n",
       "                       7.5421e-03,  9.1628e-03, -1.2359e-02, -1.6700e-05, -8.8790e-03,\n",
       "                       1.2676e-02, -3.7318e-03,  6.9471e-03, -1.9167e-02, -1.8173e-02,\n",
       "                       4.1402e-03, -2.1784e-02, -1.5522e-02, -9.5598e-03,  1.9574e-02,\n",
       "                      -1.4277e-02,  4.0301e-03,  1.1920e-02, -1.6836e-02, -2.0629e-02,\n",
       "                       8.7579e-03,  1.5147e-03, -6.6466e-03, -8.6932e-03,  4.6788e-03,\n",
       "                      -1.7763e-02, -1.9421e-02,  3.1712e-03,  1.5942e-03,  1.9955e-02,\n",
       "                      -3.4305e-04,  1.0230e-02,  6.3398e-03,  2.9262e-03, -1.4194e-02,\n",
       "                      -2.0429e-02,  4.3108e-03,  1.0525e-04, -5.5435e-03, -5.9705e-03,\n",
       "                      -1.7490e-02,  1.0868e-02,  6.6384e-03, -1.2828e-02,  2.7883e-03,\n",
       "                      -9.8919e-03,  2.1500e-02, -5.3826e-03, -8.6146e-03,  9.6599e-03,\n",
       "                       7.7075e-03,  1.4294e-02, -2.0040e-02, -4.5189e-03, -1.1361e-02,\n",
       "                      -3.8804e-03, -7.5328e-03,  1.2613e-02, -4.7580e-03, -1.7783e-02,\n",
       "                      -8.5949e-03,  1.4166e-03, -1.0520e-02,  9.6402e-03, -4.5532e-03,\n",
       "                       3.6461e-03,  2.0656e-02,  5.1338e-03, -9.7378e-03,  7.8817e-03,\n",
       "                      -7.9802e-03, -9.7192e-03, -1.3322e-02,  1.3595e-02,  1.2951e-02,\n",
       "                      -1.9080e-02,  1.5327e-02, -4.1017e-04,  9.5440e-03,  7.7807e-03,\n",
       "                       1.8954e-02,  5.4229e-03,  1.8043e-02, -2.1063e-02,  1.6024e-02,\n",
       "                       9.7956e-03, -9.3598e-03, -1.2415e-02, -1.7626e-02, -1.4232e-02,\n",
       "                      -2.0814e-02, -7.1740e-03, -1.4613e-02,  8.8721e-03, -1.8420e-02,\n",
       "                       1.4333e-02,  2.1844e-02,  1.0403e-02,  1.2817e-02,  1.7201e-02,\n",
       "                      -1.7462e-03,  1.5761e-02, -1.7752e-02,  7.0446e-03, -7.3467e-03,\n",
       "                      -7.6626e-03,  5.7533e-03, -1.4605e-02,  2.0172e-02, -3.6968e-03,\n",
       "                      -1.1427e-02,  2.5948e-03, -2.4899e-03,  1.5739e-02, -1.9683e-02,\n",
       "                      -2.0520e-03,  1.2834e-02,  1.1298e-02, -1.7654e-02, -1.3421e-02,\n",
       "                       1.2368e-02, -1.2993e-02, -3.2152e-03,  1.5312e-03, -1.9902e-02,\n",
       "                       1.5038e-02,  1.3589e-02, -1.9454e-02, -2.0858e-02, -9.7636e-03,\n",
       "                      -1.7277e-03, -4.3307e-03, -1.5562e-02,  1.2990e-02,  2.0948e-02,\n",
       "                       1.9951e-02, -1.4554e-02,  4.3806e-05, -1.6681e-02, -3.3430e-03,\n",
       "                      -8.7169e-03,  5.0565e-03,  1.5570e-02, -5.2862e-03,  5.9680e-03,\n",
       "                       9.3862e-04,  6.8109e-03, -1.4860e-02, -2.0351e-02, -1.3985e-02,\n",
       "                      -1.9968e-02,  5.4892e-03, -1.8007e-02,  2.0784e-03,  9.7017e-03,\n",
       "                      -5.0239e-03, -1.0605e-02, -7.8088e-03,  1.6502e-02, -1.7005e-02,\n",
       "                      -6.9377e-03, -2.0759e-03,  1.8016e-02,  1.0822e-02, -7.5387e-03,\n",
       "                       1.0140e-02, -3.1752e-03,  6.7824e-03,  1.8331e-02, -3.8335e-03,\n",
       "                       1.8088e-02, -3.5127e-03, -1.1699e-02,  1.3723e-02,  1.3595e-02,\n",
       "                      -1.7865e-02,  1.4994e-02,  3.2443e-03, -1.1945e-02,  2.0387e-02,\n",
       "                       8.3943e-03,  1.7659e-03,  1.8211e-02,  1.7207e-02, -1.4331e-02,\n",
       "                       1.6180e-02, -1.9458e-02,  3.4641e-03, -3.0147e-03, -4.0773e-04,\n",
       "                       4.6443e-03,  2.0505e-04, -1.9787e-02, -1.0329e-02,  1.9541e-02,\n",
       "                       8.6415e-04, -1.8571e-02,  5.1025e-03, -1.7749e-02,  1.1944e-02,\n",
       "                       1.2501e-02,  9.5873e-04, -1.0660e-03,  2.4704e-03, -1.9627e-02,\n",
       "                      -1.6164e-02, -1.5651e-02, -3.5980e-03, -1.9183e-02, -9.2703e-03,\n",
       "                       1.4851e-03, -7.7165e-03,  1.4911e-02,  7.2016e-03,  1.7810e-02,\n",
       "                       6.1575e-04,  1.7941e-02,  1.1258e-02, -1.2953e-02, -2.0861e-02,\n",
       "                      -1.8004e-02,  2.7570e-03,  8.1359e-03,  1.8840e-02,  1.5325e-02,\n",
       "                       1.1844e-02, -6.9351e-03, -1.3761e-02,  1.4388e-02, -2.0589e-02,\n",
       "                       8.5840e-03,  8.1501e-03, -1.2684e-03, -1.1441e-02,  9.3771e-03,\n",
       "                      -5.5736e-03,  1.8695e-02, -2.1005e-02, -2.0852e-02,  1.9976e-03,\n",
       "                      -1.8970e-02,  4.7200e-04,  1.3027e-02,  1.8129e-02, -1.5290e-02,\n",
       "                      -1.4274e-03,  6.1342e-03])),\n",
       "             ('decoder.layers.0.residual_connections.0.norm.alpha',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('decoder.layers.0.residual_connections.0.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('decoder.layers.0.residual_connections.1.norm.alpha',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('decoder.layers.0.residual_connections.1.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('decoder.layers.0.residual_connections.2.norm.alpha',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('decoder.layers.0.residual_connections.2.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('decoder.layers.1.self_attention_block.w_q.weight',\n",
       "              tensor([[ 6.6698e-02, -8.7342e-03,  1.2392e-03,  ...,  1.9641e-02,\n",
       "                        3.3876e-02, -4.4731e-02],\n",
       "                      [ 4.4302e-02,  6.0066e-02,  1.2112e-02,  ..., -6.8401e-03,\n",
       "                        7.5972e-02,  3.4554e-02],\n",
       "                      [ 2.6096e-02,  4.8104e-02,  7.0682e-02,  ..., -4.0187e-02,\n",
       "                        7.5327e-02,  7.5508e-02],\n",
       "                      ...,\n",
       "                      [-6.6154e-02,  2.5710e-02, -1.0999e-02,  ...,  1.7880e-02,\n",
       "                       -7.3227e-02,  5.5889e-03],\n",
       "                      [-2.3037e-02,  6.6033e-02, -2.3869e-02,  ..., -2.7648e-02,\n",
       "                       -3.6428e-02, -4.6512e-02],\n",
       "                      [-7.0853e-02, -3.8599e-02, -2.8950e-02,  ...,  4.1034e-02,\n",
       "                       -9.3915e-05, -5.1905e-02]])),\n",
       "             ('decoder.layers.1.self_attention_block.w_k.weight',\n",
       "              tensor([[-0.0497,  0.0250, -0.0097,  ...,  0.0618,  0.0138,  0.0451],\n",
       "                      [-0.0253, -0.0524,  0.0561,  ..., -0.0097, -0.0370, -0.0635],\n",
       "                      [ 0.0370,  0.0595, -0.0413,  ..., -0.0416,  0.0143, -0.0270],\n",
       "                      ...,\n",
       "                      [-0.0676,  0.0541, -0.0482,  ...,  0.0397,  0.0150,  0.0517],\n",
       "                      [-0.0599, -0.0617,  0.0717,  ..., -0.0267, -0.0318,  0.0204],\n",
       "                      [ 0.0735,  0.0443, -0.0338,  ..., -0.0476, -0.0312,  0.0175]])),\n",
       "             ('decoder.layers.1.self_attention_block.w_v.weight',\n",
       "              tensor([[-0.0522,  0.0250,  0.0327,  ..., -0.0655,  0.0515,  0.0328],\n",
       "                      [-0.0398, -0.0764, -0.0066,  ...,  0.0015, -0.0225, -0.0051],\n",
       "                      [ 0.0311, -0.0494, -0.0525,  ...,  0.0760,  0.0178,  0.0361],\n",
       "                      ...,\n",
       "                      [-0.0288, -0.0512, -0.0133,  ..., -0.0114, -0.0219, -0.0185],\n",
       "                      [ 0.0141, -0.0543,  0.0234,  ...,  0.0252,  0.0042, -0.0478],\n",
       "                      [ 0.0509,  0.0714,  0.0742,  ..., -0.0544,  0.0446, -0.0519]])),\n",
       "             ('decoder.layers.1.self_attention_block.w_o.weight',\n",
       "              tensor([[-0.0765, -0.0173,  0.0517,  ..., -0.0515, -0.0092, -0.0080],\n",
       "                      [-0.0347,  0.0071,  0.0327,  ..., -0.0191,  0.0361,  0.0312],\n",
       "                      [ 0.0587,  0.0500,  0.0281,  ..., -0.0108, -0.0047,  0.0520],\n",
       "                      ...,\n",
       "                      [-0.0116,  0.0601,  0.0478,  ...,  0.0644,  0.0141, -0.0342],\n",
       "                      [-0.0091, -0.0405,  0.0085,  ...,  0.0483, -0.0467,  0.0178],\n",
       "                      [ 0.0142,  0.0561, -0.0713,  ..., -0.0682,  0.0137,  0.0218]])),\n",
       "             ('decoder.layers.1.cross_attention_block.w_q.weight',\n",
       "              tensor([[-0.0027, -0.0062,  0.0145,  ...,  0.0336,  0.0112, -0.0591],\n",
       "                      [ 0.0636,  0.0182,  0.0669,  ..., -0.0454,  0.0196, -0.0536],\n",
       "                      [-0.0710,  0.0682,  0.0596,  ..., -0.0179, -0.0484, -0.0376],\n",
       "                      ...,\n",
       "                      [-0.0445, -0.0581,  0.0136,  ..., -0.0564,  0.0660, -0.0090],\n",
       "                      [ 0.0436,  0.0647, -0.0708,  ...,  0.0438,  0.0274, -0.0013],\n",
       "                      [-0.0321,  0.0008, -0.0241,  ...,  0.0222, -0.0566, -0.0688]])),\n",
       "             ('decoder.layers.1.cross_attention_block.w_k.weight',\n",
       "              tensor([[ 1.7179e-02,  2.3557e-02, -4.7403e-02,  ...,  6.3409e-02,\n",
       "                        1.7608e-02, -3.9983e-02],\n",
       "                      [-1.7286e-02,  5.7510e-02, -6.7332e-02,  ..., -6.3927e-02,\n",
       "                        2.3164e-02,  2.6231e-02],\n",
       "                      [ 1.1158e-02,  3.7539e-02,  3.3789e-02,  ...,  3.2933e-03,\n",
       "                        8.2329e-06, -5.4523e-02],\n",
       "                      ...,\n",
       "                      [-6.4263e-03,  4.4929e-02,  5.5844e-02,  ...,  8.9169e-03,\n",
       "                       -2.6064e-02, -7.0891e-03],\n",
       "                      [ 5.8045e-02,  2.4133e-02, -6.0354e-02,  ...,  3.3602e-02,\n",
       "                        6.5043e-02, -6.2586e-02],\n",
       "                      [-1.2550e-03,  1.7535e-02, -7.4155e-02,  ...,  5.2712e-02,\n",
       "                        5.0996e-02, -5.3052e-02]])),\n",
       "             ('decoder.layers.1.cross_attention_block.w_v.weight',\n",
       "              tensor([[-0.0705, -0.0578, -0.0252,  ..., -0.0119, -0.0455, -0.0636],\n",
       "                      [-0.0080,  0.0085, -0.0483,  ...,  0.0703,  0.0400,  0.0222],\n",
       "                      [ 0.0417,  0.0019,  0.0322,  ..., -0.0018, -0.0749, -0.0255],\n",
       "                      ...,\n",
       "                      [ 0.0239, -0.0122,  0.0609,  ..., -0.0256,  0.0600,  0.0246],\n",
       "                      [-0.0589,  0.0675, -0.0466,  ...,  0.0116, -0.0673,  0.0415],\n",
       "                      [-0.0200,  0.0061, -0.0493,  ..., -0.0636,  0.0175, -0.0581]])),\n",
       "             ('decoder.layers.1.cross_attention_block.w_o.weight',\n",
       "              tensor([[ 0.0300,  0.0093, -0.0245,  ...,  0.0123,  0.0551, -0.0215],\n",
       "                      [-0.0373, -0.0207,  0.0065,  ..., -0.0439, -0.0366, -0.0634],\n",
       "                      [-0.0525,  0.0028, -0.0545,  ...,  0.0497,  0.0278,  0.0147],\n",
       "                      ...,\n",
       "                      [-0.0147,  0.0557, -0.0574,  ...,  0.0247,  0.0078,  0.0299],\n",
       "                      [ 0.0736, -0.0027,  0.0380,  ..., -0.0339, -0.0462, -0.0381],\n",
       "                      [ 0.0483,  0.0066, -0.0139,  ...,  0.0227,  0.0278, -0.0015]])),\n",
       "             ('decoder.layers.1.feed_forward_block.linear_1.weight',\n",
       "              tensor([[ 0.0255,  0.0213, -0.0162,  ...,  0.0181,  0.0028, -0.0022],\n",
       "                      [ 0.0226,  0.0226, -0.0254,  ...,  0.0446, -0.0401, -0.0376],\n",
       "                      [-0.0359, -0.0091, -0.0084,  ..., -0.0030, -0.0212, -0.0168],\n",
       "                      ...,\n",
       "                      [ 0.0355,  0.0332, -0.0382,  ..., -0.0045,  0.0204,  0.0172],\n",
       "                      [ 0.0104, -0.0090,  0.0299,  ...,  0.0394,  0.0299, -0.0326],\n",
       "                      [-0.0275, -0.0443,  0.0052,  ...,  0.0295,  0.0176, -0.0239]])),\n",
       "             ('decoder.layers.1.feed_forward_block.linear_1.bias',\n",
       "              tensor([-0.0073, -0.0095,  0.0165,  ...,  0.0360,  0.0441,  0.0292])),\n",
       "             ('decoder.layers.1.feed_forward_block.linear_2.weight',\n",
       "              tensor([[ 0.0054,  0.0031,  0.0153,  ...,  0.0262, -0.0105,  0.0113],\n",
       "                      [-0.0344,  0.0112, -0.0480,  ...,  0.0161, -0.0380, -0.0328],\n",
       "                      [ 0.0118,  0.0257, -0.0066,  ..., -0.0221,  0.0448,  0.0269],\n",
       "                      ...,\n",
       "                      [ 0.0397, -0.0060, -0.0461,  ...,  0.0004,  0.0354,  0.0078],\n",
       "                      [-0.0417, -0.0329, -0.0040,  ..., -0.0465,  0.0027,  0.0106],\n",
       "                      [ 0.0337,  0.0155,  0.0388,  ...,  0.0134, -0.0291,  0.0007]])),\n",
       "             ('decoder.layers.1.feed_forward_block.linear_2.bias',\n",
       "              tensor([ 1.3738e-02,  1.4828e-02,  9.9797e-03, -5.0609e-03, -7.6512e-03,\n",
       "                      -1.2346e-02,  2.2373e-03, -1.1407e-02, -1.7869e-03, -5.8529e-03,\n",
       "                      -4.3577e-03, -2.0834e-02,  4.5604e-03, -3.1455e-03, -2.1699e-02,\n",
       "                       5.0603e-03,  8.6645e-03, -1.5777e-02, -7.4270e-03,  3.4779e-03,\n",
       "                       8.5106e-04, -9.2072e-03,  9.3746e-03,  6.6157e-03,  7.3400e-03,\n",
       "                       8.5667e-04,  1.3735e-02,  5.2927e-03,  3.3990e-03,  1.4857e-02,\n",
       "                       8.1837e-04, -3.3268e-03, -2.0464e-02, -4.9491e-03, -9.9818e-03,\n",
       "                       1.2601e-02, -1.5542e-03, -6.8431e-04,  3.0889e-04, -1.6036e-02,\n",
       "                      -1.6328e-02,  1.1485e-02, -4.0676e-03,  1.3794e-02,  1.8802e-02,\n",
       "                       1.2500e-02,  1.2133e-02, -9.6517e-03, -1.3868e-02, -6.8448e-03,\n",
       "                       1.0275e-02, -2.3923e-03,  1.6545e-02,  1.8163e-02,  7.2041e-03,\n",
       "                       2.1832e-03, -2.3307e-03, -2.1018e-02,  3.7562e-03, -5.8656e-03,\n",
       "                      -1.0616e-02, -3.5095e-03,  3.2260e-03, -1.3358e-03,  1.4438e-02,\n",
       "                      -1.7541e-02, -2.0926e-02,  1.7233e-02,  2.5366e-03,  3.9383e-03,\n",
       "                       8.9917e-03,  4.9484e-03,  8.7697e-04,  1.3982e-02, -2.0820e-02,\n",
       "                       9.6041e-03, -1.7173e-02,  1.2573e-02, -1.8866e-02, -1.1828e-02,\n",
       "                      -1.8389e-02, -1.3785e-02, -4.4723e-03,  4.8290e-03, -1.8737e-02,\n",
       "                       1.1989e-02,  7.3723e-03,  5.2563e-03, -1.0669e-02,  5.6361e-03,\n",
       "                       3.3044e-03, -1.0114e-02, -9.7475e-03, -1.0606e-02, -7.1306e-03,\n",
       "                       5.5255e-03,  8.1023e-03,  4.7975e-03, -1.7379e-02, -1.1180e-02,\n",
       "                       1.5634e-02, -9.0217e-03, -2.4455e-04, -1.8440e-02, -4.2542e-03,\n",
       "                       6.1432e-03, -1.0145e-02,  1.0235e-02, -6.7195e-03, -5.6642e-04,\n",
       "                       1.0435e-03,  2.0488e-02, -1.3026e-02,  1.0181e-02, -1.4899e-02,\n",
       "                      -4.8458e-03,  1.0582e-02, -7.9868e-03, -1.3263e-02,  1.7741e-02,\n",
       "                       5.2261e-03, -9.1892e-03,  1.0349e-02,  1.6310e-03,  1.8182e-02,\n",
       "                      -1.7944e-02,  1.3908e-02, -2.1501e-02,  2.0570e-02,  9.0307e-03,\n",
       "                      -6.1268e-04, -7.4377e-03, -1.4412e-02,  2.1637e-02, -7.3240e-03,\n",
       "                      -1.9123e-02, -1.2582e-02,  1.6844e-02,  6.7672e-03, -4.0763e-03,\n",
       "                      -5.3626e-03, -9.6515e-03,  2.9091e-03, -1.0912e-02, -4.9742e-03,\n",
       "                       1.7608e-02,  1.0003e-02,  2.0764e-02, -1.1471e-03, -1.4895e-03,\n",
       "                       2.1625e-02, -1.1702e-02,  2.1827e-02, -2.2002e-02,  1.9976e-02,\n",
       "                      -2.1855e-02, -2.1927e-02, -1.2816e-02, -1.7034e-03,  2.8606e-03,\n",
       "                      -2.7566e-03, -5.4884e-03, -2.0377e-02,  2.1721e-02,  5.0214e-04,\n",
       "                       1.6301e-02, -2.4950e-03,  3.6800e-03, -1.2119e-03, -9.0287e-03,\n",
       "                       9.1636e-03,  3.8316e-03, -1.1124e-02,  1.1506e-02,  2.1398e-03,\n",
       "                       3.6623e-03,  1.4913e-02,  2.1336e-02,  1.9197e-02, -3.6849e-03,\n",
       "                      -4.7893e-03,  9.4044e-03,  1.5873e-02,  4.3448e-05,  2.1149e-02,\n",
       "                       1.9903e-03,  6.7315e-03, -7.3869e-03,  1.8819e-02,  1.2616e-02,\n",
       "                       2.9712e-03,  1.4025e-02, -1.0768e-02, -1.5374e-02, -1.6321e-02,\n",
       "                       1.5654e-02, -1.3534e-02,  6.3256e-03,  6.9649e-03, -2.0686e-03,\n",
       "                      -2.8435e-03, -1.6381e-02, -1.1208e-03, -8.2966e-03, -6.6533e-03,\n",
       "                      -2.2053e-02,  4.2092e-03,  2.0899e-02,  1.9098e-02,  3.3496e-03,\n",
       "                      -1.8038e-02,  5.8449e-03, -2.5275e-03, -1.8946e-02, -1.1895e-02,\n",
       "                       2.1042e-02,  1.6327e-02,  1.8920e-02, -5.0466e-03, -1.8162e-02,\n",
       "                       2.1048e-02, -3.1961e-03, -1.8077e-02, -2.1971e-02,  1.1505e-02,\n",
       "                       1.6549e-02, -6.2737e-03,  2.1841e-02,  5.9777e-03, -1.7503e-02,\n",
       "                       7.6373e-03, -9.5193e-04, -1.5665e-02, -4.4750e-03,  1.1505e-02,\n",
       "                      -3.7720e-03, -1.2217e-03, -1.8936e-02,  1.2168e-02, -1.6820e-02,\n",
       "                      -1.8928e-02,  1.6063e-02, -1.3885e-02,  2.7022e-03,  1.6752e-02,\n",
       "                       8.8080e-03, -1.9972e-02,  5.0682e-03, -1.7050e-02,  1.5093e-02,\n",
       "                      -1.4101e-02, -1.5545e-02, -1.1165e-02, -1.5783e-02, -1.2820e-02,\n",
       "                      -1.8248e-02,  1.2038e-02,  1.6430e-02,  3.9550e-03, -1.5906e-02,\n",
       "                       8.7828e-03, -1.0050e-02,  1.8552e-02, -1.7487e-02,  1.0947e-02,\n",
       "                       8.9487e-03,  1.8549e-02,  1.6512e-02, -1.2703e-02,  3.1914e-03,\n",
       "                       5.9791e-03,  9.8940e-03,  1.2480e-02,  7.6979e-03, -1.9759e-02,\n",
       "                       3.8637e-03, -1.3324e-02, -2.0333e-02, -1.3679e-02, -1.3222e-02,\n",
       "                      -7.9909e-03,  1.7482e-02,  2.8675e-03,  1.7410e-02,  8.8832e-03,\n",
       "                      -1.2989e-02,  1.0360e-02, -2.9716e-03, -1.3318e-02,  1.5396e-03,\n",
       "                       8.7545e-03, -8.1660e-03, -1.8939e-02,  5.0647e-03, -7.6267e-03,\n",
       "                       6.3759e-03, -1.1804e-02, -6.5755e-03, -1.6289e-02, -1.6531e-02,\n",
       "                      -1.3309e-02, -1.8937e-02,  9.8078e-03,  8.6989e-03, -2.6391e-03,\n",
       "                       1.6730e-02,  1.9534e-02, -3.3447e-03, -1.1121e-02, -1.5590e-02,\n",
       "                      -1.3515e-02, -7.6619e-03, -5.8528e-03,  7.5096e-03,  2.0557e-02,\n",
       "                       1.3211e-02,  1.9472e-02,  5.5619e-03, -1.1078e-02,  9.7351e-03,\n",
       "                       3.1570e-03,  2.1942e-02,  1.1938e-02, -1.3434e-02,  1.7814e-02,\n",
       "                       1.6711e-02,  1.7317e-03, -5.1120e-03, -1.7998e-02, -5.8005e-03,\n",
       "                      -4.6610e-04,  1.7680e-02, -4.0677e-03, -1.3153e-02,  7.1191e-03,\n",
       "                       1.4588e-02, -1.8458e-02, -1.7130e-02,  1.5052e-03, -1.8884e-04,\n",
       "                      -9.9945e-03, -1.4610e-02,  1.6933e-02, -1.1112e-02,  4.6284e-03,\n",
       "                      -8.3803e-03,  6.1349e-03, -9.3085e-03,  1.5878e-02, -1.0794e-02,\n",
       "                       1.7227e-02, -1.5092e-02,  3.3277e-03, -2.2039e-03,  1.6516e-02,\n",
       "                      -1.6408e-03, -1.6594e-02, -3.9233e-03, -1.5597e-02,  9.0535e-03,\n",
       "                      -8.0999e-03, -3.7414e-03, -5.3548e-03, -1.1037e-02, -5.1030e-03,\n",
       "                      -1.9146e-02, -1.7356e-02,  7.3768e-03, -1.7594e-03,  1.1486e-03,\n",
       "                       7.0757e-04,  4.7321e-04, -1.6792e-02, -1.8107e-02, -2.0762e-02,\n",
       "                       1.8148e-02,  2.0733e-02,  1.9167e-02, -4.5124e-03, -1.6357e-02,\n",
       "                       1.3366e-02,  4.1926e-03,  5.7457e-03, -7.7544e-03,  1.6268e-02,\n",
       "                      -5.4598e-03,  9.5717e-04,  8.3406e-03, -1.6047e-02, -1.7659e-02,\n",
       "                       9.0619e-04, -1.7024e-02, -1.3059e-02,  1.5797e-02, -9.6873e-03,\n",
       "                       1.5346e-02, -1.8431e-02, -5.1458e-03, -1.1790e-02, -2.8903e-03,\n",
       "                      -2.0278e-02, -1.9325e-02, -9.6143e-03, -1.3580e-02, -1.4590e-02,\n",
       "                       6.4589e-04,  1.2680e-02, -1.2380e-03, -1.3606e-02,  3.5387e-03,\n",
       "                      -1.9986e-02, -1.3637e-02, -1.7581e-02, -7.6905e-03,  7.3149e-03,\n",
       "                       1.9985e-02,  1.4163e-02,  2.0539e-03,  1.5382e-02, -6.8364e-04,\n",
       "                       8.1728e-03, -1.8682e-02, -1.7715e-02, -1.9342e-02,  1.0699e-02,\n",
       "                       5.6221e-03, -2.0354e-02,  4.2293e-03,  9.4093e-03, -1.2684e-02,\n",
       "                      -5.6651e-03, -1.8644e-02, -8.7343e-03,  2.1609e-02,  1.9160e-03,\n",
       "                       1.1008e-02, -3.8121e-03, -4.8560e-03,  1.9871e-02,  1.3636e-02,\n",
       "                       8.8003e-03, -6.7995e-03, -6.9105e-03, -2.1846e-02, -1.0178e-02,\n",
       "                       1.6695e-02,  9.0552e-03,  1.8733e-02, -2.1743e-02,  1.1210e-02,\n",
       "                       1.4732e-02, -8.3252e-03,  1.9558e-02,  9.5437e-03,  5.3669e-03,\n",
       "                      -1.1460e-02, -8.4508e-03,  2.1025e-02,  8.8593e-03,  8.3966e-03,\n",
       "                       6.7487e-03, -6.2650e-03,  9.2109e-03, -1.8073e-02, -1.8390e-03,\n",
       "                       9.4182e-03,  1.1205e-03,  4.3238e-03,  1.6205e-02, -1.1202e-02,\n",
       "                       2.1859e-03,  1.6432e-02, -6.7784e-03, -6.3900e-04, -1.1960e-02,\n",
       "                       1.7894e-02,  1.6748e-02,  1.5492e-03, -1.6993e-02,  3.0851e-03,\n",
       "                       1.8714e-02, -6.9023e-03,  9.0608e-04, -3.5507e-03, -1.9539e-02,\n",
       "                       1.4673e-02, -7.9917e-03,  7.0368e-03, -1.4208e-02,  7.8331e-03,\n",
       "                       1.1628e-02, -7.2819e-03, -1.3508e-02, -9.4491e-03,  1.8047e-02,\n",
       "                      -1.5202e-02, -2.1443e-02, -1.8148e-02,  8.4826e-03,  9.9269e-03,\n",
       "                      -1.7996e-03, -7.0485e-03, -2.0770e-02, -1.9326e-02,  4.7118e-03,\n",
       "                       1.0799e-02, -2.1693e-02, -1.0687e-02, -1.9704e-02, -7.8288e-03,\n",
       "                      -8.3499e-03,  1.5516e-02])),\n",
       "             ('decoder.layers.1.residual_connections.0.norm.alpha',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('decoder.layers.1.residual_connections.0.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('decoder.layers.1.residual_connections.1.norm.alpha',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('decoder.layers.1.residual_connections.1.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('decoder.layers.1.residual_connections.2.norm.alpha',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('decoder.layers.1.residual_connections.2.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('decoder.layers.2.self_attention_block.w_q.weight',\n",
       "              tensor([[-0.0188,  0.0101,  0.0045,  ..., -0.0058, -0.0097, -0.0568],\n",
       "                      [-0.0425, -0.0311, -0.0356,  ..., -0.0541, -0.0366,  0.0707],\n",
       "                      [ 0.0636,  0.0734, -0.0255,  ..., -0.0458,  0.0265, -0.0113],\n",
       "                      ...,\n",
       "                      [ 0.0171,  0.0071, -0.0763,  ...,  0.0430,  0.0411, -0.0282],\n",
       "                      [-0.0278, -0.0591,  0.0164,  ...,  0.0538, -0.0061,  0.0059],\n",
       "                      [ 0.0388,  0.0075,  0.0728,  ..., -0.0529, -0.0055,  0.0727]])),\n",
       "             ('decoder.layers.2.self_attention_block.w_k.weight',\n",
       "              tensor([[-0.0575,  0.0529, -0.0057,  ...,  0.0403, -0.0095,  0.0030],\n",
       "                      [-0.0296,  0.0057,  0.0476,  ...,  0.0016,  0.0508, -0.0043],\n",
       "                      [ 0.0041, -0.0383,  0.0537,  ...,  0.0751,  0.0526,  0.0203],\n",
       "                      ...,\n",
       "                      [-0.0208,  0.0748,  0.0600,  ...,  0.0221,  0.0680,  0.0113],\n",
       "                      [ 0.0628, -0.0643,  0.0219,  ...,  0.0341,  0.0195, -0.0101],\n",
       "                      [ 0.0455,  0.0724, -0.0688,  ..., -0.0557,  0.0448, -0.0359]])),\n",
       "             ('decoder.layers.2.self_attention_block.w_v.weight',\n",
       "              tensor([[-0.0618, -0.0173,  0.0315,  ...,  0.0098,  0.0408,  0.0588],\n",
       "                      [ 0.0356, -0.0108,  0.0447,  ..., -0.0340,  0.0175,  0.0582],\n",
       "                      [ 0.0382,  0.0138, -0.0625,  ..., -0.0485, -0.0106,  0.0625],\n",
       "                      ...,\n",
       "                      [ 0.0081,  0.0294, -0.0172,  ...,  0.0600, -0.0059, -0.0087],\n",
       "                      [-0.0149,  0.0320,  0.0217,  ...,  0.0722,  0.0116, -0.0538],\n",
       "                      [-0.0677, -0.0253,  0.0760,  ...,  0.0351, -0.0487,  0.0313]])),\n",
       "             ('decoder.layers.2.self_attention_block.w_o.weight',\n",
       "              tensor([[ 0.0079, -0.0088, -0.0059,  ...,  0.0715, -0.0559,  0.0196],\n",
       "                      [ 0.0688, -0.0130, -0.0022,  ..., -0.0151,  0.0569,  0.0147],\n",
       "                      [ 0.0221, -0.0475, -0.0131,  ..., -0.0566, -0.0269,  0.0012],\n",
       "                      ...,\n",
       "                      [-0.0563,  0.0012,  0.0149,  ..., -0.0240,  0.0631, -0.0538],\n",
       "                      [-0.0098, -0.0598,  0.0120,  ...,  0.0266,  0.0691, -0.0734],\n",
       "                      [ 0.0006, -0.0716, -0.0579,  ..., -0.0521, -0.0580,  0.0252]])),\n",
       "             ('decoder.layers.2.cross_attention_block.w_q.weight',\n",
       "              tensor([[ 0.0043,  0.0364, -0.0141,  ...,  0.0672, -0.0753, -0.0024],\n",
       "                      [ 0.0330, -0.0047,  0.0472,  ...,  0.0103, -0.0408, -0.0371],\n",
       "                      [ 0.0608, -0.0568,  0.0363,  ..., -0.0206, -0.0393,  0.0438],\n",
       "                      ...,\n",
       "                      [-0.0367, -0.0479,  0.0605,  ..., -0.0165, -0.0284,  0.0242],\n",
       "                      [ 0.0749, -0.0470, -0.0666,  ...,  0.0620,  0.0570, -0.0557],\n",
       "                      [ 0.0492, -0.0149,  0.0640,  ...,  0.0556,  0.0690,  0.0680]])),\n",
       "             ('decoder.layers.2.cross_attention_block.w_k.weight',\n",
       "              tensor([[-0.0523, -0.0463,  0.0555,  ..., -0.0146,  0.0093,  0.0384],\n",
       "                      [-0.0167, -0.0088,  0.0089,  ...,  0.0370, -0.0510, -0.0449],\n",
       "                      [ 0.0291, -0.0593,  0.0685,  ..., -0.0367, -0.0434,  0.0037],\n",
       "                      ...,\n",
       "                      [-0.0386, -0.0042,  0.0237,  ..., -0.0118, -0.0478, -0.0272],\n",
       "                      [ 0.0660,  0.0451, -0.0136,  ...,  0.0420,  0.0351,  0.0443],\n",
       "                      [-0.0070, -0.0245, -0.0425,  ..., -0.0548,  0.0225,  0.0216]])),\n",
       "             ('decoder.layers.2.cross_attention_block.w_v.weight',\n",
       "              tensor([[-0.0668, -0.0487,  0.0492,  ...,  0.0717,  0.0723,  0.0610],\n",
       "                      [-0.0182, -0.0191,  0.0616,  ..., -0.0655,  0.0101,  0.0535],\n",
       "                      [-0.0495,  0.0004, -0.0062,  ...,  0.0475, -0.0371, -0.0243],\n",
       "                      ...,\n",
       "                      [-0.0442, -0.0535,  0.0589,  ..., -0.0363, -0.0102, -0.0303],\n",
       "                      [ 0.0064, -0.0706, -0.0013,  ...,  0.0488,  0.0754, -0.0460],\n",
       "                      [-0.0050,  0.0512, -0.0578,  ...,  0.0425, -0.0415,  0.0268]])),\n",
       "             ('decoder.layers.2.cross_attention_block.w_o.weight',\n",
       "              tensor([[ 0.0738,  0.0158, -0.0531,  ...,  0.0501, -0.0257,  0.0713],\n",
       "                      [ 0.0474, -0.0665, -0.0347,  ...,  0.0582,  0.0645,  0.0058],\n",
       "                      [-0.0577, -0.0331, -0.0459,  ..., -0.0141, -0.0163,  0.0521],\n",
       "                      ...,\n",
       "                      [ 0.0601,  0.0567, -0.0561,  ...,  0.0569,  0.0348, -0.0457],\n",
       "                      [ 0.0718, -0.0209,  0.0701,  ...,  0.0512,  0.0296, -0.0115],\n",
       "                      [-0.0357,  0.0058,  0.0295,  ..., -0.0300,  0.0707,  0.0612]])),\n",
       "             ('decoder.layers.2.feed_forward_block.linear_1.weight',\n",
       "              tensor([[-0.0183, -0.0196, -0.0316,  ...,  0.0270, -0.0107, -0.0284],\n",
       "                      [ 0.0032,  0.0130, -0.0104,  ..., -0.0373, -0.0388, -0.0350],\n",
       "                      [-0.0289,  0.0056, -0.0251,  ...,  0.0024,  0.0204,  0.0107],\n",
       "                      ...,\n",
       "                      [-0.0458, -0.0349,  0.0272,  ...,  0.0066, -0.0474, -0.0442],\n",
       "                      [-0.0425, -0.0197,  0.0095,  ..., -0.0161, -0.0137, -0.0374],\n",
       "                      [ 0.0102, -0.0379, -0.0108,  ..., -0.0024, -0.0229, -0.0338]])),\n",
       "             ('decoder.layers.2.feed_forward_block.linear_1.bias',\n",
       "              tensor([-0.0223,  0.0117,  0.0227,  ...,  0.0046,  0.0203,  0.0276])),\n",
       "             ('decoder.layers.2.feed_forward_block.linear_2.weight',\n",
       "              tensor([[ 0.0203, -0.0014,  0.0239,  ..., -0.0161, -0.0295, -0.0130],\n",
       "                      [ 0.0438,  0.0059,  0.0375,  ...,  0.0406, -0.0134,  0.0392],\n",
       "                      [-0.0278, -0.0372,  0.0315,  ...,  0.0115, -0.0414,  0.0449],\n",
       "                      ...,\n",
       "                      [ 0.0453, -0.0278, -0.0120,  ...,  0.0214, -0.0008,  0.0010],\n",
       "                      [-0.0336, -0.0430,  0.0378,  ...,  0.0339, -0.0307, -0.0244],\n",
       "                      [ 0.0475, -0.0027, -0.0323,  ..., -0.0479,  0.0174, -0.0019]])),\n",
       "             ('decoder.layers.2.feed_forward_block.linear_2.bias',\n",
       "              tensor([-6.0731e-03, -6.4064e-03, -3.4783e-03, -9.1094e-03,  9.0863e-03,\n",
       "                       9.0633e-03, -1.1406e-03, -1.9884e-02, -1.7302e-02,  8.9465e-03,\n",
       "                       9.5033e-03, -1.2781e-02, -1.4972e-03, -6.1925e-03,  1.0258e-02,\n",
       "                      -1.5216e-03,  4.2127e-03, -1.9961e-02, -3.7898e-04,  1.8452e-02,\n",
       "                       1.0064e-03,  1.2294e-02, -2.8307e-03, -2.2012e-02,  4.5156e-03,\n",
       "                      -1.5477e-02, -2.0173e-02,  1.4185e-02, -5.2290e-03, -1.5329e-02,\n",
       "                       3.2918e-03,  1.6422e-02, -1.8031e-02, -1.0978e-02,  1.4889e-02,\n",
       "                      -1.4790e-02,  2.8657e-03, -1.8355e-02, -1.9624e-02,  1.0751e-02,\n",
       "                      -7.3793e-03, -2.1813e-02, -7.9524e-03, -8.8520e-03,  2.1256e-02,\n",
       "                      -1.8027e-02, -1.5138e-02,  2.1717e-02, -4.8118e-03,  1.1095e-02,\n",
       "                      -2.3218e-03, -2.1110e-02, -5.8492e-03,  1.4435e-02, -1.8829e-02,\n",
       "                      -9.0719e-03, -1.4845e-02,  6.7673e-03, -2.0317e-02, -3.3233e-03,\n",
       "                      -5.7055e-03, -7.8092e-03, -6.3575e-03,  1.2569e-02,  1.9398e-02,\n",
       "                       1.7395e-02,  1.8671e-02, -1.5442e-02,  1.5224e-02, -1.7535e-02,\n",
       "                      -1.2297e-02,  2.0195e-02, -5.9431e-03,  2.0568e-02,  1.3799e-02,\n",
       "                       9.7888e-03,  8.5597e-04, -1.7222e-02, -1.4728e-02,  2.0011e-02,\n",
       "                      -3.9742e-03,  1.6411e-02, -2.1460e-02,  6.3136e-03,  2.0697e-02,\n",
       "                      -2.1232e-02,  5.9986e-03, -1.1606e-02, -4.1387e-03, -2.1805e-02,\n",
       "                      -1.5943e-02,  1.7341e-03, -3.8681e-04,  1.5933e-02, -7.8058e-03,\n",
       "                      -3.5586e-03, -7.1182e-03, -9.4023e-03, -9.4008e-03,  2.1332e-02,\n",
       "                       1.8000e-03,  1.5903e-02, -5.5621e-03,  4.1290e-03,  5.4006e-03,\n",
       "                       1.5343e-02,  2.1175e-02, -1.0684e-02,  2.0393e-02,  1.8510e-02,\n",
       "                       1.1584e-02,  1.1377e-02,  1.9048e-02, -2.7620e-03, -6.8480e-03,\n",
       "                      -1.2401e-02,  7.2682e-03, -1.6913e-02, -6.8077e-03,  4.7239e-03,\n",
       "                      -1.5956e-02, -2.0497e-02,  1.0392e-02,  1.4934e-02,  1.1879e-02,\n",
       "                      -4.7641e-03, -1.1764e-02, -7.1257e-04, -7.5750e-03,  1.6362e-03,\n",
       "                       9.4789e-03, -2.5434e-03, -8.9393e-03,  7.6266e-03,  7.9103e-03,\n",
       "                      -2.1427e-02,  2.0865e-02, -3.0828e-03, -4.8266e-03,  3.3932e-03,\n",
       "                       2.0516e-02, -8.2240e-04, -4.7697e-03, -5.3419e-03, -1.8203e-02,\n",
       "                       1.1474e-02, -1.8890e-02, -1.1152e-02,  1.4167e-02, -5.8301e-03,\n",
       "                      -1.1328e-02, -1.4744e-02, -4.7881e-03, -2.6221e-03,  2.1320e-02,\n",
       "                       2.1480e-02, -1.9292e-02, -9.1657e-03, -1.8522e-02,  3.7098e-03,\n",
       "                       1.6792e-03,  4.0208e-03,  5.1779e-03,  1.8306e-02,  1.1920e-02,\n",
       "                       3.0239e-03, -7.5044e-03, -9.1018e-03, -4.6128e-04, -1.2246e-02,\n",
       "                       1.5220e-02,  6.0344e-03, -1.6998e-02,  2.0001e-02, -1.7432e-02,\n",
       "                      -1.5387e-02, -1.6493e-02, -1.1697e-04, -2.0123e-02, -8.4688e-03,\n",
       "                      -1.2819e-02,  2.0588e-02,  2.0897e-02, -6.3830e-03, -1.8313e-02,\n",
       "                      -1.0684e-02, -1.4700e-02, -1.2720e-02, -1.4941e-02,  8.3569e-03,\n",
       "                       1.2658e-02,  2.0925e-02,  4.0353e-03, -3.9458e-03, -8.7381e-03,\n",
       "                      -4.6320e-03,  1.9347e-02, -1.2901e-02, -1.0661e-02, -6.3679e-03,\n",
       "                       7.2794e-03,  1.3153e-02, -1.9873e-02, -1.6370e-02, -6.3896e-03,\n",
       "                      -1.0893e-02,  2.4523e-03, -4.0514e-04, -4.0576e-03,  1.0986e-02,\n",
       "                       2.0309e-02,  1.0228e-02, -1.7053e-02, -1.1969e-02,  7.7686e-03,\n",
       "                      -1.8919e-02, -5.3176e-03,  1.0441e-02, -1.4535e-02,  1.2445e-02,\n",
       "                      -9.4346e-03, -3.0274e-03,  7.6197e-03,  1.9489e-03, -1.2445e-03,\n",
       "                       1.2195e-02,  1.9409e-02,  8.2689e-03, -7.0582e-03,  1.7391e-02,\n",
       "                      -4.2101e-03, -2.0782e-02, -6.1355e-03, -1.9629e-02,  2.0079e-02,\n",
       "                      -3.5735e-03,  1.9680e-02,  2.1884e-02,  9.3494e-03, -2.4049e-03,\n",
       "                      -2.0933e-03,  1.5844e-03,  1.6755e-02,  1.2414e-02, -4.8404e-03,\n",
       "                      -7.3240e-03, -6.3819e-03,  8.1950e-03, -1.1813e-02,  9.0226e-03,\n",
       "                       3.3219e-03,  7.8941e-03,  6.8406e-03, -1.5227e-02,  4.0082e-03,\n",
       "                      -3.2074e-03,  1.4496e-02, -1.8552e-02, -3.2484e-03, -2.1058e-02,\n",
       "                      -1.2722e-02,  4.3865e-03,  1.9317e-02, -9.8185e-03,  1.6371e-02,\n",
       "                       1.0529e-02, -8.1116e-03,  1.4133e-02, -1.8699e-02,  3.9087e-03,\n",
       "                       1.3257e-02,  3.6380e-03,  4.9323e-03,  2.1355e-02, -1.5843e-02,\n",
       "                      -5.4009e-03, -1.5699e-02,  5.1319e-03, -6.0695e-03,  7.1268e-03,\n",
       "                      -2.2089e-03, -1.0862e-02,  2.1763e-02, -5.1511e-03, -1.1332e-02,\n",
       "                       1.1215e-02,  1.4278e-02, -1.9504e-02,  1.1408e-02, -9.3826e-03,\n",
       "                       1.1092e-02,  1.0193e-02,  1.7118e-02,  5.9276e-04,  2.1936e-02,\n",
       "                       6.9304e-03,  8.1906e-03, -1.4056e-02,  5.0170e-03,  1.3411e-02,\n",
       "                      -1.5106e-02, -4.2468e-03,  1.4206e-02,  2.2068e-02,  1.3571e-02,\n",
       "                       1.0870e-02, -1.1189e-02, -4.5451e-03, -2.4406e-03, -7.4727e-03,\n",
       "                      -1.1458e-02, -1.9812e-02,  6.1597e-03,  2.2001e-02, -1.6570e-02,\n",
       "                      -1.2858e-02,  1.3988e-02,  1.8851e-02, -1.0180e-02, -8.5202e-03,\n",
       "                       1.9758e-02,  1.5900e-02,  6.0547e-03,  1.1362e-02, -8.6346e-03,\n",
       "                       2.1654e-02, -7.6450e-03, -1.0143e-02, -1.5138e-02,  1.6636e-02,\n",
       "                       1.2328e-02, -1.0258e-02, -8.4784e-03,  1.3293e-02,  1.9478e-02,\n",
       "                      -9.2576e-03, -1.7441e-02, -1.9342e-02,  2.0359e-02, -5.9746e-03,\n",
       "                      -1.5550e-02, -1.1561e-02,  1.6911e-02,  3.6960e-03, -1.2442e-02,\n",
       "                       1.7310e-02,  9.1406e-03, -2.2038e-03, -1.8345e-02,  2.8995e-03,\n",
       "                       7.4987e-03,  1.6083e-02,  9.0354e-03, -8.6184e-03, -2.2013e-02,\n",
       "                      -2.1736e-02, -1.9724e-02,  1.4999e-02, -1.5415e-02,  1.2324e-02,\n",
       "                       1.7224e-02,  7.4927e-03,  1.6453e-02,  1.6458e-02,  1.2587e-02,\n",
       "                      -1.9130e-02,  1.5078e-02, -1.0089e-03, -1.9021e-02,  1.0916e-02,\n",
       "                       2.1408e-03, -1.4970e-02, -1.1846e-02, -1.3836e-02,  1.8055e-02,\n",
       "                      -8.8846e-03,  1.8593e-02, -1.8421e-02,  1.5281e-02,  3.4491e-03,\n",
       "                       9.5712e-03,  1.4823e-03,  6.2170e-03,  1.5455e-02, -1.7922e-02,\n",
       "                       5.9080e-03, -1.6757e-02,  1.0457e-02, -1.6241e-02,  1.9897e-02,\n",
       "                       1.2437e-02,  2.2590e-03, -1.6475e-02, -5.2131e-03, -9.1498e-03,\n",
       "                       8.7337e-03, -1.4879e-02,  4.3958e-03,  2.2232e-04, -3.2262e-03,\n",
       "                      -3.8724e-03, -2.1404e-02, -8.3519e-05, -8.8979e-03,  6.2452e-03,\n",
       "                       5.3906e-03,  1.0041e-03, -9.0830e-03, -1.6764e-02,  1.3089e-02,\n",
       "                      -1.1566e-02,  1.0873e-02, -7.4383e-03, -9.8338e-03,  1.0788e-02,\n",
       "                       1.7382e-02, -7.1626e-03, -1.3269e-02, -1.2914e-02, -1.5373e-02,\n",
       "                       1.1928e-02,  1.2336e-02,  1.0958e-02,  4.4288e-04,  1.6017e-02,\n",
       "                      -1.9282e-02, -7.0964e-03,  1.1728e-02, -6.4032e-04, -1.7545e-03,\n",
       "                       1.2824e-02, -1.2933e-02, -1.7839e-03, -1.4166e-02, -5.6949e-03,\n",
       "                       5.4306e-03,  4.9276e-03,  1.0237e-02,  1.7267e-02, -8.0385e-03,\n",
       "                       1.4114e-02,  8.3026e-03, -5.2493e-03,  1.0650e-02,  7.2325e-03,\n",
       "                      -1.7846e-02,  1.2447e-04,  1.1730e-02, -2.0584e-02,  1.1615e-02,\n",
       "                      -8.6354e-03,  1.2347e-02,  2.0924e-02, -4.1535e-03,  1.1859e-02,\n",
       "                      -1.7712e-03, -1.6076e-02, -1.4291e-02, -1.4950e-03,  1.3982e-03,\n",
       "                      -1.7036e-02,  1.0580e-02,  1.1208e-02,  1.9778e-02,  4.4936e-03,\n",
       "                      -1.6922e-02,  6.0740e-04, -5.2341e-03,  6.0849e-03,  1.0922e-02,\n",
       "                       1.1782e-03,  2.1147e-02,  1.9671e-02,  5.1500e-04,  2.6554e-03,\n",
       "                       9.4294e-04, -9.8269e-03,  1.7026e-02, -1.2397e-02, -2.0578e-02,\n",
       "                      -2.0996e-03, -8.2804e-03,  1.4479e-02,  9.8710e-03,  2.9418e-03,\n",
       "                       1.5400e-02, -2.0591e-02,  1.8169e-02, -8.0159e-03,  3.3975e-03,\n",
       "                       1.3012e-02, -9.4796e-03,  1.4557e-03,  5.8689e-03,  1.8451e-02,\n",
       "                       5.2984e-03, -7.8029e-03,  1.0975e-02,  1.4589e-02, -2.1509e-02,\n",
       "                       1.9158e-03,  6.2102e-03, -1.9293e-02, -5.7782e-03, -5.4129e-04,\n",
       "                      -1.3254e-02, -1.5379e-03, -1.6339e-02, -7.5575e-03,  6.3601e-03,\n",
       "                      -8.7829e-03, -1.2148e-02])),\n",
       "             ('decoder.layers.2.residual_connections.0.norm.alpha',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('decoder.layers.2.residual_connections.0.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('decoder.layers.2.residual_connections.1.norm.alpha',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('decoder.layers.2.residual_connections.1.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('decoder.layers.2.residual_connections.2.norm.alpha',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('decoder.layers.2.residual_connections.2.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('decoder.layers.3.self_attention_block.w_q.weight',\n",
       "              tensor([[-0.0031, -0.0173, -0.0530,  ..., -0.0569,  0.0523, -0.0688],\n",
       "                      [-0.0256, -0.0139,  0.0572,  ...,  0.0317,  0.0756,  0.0349],\n",
       "                      [-0.0523, -0.0691, -0.0254,  ...,  0.0232,  0.0556, -0.0133],\n",
       "                      ...,\n",
       "                      [ 0.0640, -0.0231,  0.0478,  ..., -0.0420, -0.0095, -0.0576],\n",
       "                      [-0.0031,  0.0358,  0.0408,  ..., -0.0704, -0.0355, -0.0737],\n",
       "                      [-0.0414,  0.0088, -0.0048,  ...,  0.0682, -0.0329, -0.0207]])),\n",
       "             ('decoder.layers.3.self_attention_block.w_k.weight',\n",
       "              tensor([[-0.0518,  0.0504,  0.0125,  ..., -0.0708,  0.0512, -0.0159],\n",
       "                      [ 0.0117, -0.0500, -0.0665,  ..., -0.0027,  0.0505,  0.0477],\n",
       "                      [-0.0423,  0.0147, -0.0451,  ...,  0.0200,  0.0511, -0.0690],\n",
       "                      ...,\n",
       "                      [ 0.0517, -0.0747,  0.0479,  ..., -0.0346, -0.0026, -0.0030],\n",
       "                      [ 0.0244,  0.0754,  0.0136,  ...,  0.0665,  0.0252,  0.0631],\n",
       "                      [-0.0669,  0.0200, -0.0671,  ..., -0.0755,  0.0693,  0.0253]])),\n",
       "             ('decoder.layers.3.self_attention_block.w_v.weight',\n",
       "              tensor([[-0.0035, -0.0201,  0.0071,  ...,  0.0046,  0.0439,  0.0693],\n",
       "                      [ 0.0529,  0.0085,  0.0425,  ..., -0.0524, -0.0167, -0.0592],\n",
       "                      [-0.0764,  0.0431,  0.0715,  ..., -0.0747,  0.0408,  0.0618],\n",
       "                      ...,\n",
       "                      [ 0.0276,  0.0640,  0.0134,  ..., -0.0168,  0.0469, -0.0240],\n",
       "                      [-0.0006,  0.0477,  0.0013,  ..., -0.0720, -0.0248,  0.0642],\n",
       "                      [-0.0641,  0.0266,  0.0642,  ..., -0.0329,  0.0055,  0.0536]])),\n",
       "             ('decoder.layers.3.self_attention_block.w_o.weight',\n",
       "              tensor([[ 0.0211,  0.0731,  0.0116,  ...,  0.0608,  0.0044,  0.0162],\n",
       "                      [ 0.0410,  0.0140, -0.0198,  ...,  0.0115, -0.0237,  0.0546],\n",
       "                      [ 0.0609,  0.0702, -0.0612,  ..., -0.0726,  0.0655, -0.0264],\n",
       "                      ...,\n",
       "                      [ 0.0348,  0.0595, -0.0141,  ..., -0.0385, -0.0527,  0.0403],\n",
       "                      [ 0.0006,  0.0325,  0.0341,  ..., -0.0677, -0.0722,  0.0639],\n",
       "                      [ 0.0222, -0.0696,  0.0075,  ..., -0.0243, -0.0564,  0.0603]])),\n",
       "             ('decoder.layers.3.cross_attention_block.w_q.weight',\n",
       "              tensor([[-0.0592,  0.0047, -0.0474,  ..., -0.0448,  0.0096,  0.0587],\n",
       "                      [ 0.0136, -0.0447, -0.0196,  ...,  0.0763,  0.0194, -0.0543],\n",
       "                      [ 0.0350, -0.0588, -0.0463,  ..., -0.0281,  0.0331, -0.0238],\n",
       "                      ...,\n",
       "                      [-0.0044, -0.0242, -0.0637,  ...,  0.0111,  0.0152,  0.0499],\n",
       "                      [-0.0086,  0.0747,  0.0259,  ..., -0.0405,  0.0020,  0.0465],\n",
       "                      [ 0.0499,  0.0082, -0.0707,  ..., -0.0067, -0.0647, -0.0088]])),\n",
       "             ('decoder.layers.3.cross_attention_block.w_k.weight',\n",
       "              tensor([[-0.0304, -0.0706,  0.0144,  ...,  0.0124,  0.0554,  0.0328],\n",
       "                      [-0.0318,  0.0238,  0.0143,  ..., -0.0016, -0.0038, -0.0162],\n",
       "                      [ 0.0582,  0.0530,  0.0692,  ..., -0.0016, -0.0241,  0.0205],\n",
       "                      ...,\n",
       "                      [-0.0188, -0.0408, -0.0288,  ...,  0.0620,  0.0685, -0.0334],\n",
       "                      [-0.0365,  0.0579,  0.0455,  ..., -0.0392, -0.0230,  0.0487],\n",
       "                      [-0.0293,  0.0539, -0.0625,  ...,  0.0294,  0.0632, -0.0530]])),\n",
       "             ('decoder.layers.3.cross_attention_block.w_v.weight',\n",
       "              tensor([[-0.0005, -0.0130,  0.0345,  ..., -0.0451,  0.0501,  0.0142],\n",
       "                      [ 0.0090, -0.0567, -0.0178,  ...,  0.0211, -0.0557, -0.0374],\n",
       "                      [-0.0561,  0.0518, -0.0286,  ..., -0.0249,  0.0196, -0.0513],\n",
       "                      ...,\n",
       "                      [ 0.0015,  0.0202,  0.0751,  ...,  0.0097, -0.0199,  0.0407],\n",
       "                      [ 0.0327,  0.0543,  0.0365,  ...,  0.0440,  0.0130, -0.0076],\n",
       "                      [ 0.0289, -0.0061, -0.0259,  ...,  0.0184,  0.0086, -0.0349]])),\n",
       "             ('decoder.layers.3.cross_attention_block.w_o.weight',\n",
       "              tensor([[-0.0113,  0.0103, -0.0216,  ..., -0.0239,  0.0179, -0.0519],\n",
       "                      [-0.0147,  0.0023, -0.0761,  ...,  0.0457,  0.0114, -0.0570],\n",
       "                      [-0.0750, -0.0002, -0.0471,  ...,  0.0108, -0.0359, -0.0489],\n",
       "                      ...,\n",
       "                      [ 0.0569, -0.0136, -0.0117,  ..., -0.0710,  0.0733,  0.0461],\n",
       "                      [-0.0553,  0.0303,  0.0308,  ..., -0.0245,  0.0126, -0.0411],\n",
       "                      [-0.0688, -0.0466, -0.0037,  ...,  0.0420,  0.0025, -0.0478]])),\n",
       "             ('decoder.layers.3.feed_forward_block.linear_1.weight',\n",
       "              tensor([[ 0.0263,  0.0221,  0.0240,  ...,  0.0083, -0.0118, -0.0186],\n",
       "                      [-0.0312, -0.0277,  0.0435,  ..., -0.0103,  0.0171,  0.0121],\n",
       "                      [-0.0005,  0.0034,  0.0032,  ...,  0.0086, -0.0045,  0.0246],\n",
       "                      ...,\n",
       "                      [ 0.0226,  0.0115, -0.0226,  ...,  0.0058,  0.0264, -0.0477],\n",
       "                      [ 0.0121,  0.0372, -0.0172,  ..., -0.0327,  0.0475, -0.0023],\n",
       "                      [ 0.0041, -0.0032, -0.0388,  ...,  0.0036, -0.0265, -0.0324]])),\n",
       "             ('decoder.layers.3.feed_forward_block.linear_1.bias',\n",
       "              tensor([-0.0402, -0.0416, -0.0099,  ...,  0.0112,  0.0378, -0.0026])),\n",
       "             ('decoder.layers.3.feed_forward_block.linear_2.weight',\n",
       "              tensor([[-0.0228, -0.0044,  0.0190,  ..., -0.0111,  0.0268,  0.0286],\n",
       "                      [ 0.0222, -0.0427,  0.0113,  ..., -0.0345, -0.0193, -0.0287],\n",
       "                      [-0.0382,  0.0465, -0.0372,  ...,  0.0380, -0.0128,  0.0251],\n",
       "                      ...,\n",
       "                      [-0.0231, -0.0212, -0.0455,  ...,  0.0221, -0.0361, -0.0012],\n",
       "                      [ 0.0414,  0.0150,  0.0456,  ..., -0.0250,  0.0043, -0.0072],\n",
       "                      [-0.0360, -0.0407, -0.0457,  ...,  0.0331,  0.0044, -0.0189]])),\n",
       "             ('decoder.layers.3.feed_forward_block.linear_2.bias',\n",
       "              tensor([-5.5395e-03,  1.0017e-02, -1.3616e-03,  1.7044e-03, -9.8443e-03,\n",
       "                       1.0866e-02,  1.1157e-02,  9.8214e-03,  1.9772e-02, -1.2576e-02,\n",
       "                      -1.8002e-02, -1.7133e-02, -1.5042e-03,  5.9435e-03, -1.7575e-02,\n",
       "                       2.0505e-02, -1.6045e-02, -4.2243e-03, -1.3874e-02,  2.1088e-02,\n",
       "                      -1.9947e-02, -3.3228e-03,  8.1974e-03, -3.9236e-03, -8.9407e-03,\n",
       "                       1.6292e-02, -6.9898e-03, -2.1581e-02,  2.0886e-02,  5.8705e-03,\n",
       "                      -1.8158e-02,  1.6195e-02, -1.2240e-02, -1.4208e-02, -4.8116e-03,\n",
       "                       2.5892e-03, -1.7181e-02,  1.4385e-02, -4.7849e-03,  6.2142e-03,\n",
       "                       1.3126e-02, -1.8094e-02,  5.3949e-04,  2.0179e-02,  1.2447e-02,\n",
       "                       1.3560e-02, -3.4694e-03,  1.5492e-02,  1.8719e-02, -1.2393e-02,\n",
       "                       7.4564e-03,  2.1689e-02,  8.9583e-03, -3.6168e-03, -2.1116e-02,\n",
       "                      -5.9563e-03,  1.3602e-02, -6.7787e-03, -1.5662e-02,  2.8084e-03,\n",
       "                      -1.2573e-02,  1.6102e-03,  1.2197e-02,  2.1739e-02, -2.7158e-03,\n",
       "                       1.8717e-02,  5.9242e-03, -1.8809e-02,  2.0917e-02,  1.0060e-03,\n",
       "                       1.9496e-02, -2.7567e-04,  1.4949e-02,  6.2668e-03,  2.1701e-02,\n",
       "                      -1.1113e-02,  1.4916e-02,  1.3710e-03,  1.0103e-02,  1.2700e-02,\n",
       "                       2.0534e-02, -4.9153e-03, -1.5317e-02,  1.0022e-02, -9.8503e-03,\n",
       "                      -1.0718e-02,  7.1279e-03, -4.9049e-03,  1.2620e-02,  1.9338e-03,\n",
       "                       1.5311e-02,  1.3660e-02, -1.2248e-03, -9.9605e-03, -1.5708e-02,\n",
       "                      -1.5401e-02, -1.4592e-02, -5.8008e-03,  6.4449e-03, -3.5209e-03,\n",
       "                       2.2486e-03,  1.7321e-02, -2.0819e-02, -1.7260e-02, -5.2010e-03,\n",
       "                      -2.0084e-03,  1.3541e-02,  1.6235e-02, -1.5335e-02,  5.4947e-04,\n",
       "                       5.1024e-03, -1.3204e-02, -1.5957e-02,  5.9101e-03,  9.1534e-03,\n",
       "                       1.5140e-02,  1.1736e-02,  1.1353e-02,  4.4000e-03, -1.7234e-02,\n",
       "                      -5.5080e-03,  3.8260e-03, -2.1687e-02,  1.4182e-02,  1.0887e-02,\n",
       "                      -1.5604e-02, -7.6280e-03, -5.6044e-03,  2.1635e-02, -1.8724e-02,\n",
       "                      -6.8489e-03,  3.9924e-04,  5.1009e-03,  4.9753e-03, -1.3852e-02,\n",
       "                       1.2500e-02,  1.0180e-02, -7.4403e-03, -6.1471e-03, -7.5285e-03,\n",
       "                       1.9511e-02,  3.8359e-03, -1.0729e-02, -1.3525e-02, -1.7014e-02,\n",
       "                       1.8079e-02, -2.1305e-02,  1.6349e-03,  2.1516e-02,  2.5793e-03,\n",
       "                       2.0472e-02,  1.6485e-02, -1.6545e-02,  3.5178e-04,  1.9709e-02,\n",
       "                      -1.1752e-02, -1.8873e-02, -1.1763e-02, -9.0018e-03,  1.8638e-02,\n",
       "                       3.4696e-03,  1.9277e-02,  1.4592e-02, -2.0563e-03,  1.8464e-02,\n",
       "                       7.2233e-04, -1.9530e-02, -2.0712e-02,  1.0998e-02,  3.2069e-03,\n",
       "                       3.9243e-03,  1.0006e-02,  8.2159e-03,  2.1165e-02, -4.9391e-04,\n",
       "                       1.9793e-02,  1.2454e-03, -1.0844e-02,  2.3824e-03, -1.3558e-03,\n",
       "                       1.8232e-02,  5.1470e-03, -1.7598e-02, -2.1294e-03,  6.5179e-04,\n",
       "                       1.3348e-02, -5.8527e-03,  1.9658e-02,  1.9986e-02, -1.3198e-02,\n",
       "                       4.2045e-03,  1.6298e-02, -1.7573e-02, -7.3948e-03, -1.6365e-02,\n",
       "                      -1.3289e-02, -7.0063e-03, -1.5317e-03,  4.8704e-03,  1.6238e-02,\n",
       "                       3.6919e-03,  1.4660e-02,  4.5113e-03,  2.0858e-02, -1.5578e-02,\n",
       "                       8.9785e-03,  7.4569e-03,  1.2125e-02,  7.4955e-03,  7.1619e-03,\n",
       "                      -2.6262e-03, -1.2694e-02,  2.1657e-02,  7.9501e-05,  1.7289e-02,\n",
       "                      -2.0222e-02, -4.4621e-03, -1.5387e-02, -8.6762e-03,  1.6850e-02,\n",
       "                      -1.4465e-02, -1.6199e-02,  8.1476e-03,  1.3746e-02,  3.2284e-04,\n",
       "                      -7.5378e-03, -1.4574e-02,  1.7623e-02,  1.3411e-02, -1.8437e-02,\n",
       "                      -1.4822e-02,  1.3108e-02, -1.9982e-02, -1.2127e-02, -1.9992e-03,\n",
       "                      -4.9498e-03, -7.2169e-03, -2.1780e-02,  1.9548e-02,  2.1592e-02,\n",
       "                       6.5517e-03, -1.9299e-02, -1.0954e-02, -1.4385e-02, -1.4374e-02,\n",
       "                      -1.9286e-02,  1.7016e-03, -1.8573e-02, -4.7525e-03,  1.6405e-02,\n",
       "                      -4.9425e-03, -1.3797e-02, -1.9317e-02, -1.1731e-02,  5.0465e-03,\n",
       "                       1.0390e-02,  1.4211e-02,  8.7966e-03,  1.6984e-02,  7.5147e-03,\n",
       "                      -1.4774e-02,  2.3909e-03,  6.1364e-03, -1.7249e-02, -3.7432e-03,\n",
       "                       1.7698e-02,  2.1724e-03,  9.5658e-03,  3.8717e-03,  1.6198e-02,\n",
       "                       8.6654e-03,  1.8111e-02,  1.9311e-03, -1.6676e-02, -9.0916e-03,\n",
       "                      -8.1339e-03,  2.1174e-02, -1.7411e-02, -2.0919e-02, -9.2606e-03,\n",
       "                      -1.1877e-03,  1.9201e-02, -6.8963e-03,  1.7881e-02,  1.6217e-03,\n",
       "                      -1.8743e-02, -1.5601e-02,  1.6307e-02, -5.3762e-03,  1.3234e-02,\n",
       "                      -1.8888e-03, -1.7362e-03,  2.1423e-02, -5.6940e-03,  1.3464e-02,\n",
       "                      -1.4843e-02,  1.0590e-02,  8.5879e-03,  1.8472e-02, -8.9309e-03,\n",
       "                      -5.6840e-04,  2.1191e-02, -2.2974e-03,  7.0324e-03, -1.5166e-02,\n",
       "                      -2.0232e-02,  5.9968e-03,  7.1869e-03,  3.6379e-03,  7.3519e-04,\n",
       "                       2.1595e-02, -6.0565e-03,  1.5781e-02,  3.3491e-03, -5.5393e-03,\n",
       "                       6.8304e-03, -1.1466e-02,  1.5233e-02,  2.6507e-04,  9.1188e-03,\n",
       "                      -8.0701e-03,  5.6869e-03,  3.1312e-03,  1.9201e-02, -3.8130e-03,\n",
       "                       1.1484e-02,  1.9576e-02,  6.2852e-03,  1.1741e-02,  1.9400e-02,\n",
       "                      -1.5743e-02,  5.3016e-03,  1.1993e-02, -7.9287e-03,  1.2968e-02,\n",
       "                       7.6300e-03, -2.1582e-02, -6.8249e-03,  7.6396e-03, -1.4326e-02,\n",
       "                      -9.7191e-04,  6.0802e-03, -7.2440e-03, -4.0883e-03,  1.9393e-02,\n",
       "                       9.5273e-03, -1.6222e-02, -1.0639e-02, -6.0632e-03,  2.1448e-02,\n",
       "                      -9.4131e-03,  2.1008e-02,  8.9108e-03,  7.0716e-03, -3.9745e-03,\n",
       "                       4.3102e-03, -1.3958e-03,  7.7627e-03, -1.4884e-02,  2.1234e-02,\n",
       "                       6.2217e-03, -1.6505e-02, -1.1628e-02, -3.1223e-03,  9.7493e-03,\n",
       "                       7.3131e-03,  1.6435e-02, -1.6400e-02, -4.7047e-03, -8.7791e-03,\n",
       "                       1.8545e-02, -7.4384e-03,  1.6152e-03, -4.2614e-03,  1.0823e-02,\n",
       "                      -9.8692e-03, -1.2906e-02, -1.6996e-02, -6.9276e-03, -9.2379e-03,\n",
       "                       6.7330e-04,  2.0260e-02,  1.4527e-02,  1.4105e-02,  2.7595e-03,\n",
       "                       2.0660e-02, -1.7689e-02,  3.5644e-03,  2.0775e-02, -2.8708e-03,\n",
       "                       1.9232e-02,  1.7372e-02,  1.9282e-02, -7.6927e-03,  2.0336e-02,\n",
       "                       1.9857e-02,  3.0315e-03, -1.0294e-02,  6.3068e-03,  1.9800e-03,\n",
       "                       8.4179e-03,  1.0112e-02,  3.8470e-03, -1.2147e-02,  7.9744e-04,\n",
       "                      -6.3886e-03,  2.7965e-03, -3.9037e-03,  3.3578e-03, -9.5618e-03,\n",
       "                      -3.5712e-03,  1.5615e-02, -7.1036e-03, -8.2989e-03,  2.1389e-02,\n",
       "                       1.1424e-02, -1.8768e-03,  2.0163e-02,  2.1568e-03,  1.7595e-02,\n",
       "                      -8.7399e-03, -3.4565e-04,  8.2937e-03, -6.8764e-03, -9.0931e-03,\n",
       "                      -2.0930e-02, -4.3198e-03, -1.1477e-02,  1.4350e-02,  1.4892e-02,\n",
       "                       2.1275e-02, -8.0597e-03,  7.5365e-03, -1.9319e-02,  1.3066e-02,\n",
       "                       2.1898e-02, -8.9295e-03,  6.4794e-03, -2.8350e-03,  2.1774e-02,\n",
       "                      -8.4028e-03,  1.0134e-02, -1.8074e-02,  1.1096e-03,  1.6665e-02,\n",
       "                       8.4279e-03,  8.6382e-03, -8.0858e-03, -1.5779e-02,  5.4858e-03,\n",
       "                       1.7569e-02,  4.1368e-03, -1.1474e-02, -8.1215e-03,  1.6770e-02,\n",
       "                      -4.0516e-03,  2.5629e-03,  1.5684e-02,  4.8520e-03, -4.1434e-03,\n",
       "                      -6.8627e-03,  1.1630e-02,  3.4910e-03,  1.0419e-02,  2.2965e-03,\n",
       "                       1.0445e-02, -1.5126e-02,  2.1609e-02, -1.3021e-02,  6.9346e-03,\n",
       "                      -7.0910e-03, -1.1037e-02,  1.9225e-02,  5.4292e-03, -9.6066e-03,\n",
       "                      -1.2723e-02,  2.0646e-02, -1.3360e-02,  1.4755e-03,  8.9727e-03,\n",
       "                       1.1721e-03,  1.6709e-02, -1.8356e-02, -1.0956e-02,  2.4489e-03,\n",
       "                      -1.7335e-02, -2.0140e-02, -1.5824e-02, -1.1228e-02,  1.1660e-02,\n",
       "                      -1.4244e-02, -6.6539e-03,  1.9188e-02, -1.4168e-02,  1.8516e-02,\n",
       "                      -9.6923e-03,  1.0680e-03, -1.5895e-02,  1.2155e-02, -4.5406e-03,\n",
       "                      -1.5836e-02, -1.7971e-02,  1.5202e-02,  1.8929e-02, -1.9066e-02,\n",
       "                      -1.4884e-03,  2.1174e-02, -2.0311e-02,  1.3105e-02, -6.2831e-03,\n",
       "                       9.1701e-03, -2.9872e-03])),\n",
       "             ('decoder.layers.3.residual_connections.0.norm.alpha',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('decoder.layers.3.residual_connections.0.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('decoder.layers.3.residual_connections.1.norm.alpha',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('decoder.layers.3.residual_connections.1.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('decoder.layers.3.residual_connections.2.norm.alpha',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('decoder.layers.3.residual_connections.2.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('decoder.layers.4.self_attention_block.w_q.weight',\n",
       "              tensor([[ 0.0701, -0.0537, -0.0214,  ...,  0.0229, -0.0244,  0.0043],\n",
       "                      [ 0.0214, -0.0015,  0.0124,  ...,  0.0707,  0.0568,  0.0253],\n",
       "                      [ 0.0557, -0.0570,  0.0269,  ..., -0.0303, -0.0403,  0.0072],\n",
       "                      ...,\n",
       "                      [ 0.0089, -0.0324,  0.0380,  ..., -0.0283,  0.0151, -0.0038],\n",
       "                      [-0.0485,  0.0260,  0.0016,  ..., -0.0493, -0.0242, -0.0131],\n",
       "                      [-0.0135, -0.0263, -0.0156,  ...,  0.0286, -0.0447,  0.0212]])),\n",
       "             ('decoder.layers.4.self_attention_block.w_k.weight',\n",
       "              tensor([[-0.0608, -0.0282, -0.0357,  ...,  0.0051,  0.0653,  0.0081],\n",
       "                      [ 0.0689, -0.0597,  0.0142,  ..., -0.0555,  0.0309,  0.0604],\n",
       "                      [-0.0196, -0.0334, -0.0414,  ...,  0.0163,  0.0473,  0.0449],\n",
       "                      ...,\n",
       "                      [-0.0542, -0.0050,  0.0424,  ...,  0.0080, -0.0576,  0.0744],\n",
       "                      [ 0.0747,  0.0583,  0.0290,  ..., -0.0303,  0.0470, -0.0252],\n",
       "                      [ 0.0115, -0.0332,  0.0557,  ..., -0.0337,  0.0639,  0.0569]])),\n",
       "             ('decoder.layers.4.self_attention_block.w_v.weight',\n",
       "              tensor([[-0.0712, -0.0072,  0.0296,  ...,  0.0424, -0.0376,  0.0002],\n",
       "                      [ 0.0708,  0.0224, -0.0189,  ...,  0.0069,  0.0320,  0.0658],\n",
       "                      [-0.0042, -0.0721,  0.0113,  ...,  0.0105, -0.0630, -0.0631],\n",
       "                      ...,\n",
       "                      [-0.0427,  0.0277,  0.0278,  ..., -0.0376,  0.0500,  0.0743],\n",
       "                      [-0.0395, -0.0465, -0.0720,  ..., -0.0531, -0.0163, -0.0221],\n",
       "                      [ 0.0478, -0.0371, -0.0574,  ..., -0.0343, -0.0107,  0.0152]])),\n",
       "             ('decoder.layers.4.self_attention_block.w_o.weight',\n",
       "              tensor([[ 3.5782e-02,  2.9447e-02,  4.0665e-02,  ..., -5.6728e-02,\n",
       "                        6.3575e-02,  4.8706e-02],\n",
       "                      [-1.3715e-02,  1.6979e-02,  4.4631e-03,  ..., -3.4561e-02,\n",
       "                        2.1532e-02, -6.9108e-02],\n",
       "                      [-8.4348e-03,  1.6848e-02, -1.3088e-02,  ...,  3.5907e-02,\n",
       "                        6.2898e-02,  6.6795e-03],\n",
       "                      ...,\n",
       "                      [ 7.6360e-03,  7.1621e-02, -5.0546e-02,  ...,  1.4401e-02,\n",
       "                        3.1138e-02,  1.6799e-02],\n",
       "                      [-5.9847e-02,  6.9649e-02, -1.4812e-02,  ..., -6.0297e-02,\n",
       "                        7.6860e-05, -5.3997e-02],\n",
       "                      [-5.9116e-02, -4.5666e-02,  3.2100e-02,  ..., -5.0517e-02,\n",
       "                        6.4863e-03, -2.3266e-02]])),\n",
       "             ('decoder.layers.4.cross_attention_block.w_q.weight',\n",
       "              tensor([[-0.0438,  0.0752, -0.0222,  ..., -0.0131,  0.0203,  0.0534],\n",
       "                      [ 0.0225, -0.0210, -0.0490,  ..., -0.0400, -0.0539, -0.0316],\n",
       "                      [ 0.0748, -0.0150,  0.0302,  ..., -0.0701, -0.0439, -0.0640],\n",
       "                      ...,\n",
       "                      [ 0.0226, -0.0540, -0.0069,  ...,  0.0760,  0.0733,  0.0322],\n",
       "                      [-0.0590, -0.0222, -0.0164,  ...,  0.0619,  0.0705,  0.0372],\n",
       "                      [ 0.0102, -0.0238, -0.0266,  ..., -0.0703,  0.0229,  0.0449]])),\n",
       "             ('decoder.layers.4.cross_attention_block.w_k.weight',\n",
       "              tensor([[-0.0656, -0.0428,  0.0303,  ..., -0.0088, -0.0647, -0.0475],\n",
       "                      [ 0.0365,  0.0222,  0.0350,  ..., -0.0326,  0.0331,  0.0356],\n",
       "                      [ 0.0452, -0.0285, -0.0502,  ..., -0.0520,  0.0610,  0.0601],\n",
       "                      ...,\n",
       "                      [-0.0290,  0.0321, -0.0294,  ...,  0.0155,  0.0336, -0.0133],\n",
       "                      [ 0.0448,  0.0195, -0.0252,  ..., -0.0404, -0.0014, -0.0156],\n",
       "                      [-0.0667, -0.0143, -0.0241,  ...,  0.0548, -0.0489, -0.0141]])),\n",
       "             ('decoder.layers.4.cross_attention_block.w_v.weight',\n",
       "              tensor([[-0.0559, -0.0491, -0.0588,  ..., -0.0194, -0.0626,  0.0303],\n",
       "                      [ 0.0035,  0.0397, -0.0294,  ..., -0.0333, -0.0159,  0.0450],\n",
       "                      [-0.0136,  0.0139,  0.0141,  ..., -0.0067, -0.0040, -0.0261],\n",
       "                      ...,\n",
       "                      [ 0.0248, -0.0684, -0.0550,  ..., -0.0097,  0.0460,  0.0346],\n",
       "                      [-0.0138,  0.0699,  0.0694,  ...,  0.0062, -0.0121, -0.0112],\n",
       "                      [ 0.0060,  0.0125,  0.0222,  ...,  0.0292,  0.0548, -0.0039]])),\n",
       "             ('decoder.layers.4.cross_attention_block.w_o.weight',\n",
       "              tensor([[ 0.0626, -0.0644, -0.0631,  ...,  0.0231, -0.0604,  0.0465],\n",
       "                      [ 0.0111,  0.0250,  0.0441,  ...,  0.0133, -0.0380, -0.0523],\n",
       "                      [ 0.0051,  0.0193, -0.0617,  ...,  0.0300,  0.0380,  0.0175],\n",
       "                      ...,\n",
       "                      [-0.0201,  0.0599,  0.0012,  ...,  0.0701,  0.0539,  0.0475],\n",
       "                      [-0.0745,  0.0637, -0.0387,  ...,  0.0178,  0.0578, -0.0014],\n",
       "                      [ 0.0265,  0.0762, -0.0684,  ...,  0.0380, -0.0275, -0.0366]])),\n",
       "             ('decoder.layers.4.feed_forward_block.linear_1.weight',\n",
       "              tensor([[ 0.0455,  0.0206, -0.0360,  ...,  0.0277, -0.0142, -0.0181],\n",
       "                      [-0.0221,  0.0004, -0.0216,  ...,  0.0057,  0.0017, -0.0241],\n",
       "                      [-0.0278,  0.0221, -0.0138,  ..., -0.0342, -0.0377, -0.0446],\n",
       "                      ...,\n",
       "                      [-0.0332, -0.0375,  0.0475,  ..., -0.0361,  0.0292, -0.0292],\n",
       "                      [-0.0460,  0.0043, -0.0219,  ...,  0.0074,  0.0288,  0.0252],\n",
       "                      [ 0.0276,  0.0147,  0.0009,  ...,  0.0013,  0.0298,  0.0334]])),\n",
       "             ('decoder.layers.4.feed_forward_block.linear_1.bias',\n",
       "              tensor([ 0.0027, -0.0304,  0.0236,  ...,  0.0347, -0.0330, -0.0132])),\n",
       "             ('decoder.layers.4.feed_forward_block.linear_2.weight',\n",
       "              tensor([[-0.0342, -0.0417, -0.0444,  ..., -0.0414, -0.0148,  0.0114],\n",
       "                      [-0.0341,  0.0247,  0.0089,  ...,  0.0378,  0.0080,  0.0099],\n",
       "                      [-0.0382, -0.0271, -0.0353,  ...,  0.0305, -0.0232, -0.0058],\n",
       "                      ...,\n",
       "                      [-0.0110,  0.0379, -0.0338,  ..., -0.0413, -0.0278, -0.0381],\n",
       "                      [ 0.0415, -0.0059, -0.0032,  ...,  0.0257, -0.0042, -0.0395],\n",
       "                      [-0.0215,  0.0337, -0.0245,  ...,  0.0367, -0.0193,  0.0470]])),\n",
       "             ('decoder.layers.4.feed_forward_block.linear_2.bias',\n",
       "              tensor([ 0.0039, -0.0060,  0.0113, -0.0088, -0.0164,  0.0065,  0.0131,  0.0010,\n",
       "                       0.0037, -0.0151, -0.0010, -0.0040,  0.0158, -0.0115, -0.0160,  0.0006,\n",
       "                      -0.0068,  0.0042,  0.0008, -0.0185,  0.0083,  0.0064, -0.0014,  0.0071,\n",
       "                       0.0176, -0.0217,  0.0089, -0.0012, -0.0168, -0.0175, -0.0138,  0.0012,\n",
       "                      -0.0103,  0.0052,  0.0083,  0.0052, -0.0112, -0.0107, -0.0159,  0.0035,\n",
       "                       0.0076,  0.0156,  0.0045,  0.0075,  0.0105,  0.0087, -0.0048, -0.0207,\n",
       "                       0.0082,  0.0214, -0.0137, -0.0113,  0.0014,  0.0031, -0.0134, -0.0055,\n",
       "                      -0.0114,  0.0136, -0.0202,  0.0147,  0.0082, -0.0016,  0.0035, -0.0153,\n",
       "                      -0.0124,  0.0206, -0.0046,  0.0095,  0.0181,  0.0102,  0.0066,  0.0092,\n",
       "                       0.0059,  0.0082,  0.0145,  0.0118,  0.0026,  0.0163,  0.0078,  0.0019,\n",
       "                      -0.0056, -0.0116, -0.0117,  0.0028,  0.0138,  0.0149, -0.0158, -0.0096,\n",
       "                      -0.0158,  0.0201, -0.0171, -0.0215, -0.0173,  0.0161,  0.0151,  0.0018,\n",
       "                       0.0104,  0.0163, -0.0160,  0.0187,  0.0021, -0.0167,  0.0149,  0.0174,\n",
       "                       0.0004,  0.0192,  0.0125,  0.0105, -0.0118,  0.0029,  0.0101,  0.0186,\n",
       "                      -0.0143, -0.0106,  0.0060,  0.0118, -0.0139, -0.0139,  0.0007,  0.0025,\n",
       "                      -0.0204,  0.0119,  0.0085,  0.0155, -0.0031, -0.0075, -0.0052,  0.0177,\n",
       "                       0.0119, -0.0099,  0.0026,  0.0006, -0.0022,  0.0010, -0.0117, -0.0201,\n",
       "                       0.0028, -0.0028, -0.0134,  0.0094, -0.0088, -0.0202,  0.0141,  0.0070,\n",
       "                      -0.0046, -0.0001, -0.0046,  0.0136, -0.0095, -0.0028,  0.0218, -0.0059,\n",
       "                       0.0116,  0.0112,  0.0182, -0.0105, -0.0053, -0.0100,  0.0067,  0.0170,\n",
       "                       0.0062,  0.0126, -0.0166,  0.0176, -0.0133,  0.0045, -0.0061, -0.0125,\n",
       "                      -0.0099,  0.0008, -0.0191,  0.0215, -0.0134,  0.0020,  0.0198,  0.0142,\n",
       "                      -0.0150,  0.0125,  0.0175,  0.0025,  0.0171, -0.0021, -0.0125, -0.0068,\n",
       "                      -0.0134,  0.0020,  0.0164, -0.0034,  0.0195,  0.0219,  0.0027, -0.0208,\n",
       "                       0.0115,  0.0010, -0.0054, -0.0214,  0.0171,  0.0218,  0.0087, -0.0215,\n",
       "                      -0.0031, -0.0133, -0.0111,  0.0090, -0.0044,  0.0056,  0.0118,  0.0186,\n",
       "                      -0.0051, -0.0120, -0.0132, -0.0023,  0.0153, -0.0140,  0.0112, -0.0061,\n",
       "                       0.0008,  0.0163,  0.0205,  0.0170, -0.0102,  0.0187,  0.0104,  0.0031,\n",
       "                       0.0142, -0.0067, -0.0141, -0.0022, -0.0184, -0.0114,  0.0081, -0.0067,\n",
       "                       0.0113, -0.0157, -0.0172, -0.0072,  0.0120,  0.0020,  0.0155,  0.0186,\n",
       "                       0.0041, -0.0064, -0.0154,  0.0192,  0.0177,  0.0057,  0.0083, -0.0012,\n",
       "                       0.0005, -0.0133,  0.0051, -0.0075, -0.0174,  0.0202, -0.0084, -0.0016,\n",
       "                       0.0004,  0.0008, -0.0047, -0.0133,  0.0205, -0.0204, -0.0077,  0.0058,\n",
       "                       0.0158, -0.0196,  0.0030,  0.0024, -0.0025,  0.0171, -0.0068, -0.0026,\n",
       "                      -0.0056, -0.0216, -0.0022, -0.0112,  0.0221,  0.0037,  0.0190,  0.0099,\n",
       "                       0.0218, -0.0122, -0.0202, -0.0098,  0.0144, -0.0074,  0.0082,  0.0194,\n",
       "                      -0.0122,  0.0028,  0.0208,  0.0193,  0.0109, -0.0026, -0.0183,  0.0152,\n",
       "                      -0.0165,  0.0199,  0.0053, -0.0153, -0.0008, -0.0054,  0.0161,  0.0095,\n",
       "                       0.0110,  0.0104, -0.0103, -0.0095, -0.0101,  0.0105, -0.0049, -0.0067,\n",
       "                      -0.0085,  0.0024,  0.0144, -0.0121,  0.0145,  0.0200,  0.0138, -0.0061,\n",
       "                      -0.0046, -0.0097, -0.0168, -0.0097,  0.0073, -0.0216, -0.0033, -0.0124,\n",
       "                      -0.0058,  0.0134,  0.0001,  0.0147,  0.0161,  0.0107,  0.0015, -0.0041,\n",
       "                       0.0021,  0.0051, -0.0201,  0.0178,  0.0162,  0.0028, -0.0114, -0.0020,\n",
       "                      -0.0048, -0.0046, -0.0124, -0.0210, -0.0125,  0.0130,  0.0061, -0.0107,\n",
       "                      -0.0151,  0.0082,  0.0043,  0.0167,  0.0110, -0.0046,  0.0127,  0.0174,\n",
       "                       0.0204,  0.0036,  0.0164,  0.0109,  0.0044, -0.0182, -0.0166,  0.0141,\n",
       "                      -0.0094, -0.0140, -0.0077,  0.0062, -0.0120, -0.0182, -0.0168, -0.0037,\n",
       "                       0.0168,  0.0221, -0.0173, -0.0046,  0.0186, -0.0206, -0.0023,  0.0181,\n",
       "                      -0.0092, -0.0106, -0.0154,  0.0120, -0.0204, -0.0146, -0.0140, -0.0133,\n",
       "                       0.0029, -0.0099,  0.0205, -0.0029,  0.0053, -0.0156, -0.0014, -0.0198,\n",
       "                       0.0102,  0.0079,  0.0047, -0.0212, -0.0187, -0.0071, -0.0013, -0.0083,\n",
       "                       0.0099,  0.0043,  0.0159,  0.0009, -0.0217, -0.0190, -0.0084, -0.0182,\n",
       "                       0.0027,  0.0131, -0.0059, -0.0209,  0.0091,  0.0214, -0.0048, -0.0079,\n",
       "                      -0.0210, -0.0015, -0.0016, -0.0152,  0.0202, -0.0055, -0.0136,  0.0074,\n",
       "                       0.0182, -0.0048, -0.0154,  0.0027, -0.0077,  0.0198, -0.0179,  0.0220,\n",
       "                       0.0130,  0.0076,  0.0168, -0.0114, -0.0158,  0.0022,  0.0112,  0.0123,\n",
       "                       0.0023,  0.0131,  0.0064,  0.0218,  0.0100, -0.0086, -0.0157, -0.0058,\n",
       "                      -0.0076,  0.0019, -0.0096, -0.0214,  0.0095,  0.0152,  0.0085,  0.0218,\n",
       "                      -0.0020, -0.0193,  0.0138, -0.0073, -0.0185,  0.0053, -0.0114,  0.0026,\n",
       "                      -0.0175,  0.0042, -0.0127, -0.0211,  0.0139,  0.0050, -0.0179,  0.0218,\n",
       "                      -0.0110, -0.0074, -0.0174, -0.0128, -0.0005, -0.0006,  0.0048, -0.0201,\n",
       "                      -0.0166,  0.0192, -0.0122, -0.0036,  0.0192,  0.0020,  0.0089,  0.0171,\n",
       "                       0.0087, -0.0062,  0.0007,  0.0135,  0.0188,  0.0076,  0.0149, -0.0059,\n",
       "                       0.0068,  0.0101,  0.0053,  0.0087,  0.0063,  0.0095,  0.0101,  0.0009])),\n",
       "             ('decoder.layers.4.residual_connections.0.norm.alpha',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('decoder.layers.4.residual_connections.0.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('decoder.layers.4.residual_connections.1.norm.alpha',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('decoder.layers.4.residual_connections.1.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('decoder.layers.4.residual_connections.2.norm.alpha',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('decoder.layers.4.residual_connections.2.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('decoder.layers.5.self_attention_block.w_q.weight',\n",
       "              tensor([[ 0.0610,  0.0381, -0.0606,  ..., -0.0415, -0.0669, -0.0166],\n",
       "                      [-0.0531, -0.0680,  0.0376,  ..., -0.0247,  0.0232,  0.0590],\n",
       "                      [ 0.0427,  0.0144, -0.0380,  ..., -0.0035, -0.0740,  0.0531],\n",
       "                      ...,\n",
       "                      [-0.0021, -0.0370,  0.0728,  ...,  0.0662, -0.0711, -0.0407],\n",
       "                      [-0.0309, -0.0010, -0.0661,  ...,  0.0438,  0.0448,  0.0599],\n",
       "                      [-0.0670,  0.0262, -0.0434,  ...,  0.0255,  0.0527,  0.0209]])),\n",
       "             ('decoder.layers.5.self_attention_block.w_k.weight',\n",
       "              tensor([[-2.0550e-02,  6.8471e-06, -3.4450e-02,  ...,  7.0831e-02,\n",
       "                        2.0780e-02,  1.0829e-02],\n",
       "                      [-2.0654e-02, -7.0324e-02, -6.9267e-02,  ...,  7.3888e-02,\n",
       "                        5.0886e-02, -4.4012e-02],\n",
       "                      [-1.9281e-02, -6.5815e-02,  4.1404e-02,  ...,  1.4821e-02,\n",
       "                       -2.2461e-02, -5.2757e-02],\n",
       "                      ...,\n",
       "                      [-1.8428e-02,  5.8409e-03, -6.4237e-02,  ..., -3.3067e-02,\n",
       "                        5.2370e-02,  4.4200e-02],\n",
       "                      [-7.1194e-02,  1.8211e-02, -2.7201e-02,  ...,  3.6953e-02,\n",
       "                       -6.4100e-02, -3.0663e-02],\n",
       "                      [-5.4057e-02,  2.5345e-02,  6.1812e-02,  ...,  1.7281e-03,\n",
       "                       -1.1388e-02, -5.8012e-02]])),\n",
       "             ('decoder.layers.5.self_attention_block.w_v.weight',\n",
       "              tensor([[-0.0285,  0.0698,  0.0034,  ..., -0.0546,  0.0360, -0.0238],\n",
       "                      [-0.0380, -0.0439,  0.0361,  ...,  0.0391, -0.0124, -0.0145],\n",
       "                      [ 0.0136,  0.0602, -0.0547,  ..., -0.0558, -0.0167,  0.0547],\n",
       "                      ...,\n",
       "                      [-0.0121,  0.0561, -0.0315,  ..., -0.0173,  0.0547, -0.0662],\n",
       "                      [ 0.0401, -0.0651,  0.0358,  ...,  0.0188, -0.0697, -0.0125],\n",
       "                      [-0.0690,  0.0613,  0.0344,  ..., -0.0436, -0.0550, -0.0272]])),\n",
       "             ('decoder.layers.5.self_attention_block.w_o.weight',\n",
       "              tensor([[ 0.0638, -0.0448, -0.0032,  ...,  0.0507,  0.0477,  0.0065],\n",
       "                      [ 0.0506,  0.0174,  0.0066,  ...,  0.0316,  0.0569, -0.0302],\n",
       "                      [-0.0528,  0.0308,  0.0291,  ..., -0.0572,  0.0735,  0.0746],\n",
       "                      ...,\n",
       "                      [ 0.0240, -0.0557,  0.0700,  ...,  0.0416, -0.0340,  0.0061],\n",
       "                      [-0.0182,  0.0468, -0.0251,  ...,  0.0279,  0.0397,  0.0681],\n",
       "                      [-0.0680, -0.0051, -0.0317,  ...,  0.0424, -0.0663,  0.0645]])),\n",
       "             ('decoder.layers.5.cross_attention_block.w_q.weight',\n",
       "              tensor([[ 0.0648,  0.0686, -0.0498,  ...,  0.0454,  0.0289,  0.0468],\n",
       "                      [ 0.0620,  0.0345,  0.0568,  ...,  0.0472, -0.0180,  0.0659],\n",
       "                      [-0.0154,  0.0209, -0.0528,  ...,  0.0080, -0.0659, -0.0648],\n",
       "                      ...,\n",
       "                      [ 0.0479,  0.0456,  0.0449,  ..., -0.0189,  0.0006, -0.0113],\n",
       "                      [-0.0011, -0.0635,  0.0118,  ..., -0.0031, -0.0278, -0.0599],\n",
       "                      [ 0.0024,  0.0453, -0.0409,  ...,  0.0016, -0.0218, -0.0686]])),\n",
       "             ('decoder.layers.5.cross_attention_block.w_k.weight',\n",
       "              tensor([[-0.0711,  0.0735,  0.0344,  ..., -0.0489,  0.0066, -0.0696],\n",
       "                      [-0.0365,  0.0287, -0.0345,  ..., -0.0078,  0.0763, -0.0528],\n",
       "                      [-0.0139, -0.0493,  0.0547,  ...,  0.0743, -0.0562, -0.0074],\n",
       "                      ...,\n",
       "                      [-0.0159,  0.0556, -0.0539,  ...,  0.0443,  0.0181, -0.0613],\n",
       "                      [ 0.0427,  0.0286, -0.0181,  ...,  0.0278,  0.0070, -0.0374],\n",
       "                      [ 0.0368, -0.0328,  0.0584,  ..., -0.0607,  0.0053,  0.0515]])),\n",
       "             ('decoder.layers.5.cross_attention_block.w_v.weight',\n",
       "              tensor([[ 0.0425,  0.0353,  0.0397,  ...,  0.0608, -0.0507,  0.0580],\n",
       "                      [-0.0344,  0.0156,  0.0386,  ..., -0.0694, -0.0002, -0.0678],\n",
       "                      [-0.0355,  0.0124, -0.0542,  ..., -0.0017, -0.0407,  0.0518],\n",
       "                      ...,\n",
       "                      [-0.0350, -0.0172,  0.0231,  ..., -0.0623, -0.0082, -0.0058],\n",
       "                      [-0.0716,  0.0497, -0.0039,  ..., -0.0338, -0.0206, -0.0015],\n",
       "                      [ 0.0717,  0.0401, -0.0674,  ...,  0.0758, -0.0237,  0.0728]])),\n",
       "             ('decoder.layers.5.cross_attention_block.w_o.weight',\n",
       "              tensor([[ 0.0455, -0.0017, -0.0511,  ...,  0.0746, -0.0392, -0.0197],\n",
       "                      [ 0.0172,  0.0707,  0.0546,  ..., -0.0203, -0.0032, -0.0196],\n",
       "                      [ 0.0301, -0.0553,  0.0360,  ...,  0.0281,  0.0700,  0.0266],\n",
       "                      ...,\n",
       "                      [-0.0610, -0.0440, -0.0486,  ..., -0.0701, -0.0105,  0.0545],\n",
       "                      [ 0.0506, -0.0732,  0.0622,  ..., -0.0304, -0.0640,  0.0355],\n",
       "                      [ 0.0692,  0.0261,  0.0336,  ..., -0.0113, -0.0446,  0.0074]])),\n",
       "             ('decoder.layers.5.feed_forward_block.linear_1.weight',\n",
       "              tensor([[-0.0267,  0.0063, -0.0266,  ..., -0.0152,  0.0304,  0.0097],\n",
       "                      [-0.0203,  0.0351, -0.0174,  ...,  0.0444,  0.0348,  0.0003],\n",
       "                      [ 0.0159,  0.0409, -0.0120,  ..., -0.0484, -0.0080, -0.0467],\n",
       "                      ...,\n",
       "                      [ 0.0133,  0.0077, -0.0423,  ..., -0.0152, -0.0471, -0.0143],\n",
       "                      [ 0.0436, -0.0062, -0.0302,  ...,  0.0425,  0.0464,  0.0113],\n",
       "                      [-0.0441, -0.0358, -0.0231,  ...,  0.0389,  0.0094, -0.0395]])),\n",
       "             ('decoder.layers.5.feed_forward_block.linear_1.bias',\n",
       "              tensor([ 0.0404, -0.0305,  0.0011,  ..., -0.0123, -0.0359,  0.0356])),\n",
       "             ('decoder.layers.5.feed_forward_block.linear_2.weight',\n",
       "              tensor([[ 0.0286, -0.0362, -0.0022,  ...,  0.0299,  0.0419,  0.0389],\n",
       "                      [-0.0327,  0.0078, -0.0174,  ..., -0.0193, -0.0018,  0.0296],\n",
       "                      [ 0.0451, -0.0237, -0.0178,  ..., -0.0335, -0.0408, -0.0162],\n",
       "                      ...,\n",
       "                      [-0.0338, -0.0226, -0.0099,  ..., -0.0374,  0.0332, -0.0003],\n",
       "                      [ 0.0464, -0.0352,  0.0387,  ..., -0.0260, -0.0238,  0.0222],\n",
       "                      [ 0.0296, -0.0364, -0.0391,  ...,  0.0124,  0.0370, -0.0151]])),\n",
       "             ('decoder.layers.5.feed_forward_block.linear_2.bias',\n",
       "              tensor([ 1.0059e-02,  1.1970e-02,  1.2846e-02, -1.0964e-02,  9.0989e-03,\n",
       "                       2.1324e-02,  2.8449e-03, -1.5497e-03, -1.7346e-02,  1.9007e-02,\n",
       "                      -1.5952e-02,  1.3203e-02,  1.9381e-02, -1.6857e-02, -1.9769e-02,\n",
       "                      -6.0490e-03,  1.5942e-03, -2.0003e-02,  1.3907e-02,  1.5037e-03,\n",
       "                      -5.3251e-03, -9.1676e-03,  5.9074e-03, -2.0736e-02,  6.7124e-03,\n",
       "                       5.7735e-03, -1.4196e-02, -2.0550e-02,  1.8737e-02,  1.2733e-02,\n",
       "                       9.3417e-03,  2.0175e-02, -8.0101e-03,  7.3452e-03, -1.7708e-02,\n",
       "                      -5.1826e-04,  2.1843e-02,  5.0156e-03, -1.3991e-02, -6.9903e-03,\n",
       "                       4.0870e-03, -2.1066e-02, -2.6022e-03,  1.9416e-02, -1.9564e-02,\n",
       "                      -6.3330e-03, -5.8706e-03, -7.2354e-03,  4.6005e-03,  1.6410e-02,\n",
       "                      -1.0475e-02, -1.8312e-03, -4.5055e-03,  7.7184e-03, -1.7105e-02,\n",
       "                      -1.4784e-02, -1.2042e-02, -1.2268e-02, -1.4985e-02,  1.2727e-02,\n",
       "                       1.9892e-02, -1.3007e-02, -2.0460e-02,  5.1992e-03,  4.4757e-03,\n",
       "                       9.5547e-03, -4.4843e-03,  1.8132e-02,  3.6192e-03, -5.5775e-03,\n",
       "                      -9.0905e-03,  1.6378e-02, -1.8145e-02, -1.7080e-02,  7.3497e-03,\n",
       "                      -1.6774e-02, -1.0848e-02,  2.1818e-02,  1.1481e-02, -1.7597e-02,\n",
       "                       7.9608e-04, -4.4993e-03, -1.6662e-02,  1.5136e-02,  5.6705e-03,\n",
       "                      -6.2819e-03, -1.1179e-02, -9.6584e-03,  4.6359e-03,  2.0440e-03,\n",
       "                       8.0249e-03, -1.1491e-02,  9.0724e-03,  4.8797e-03,  1.9996e-02,\n",
       "                       2.0735e-03,  1.1362e-02,  1.3787e-02,  1.5440e-02,  1.0036e-02,\n",
       "                      -6.2344e-03, -1.0108e-02, -1.1235e-02, -7.3902e-03,  9.7649e-03,\n",
       "                       2.0100e-02,  6.2009e-03, -2.0659e-02,  2.0134e-02, -1.2863e-02,\n",
       "                      -7.9235e-03,  1.8075e-03,  7.4932e-03,  1.0048e-02,  1.5712e-02,\n",
       "                       1.6926e-02, -8.8848e-03, -1.9730e-02,  1.6545e-04, -2.1019e-02,\n",
       "                       1.8330e-02,  1.7477e-03,  3.8813e-03, -4.8384e-03, -9.7161e-05,\n",
       "                       1.1357e-02, -4.1800e-03, -4.8107e-03, -1.2723e-04, -1.4398e-02,\n",
       "                       1.8456e-02, -1.8987e-03, -1.9150e-04, -4.2810e-03, -2.0564e-02,\n",
       "                      -1.6604e-02,  1.4353e-02,  5.7819e-03, -2.0387e-02, -1.5024e-02,\n",
       "                      -2.5648e-03, -1.1968e-02,  1.6291e-02,  1.5106e-03,  2.9012e-04,\n",
       "                       3.7610e-03,  1.1084e-03, -1.4484e-02, -1.2151e-02,  9.6995e-03,\n",
       "                       1.1680e-02, -9.5409e-03, -7.9591e-03, -9.5939e-03, -1.7492e-02,\n",
       "                      -5.7976e-03, -2.0210e-02,  4.7088e-03,  1.6843e-02, -1.5080e-02,\n",
       "                      -6.3011e-03,  1.2464e-02,  2.1759e-02,  1.3670e-02,  2.9284e-03,\n",
       "                       1.0183e-02,  9.5489e-03,  1.4593e-03,  5.9514e-03, -2.0643e-02,\n",
       "                       1.8686e-02,  1.8742e-02, -3.3584e-03, -1.6510e-02,  1.5766e-02,\n",
       "                       1.0448e-02,  1.4809e-02,  1.2892e-02,  4.9814e-03,  1.7576e-02,\n",
       "                      -2.2025e-02, -8.0771e-03, -1.7268e-02, -6.4857e-03,  6.5095e-03,\n",
       "                       1.5713e-02, -3.1024e-03,  5.2218e-03, -1.0075e-02,  2.0546e-02,\n",
       "                       5.6084e-03,  1.4258e-02,  1.0435e-02,  1.5741e-02,  1.5115e-02,\n",
       "                      -1.5684e-02,  1.4153e-02,  1.2830e-03,  1.1835e-02, -4.0461e-03,\n",
       "                      -1.3451e-02, -1.2268e-02,  5.4037e-03,  1.2286e-02, -1.4500e-02,\n",
       "                       7.3623e-03, -5.7639e-03,  1.5823e-02, -2.0413e-02, -5.8668e-04,\n",
       "                       1.5318e-03, -4.4804e-03, -1.9382e-02, -2.1392e-03,  1.5401e-02,\n",
       "                       1.7375e-02, -4.3029e-03, -1.0647e-02, -6.1082e-03,  1.8869e-02,\n",
       "                      -1.6577e-02, -6.8390e-03, -2.1721e-02, -1.2271e-02, -9.2807e-03,\n",
       "                      -1.7053e-02, -1.8005e-02, -6.1627e-03, -5.4062e-03,  6.4438e-03,\n",
       "                      -3.3017e-03, -7.9736e-04,  1.4611e-02, -1.9504e-02, -1.8558e-02,\n",
       "                      -2.5204e-03,  1.7791e-02, -1.0715e-02, -8.2613e-03,  2.0030e-02,\n",
       "                      -1.5980e-02,  4.9375e-03, -9.7628e-03, -8.4831e-03,  5.8978e-03,\n",
       "                       2.1561e-02, -3.4993e-03, -1.6276e-02, -3.5770e-03,  4.3439e-03,\n",
       "                      -4.7168e-03,  1.9838e-02, -5.4408e-03, -1.2221e-03,  7.2947e-03,\n",
       "                       1.4452e-02, -2.5405e-03, -2.0576e-03,  1.0157e-02, -1.1746e-02,\n",
       "                       1.0987e-03,  1.1382e-02,  1.5374e-02, -4.4667e-03,  4.8880e-03,\n",
       "                       8.4039e-03, -7.1881e-03,  6.2645e-03, -1.3490e-02, -1.8617e-02,\n",
       "                       1.9837e-02,  8.9612e-03,  7.1850e-03,  5.6374e-03,  1.2439e-02,\n",
       "                      -1.0047e-02,  4.3874e-03, -1.2597e-02,  1.5557e-02, -2.8451e-03,\n",
       "                      -2.8482e-03,  6.3242e-03,  1.9721e-03, -7.4789e-03, -2.0566e-02,\n",
       "                       1.6937e-02, -1.3091e-02,  1.0272e-02,  7.4366e-04, -1.9516e-02,\n",
       "                      -4.3331e-03,  1.9071e-02,  8.4224e-03, -2.9372e-03, -6.7463e-03,\n",
       "                      -1.2122e-02, -1.2681e-02,  1.5797e-02,  1.1788e-02,  1.9148e-02,\n",
       "                      -1.5038e-02,  1.6023e-03,  2.2083e-02, -2.8261e-03, -6.3997e-03,\n",
       "                       2.1635e-02, -2.4395e-03, -1.6360e-02,  7.7539e-03, -7.3199e-03,\n",
       "                       1.3631e-02,  7.4058e-03,  2.4872e-03,  3.6918e-03,  1.7181e-02,\n",
       "                       1.3234e-02,  3.3388e-03, -1.6461e-02,  7.0895e-03, -1.3194e-02,\n",
       "                      -1.4087e-02, -2.1846e-02, -1.6237e-02, -8.8111e-03, -1.6891e-02,\n",
       "                      -1.8666e-02, -2.1184e-03, -1.6191e-02, -5.6972e-03, -4.5594e-03,\n",
       "                       1.1181e-02,  1.8997e-02, -1.8602e-02,  2.6406e-03,  5.6810e-04,\n",
       "                      -2.0686e-02,  1.8988e-02,  2.1719e-02,  9.1001e-04,  2.3658e-03,\n",
       "                      -1.6175e-02,  1.4566e-02,  2.1939e-02,  2.4064e-03, -5.2262e-05,\n",
       "                      -1.2249e-02, -1.4253e-02,  2.3203e-03,  6.0934e-03, -9.5738e-03,\n",
       "                       7.0676e-03, -1.4322e-02,  1.8682e-02, -8.0138e-03, -1.5893e-02,\n",
       "                       8.7885e-03,  5.5481e-03, -6.9615e-03,  2.1953e-03, -1.2496e-02,\n",
       "                       2.7272e-03,  1.5014e-02,  1.0972e-02, -6.7784e-04,  1.1633e-02,\n",
       "                      -1.5315e-02,  5.8931e-03,  7.8615e-03,  6.7399e-03, -7.0999e-03,\n",
       "                       1.7337e-02,  2.1181e-02, -1.5103e-02,  1.2034e-02, -4.4920e-03,\n",
       "                      -1.3972e-02, -4.5360e-03,  7.9125e-03,  1.3750e-03, -5.1234e-03,\n",
       "                      -2.0381e-02,  1.8392e-02,  1.6539e-02, -1.4260e-02,  2.1821e-02,\n",
       "                      -3.0755e-03,  1.3330e-02,  2.8276e-03,  2.0623e-02, -2.1359e-02,\n",
       "                       1.4537e-02,  1.3536e-02, -9.8147e-03, -1.4999e-02, -1.9482e-03,\n",
       "                      -1.5778e-02,  2.1988e-02, -8.8187e-03, -9.0748e-05, -2.0001e-02,\n",
       "                      -1.1538e-02,  1.8913e-02, -2.4635e-03,  5.8577e-03, -1.3761e-02,\n",
       "                      -2.1630e-02, -9.0483e-03,  1.2473e-03, -1.0484e-02, -2.8502e-03,\n",
       "                      -1.6561e-02, -1.0869e-02,  3.9569e-03,  1.8815e-03, -6.7734e-03,\n",
       "                      -1.2870e-02,  1.4502e-03,  1.4991e-02, -1.6446e-02, -2.0404e-02,\n",
       "                       3.1808e-03, -1.9066e-02,  2.0060e-02, -2.5878e-04,  2.1332e-02,\n",
       "                      -2.1098e-02, -1.7617e-02,  2.1992e-02, -1.5971e-02, -1.7770e-02,\n",
       "                       1.2981e-02, -4.5434e-03, -1.7413e-02,  2.0962e-02, -5.3514e-03,\n",
       "                       7.4693e-03,  2.1534e-03, -1.5819e-02, -1.2327e-03, -8.7349e-03,\n",
       "                       3.7298e-03, -1.1752e-02,  2.0938e-02,  1.0572e-02, -1.4366e-03,\n",
       "                      -1.8387e-02, -9.5183e-03,  1.7924e-02, -2.9026e-03,  2.1707e-03,\n",
       "                       4.7530e-03,  7.0598e-03, -1.9143e-02, -1.9087e-02, -1.0947e-02,\n",
       "                      -1.4791e-02, -1.4909e-02, -1.7607e-02, -4.8437e-03,  7.3461e-03,\n",
       "                       2.3850e-03,  1.9697e-02,  2.3342e-03, -2.7820e-03, -1.7952e-02,\n",
       "                      -1.5423e-02,  5.4450e-03,  9.4778e-03,  1.4915e-02, -9.6930e-03,\n",
       "                       8.7543e-03, -1.2569e-02, -5.4373e-03, -3.0924e-03, -8.5196e-03,\n",
       "                       4.6471e-03, -1.2400e-03, -1.3878e-02, -5.7433e-03, -1.7397e-02,\n",
       "                      -2.5882e-03,  1.4994e-02,  1.8443e-02, -1.8569e-02,  1.7062e-02,\n",
       "                       1.6827e-02, -1.3415e-02, -1.4163e-02,  1.5991e-02, -9.9487e-03,\n",
       "                       2.1748e-03,  1.4793e-02,  6.1971e-03,  1.4100e-02,  1.7817e-02,\n",
       "                      -1.6202e-02, -1.4633e-02,  6.6313e-03,  1.4395e-02,  1.9784e-02,\n",
       "                      -1.8883e-03,  1.6009e-02, -1.9302e-03,  1.8687e-02, -3.7537e-03,\n",
       "                      -1.9515e-02,  2.2016e-02, -1.7038e-02,  1.5909e-02,  1.3638e-02,\n",
       "                      -5.5982e-03,  1.8688e-02])),\n",
       "             ('decoder.layers.5.residual_connections.0.norm.alpha',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('decoder.layers.5.residual_connections.0.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('decoder.layers.5.residual_connections.1.norm.alpha',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('decoder.layers.5.residual_connections.1.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('decoder.layers.5.residual_connections.2.norm.alpha',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('decoder.layers.5.residual_connections.2.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('decoder.norm.alpha',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('decoder.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('src_embed.embedding.weight',\n",
       "              tensor([[-3.5880e-04,  1.2599e-02,  1.0324e-02,  ...,  4.9835e-03,\n",
       "                        5.0834e-03,  7.1437e-03],\n",
       "                      [-2.4516e-03, -3.7846e-03,  1.2520e-02,  ..., -1.3764e-02,\n",
       "                       -2.2653e-03,  1.0083e-02],\n",
       "                      [ 6.6463e-03,  3.4395e-03, -1.1844e-02,  ..., -1.3460e-02,\n",
       "                       -4.8171e-03, -2.2525e-03],\n",
       "                      ...,\n",
       "                      [ 5.3808e-03,  8.1845e-03, -6.8959e-03,  ...,  4.3037e-03,\n",
       "                        4.8464e-03,  1.2436e-02],\n",
       "                      [-1.1730e-02,  5.4905e-03,  1.0679e-05,  ...,  1.0345e-02,\n",
       "                       -1.2414e-02,  1.5449e-03],\n",
       "                      [-1.1855e-02, -9.3801e-03,  1.1782e-02,  ..., -2.6479e-03,\n",
       "                        6.7129e-03, -1.5868e-03]])),\n",
       "             ('tgt_embed.embedding.weight',\n",
       "              tensor([[-0.0041,  0.0012,  0.0007,  ...,  0.0121, -0.0123, -0.0041],\n",
       "                      [-0.0112,  0.0068,  0.0122,  ...,  0.0026, -0.0108,  0.0088],\n",
       "                      [ 0.0113,  0.0056, -0.0045,  ..., -0.0135,  0.0127,  0.0124],\n",
       "                      ...,\n",
       "                      [ 0.0040,  0.0030,  0.0058,  ...,  0.0122, -0.0138,  0.0079],\n",
       "                      [-0.0053, -0.0114,  0.0114,  ...,  0.0044,  0.0031,  0.0072],\n",
       "                      [-0.0011,  0.0067,  0.0028,  ...,  0.0017, -0.0112,  0.0114]])),\n",
       "             ('src_pos.pe',\n",
       "              tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
       "                         0.0000e+00,  1.0000e+00],\n",
       "                       [ 8.4147e-01,  5.4030e-01,  8.2186e-01,  ...,  1.0000e+00,\n",
       "                         1.0366e-04,  1.0000e+00],\n",
       "                       [ 9.0930e-01, -4.1615e-01,  9.3641e-01,  ...,  1.0000e+00,\n",
       "                         2.0733e-04,  1.0000e+00],\n",
       "                       ...,\n",
       "                       [ 9.8936e-01,  1.4547e-01,  9.8755e-01,  ...,  9.9930e-01,\n",
       "                         3.5963e-02,  9.9935e-01],\n",
       "                       [ 6.5696e-01, -7.5392e-01,  4.3332e-01,  ...,  9.9930e-01,\n",
       "                         3.6067e-02,  9.9935e-01],\n",
       "                       [-2.7944e-01, -9.6016e-01, -4.9383e-01,  ...,  9.9930e-01,\n",
       "                         3.6171e-02,  9.9935e-01]]])),\n",
       "             ('tgt_pos.pe',\n",
       "              tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
       "                         0.0000e+00,  1.0000e+00],\n",
       "                       [ 8.4147e-01,  5.4030e-01,  8.2186e-01,  ...,  1.0000e+00,\n",
       "                         1.0366e-04,  1.0000e+00],\n",
       "                       [ 9.0930e-01, -4.1615e-01,  9.3641e-01,  ...,  1.0000e+00,\n",
       "                         2.0733e-04,  1.0000e+00],\n",
       "                       ...,\n",
       "                       [ 9.8936e-01,  1.4547e-01,  9.8755e-01,  ...,  9.9930e-01,\n",
       "                         3.5963e-02,  9.9935e-01],\n",
       "                       [ 6.5696e-01, -7.5392e-01,  4.3332e-01,  ...,  9.9930e-01,\n",
       "                         3.6067e-02,  9.9935e-01],\n",
       "                       [-2.7944e-01, -9.6016e-01, -4.9383e-01,  ...,  9.9930e-01,\n",
       "                         3.6171e-02,  9.9935e-01]]])),\n",
       "             ('projection_layer.proj.weight',\n",
       "              tensor([[ 0.0128,  0.0095, -0.0138,  ..., -0.0123,  0.0005,  0.0117],\n",
       "                      [-0.0055,  0.0048, -0.0078,  ..., -0.0138, -0.0034,  0.0133],\n",
       "                      [ 0.0004, -0.0064,  0.0041,  ...,  0.0064, -0.0139, -0.0094],\n",
       "                      ...,\n",
       "                      [ 0.0056, -0.0085,  0.0002,  ..., -0.0032,  0.0013,  0.0004],\n",
       "                      [-0.0140,  0.0017, -0.0002,  ...,  0.0039,  0.0017,  0.0116],\n",
       "                      [-0.0013,  0.0138,  0.0007,  ..., -0.0124, -0.0085,  0.0034]])),\n",
       "             ('projection_layer.proj.bias',\n",
       "              tensor([ 0.0043, -0.0024, -0.0170,  ...,  0.0048, -0.0235, -0.0363]))])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142e75b3",
   "metadata": {},
   "source": [
    "## .encode() - ENCODER OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "54c959c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0758, -0.3183,  0.3030,  ...,  0.9124, -0.7326,  0.5934],\n",
       "         [-0.6861, -1.5884,  1.5389,  ...,  1.4303, -0.6450, -0.4349],\n",
       "         [ 0.3746, -0.9457,  1.3289,  ...,  0.5405, -1.2694, -0.7005],\n",
       "         ...,\n",
       "         [ 0.1409, -1.2523,  1.0696,  ...,  1.6832, -0.8411, -0.4607],\n",
       "         [ 0.0254, -2.2847,  1.1141,  ...,  1.2877, -0.9019, -0.2405],\n",
       "         [-0.2786, -1.8332,  1.0711,  ...,  0.9532, -0.9232,  0.9248]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_output = model.encode(\n",
    "    src = encoder_input,\n",
    "    src_mask = encoder_mask\n",
    ")\n",
    "\n",
    "encoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2238e156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 350, 512])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f333c4d",
   "metadata": {},
   "source": [
    "## .decode() - DECODER OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "43eb1a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9673, -0.0945,  0.6777,  ...,  0.1936,  0.0362,  1.3110],\n",
       "         [-0.0672, -0.7670,  0.2378,  ...,  1.0070, -0.0686,  0.5025],\n",
       "         [-0.7922,  0.1111,  0.2079,  ...,  1.1729, -0.3677,  0.8631],\n",
       "         ...,\n",
       "         [-0.4691, -0.4147,  1.2252,  ...,  0.4172,  1.0044,  1.3540],\n",
       "         [-0.3436, -0.7128,  0.1191,  ..., -0.0695,  0.2840,  1.1487],\n",
       "         [-1.4476, -1.1025,  0.7166,  ...,  0.5140,  0.6403,  0.3491]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output = model.decode(\n",
    "    encoder_output = encoder_output,\n",
    "    src_mask = encoder_mask,\n",
    "    tgt = decoder_input,\n",
    "    tgt_mask = decoder_mask\n",
    ")\n",
    "\n",
    "decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2170bfa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 350, 512])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b182f6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output[:, -1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0690f6c2",
   "metadata": {},
   "source": [
    "## .project()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d66c135",
   "metadata": {},
   "source": [
    "### for ALL **TOKENS** IN SEQUENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "db1a4d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2369,  0.1613,  0.3271,  ...,  0.3588,  0.1631,  0.1601],\n",
       "         [ 0.3664,  0.0593,  0.0747,  ...,  0.2508,  0.2975,  0.1092],\n",
       "         [ 0.1905,  0.1513,  0.1399,  ...,  0.3924,  0.1827,  0.0325],\n",
       "         ...,\n",
       "         [ 0.2921,  0.0548,  0.0913,  ...,  0.3638,  0.0856,  0.0445],\n",
       "         [ 0.3252, -0.0749,  0.0987,  ...,  0.3251,  0.0161,  0.1077],\n",
       "         [ 0.1845, -0.0841,  0.0419,  ...,  0.3121, -0.0399,  0.0511]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = model.project(\n",
    "    x = decoder_output\n",
    ")\n",
    "\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9e024c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 350, 30000])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape # Each TOKEN in the SEQUENCE has a LOGIT DISTRIBUTION over the ENTIRE VOCABULARY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c9e49c",
   "metadata": {},
   "source": [
    "### for LAST **TOKEN** IN SEQUENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "cc61a10d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1845, -0.0841,  0.0419,  ...,  0.3121, -0.0399,  0.0511]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_token_logits = model.project(\n",
    "    x = decoder_output[:, -1]\n",
    ")\n",
    "\n",
    "last_token_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cf7416d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 30000])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_token_logits.shape # The LOGIT DISTRIBUTION of the LAST TOKEN in the SEQUENCE over the ENTIRE VOCABULARY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f919aa",
   "metadata": {},
   "source": [
    "# **greedy_decode()**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceb9490",
   "metadata": {},
   "source": [
    "- The implementation automatically does a `model.project()` on the **LAST TOKEN** only, then it iterates until seq_len is exhausted or until [EOS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "854d458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train import greedy_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "945da893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    2,  3706,  7505,  7505, 19551, 22777, 22579, 10684, 23033, 19551,\n",
       "          305, 22777, 17437, 17437, 27867, 19551, 27867, 19551, 27867,  7748,\n",
       "        22777, 27867, 27867, 16430, 23122, 19551,   350,  8665,   350, 19551,\n",
       "        17437, 17437,  4111, 19551, 22777, 17437, 19551, 19551, 19551, 27867,\n",
       "        19551, 27867, 22777, 22777, 19551, 23027, 19551, 17437, 19551, 19551,\n",
       "        27867,  7505, 17437, 19551, 22777, 19551, 19551, 22777, 19551, 22777,\n",
       "        27867, 22777, 23343, 23343,   350, 27867, 17437, 19551, 22777, 27867,\n",
       "        23033,  7505, 27867, 19551, 19551,   278, 19551, 27867, 19551, 19551,\n",
       "        19551, 20713, 19551,  7505, 19551, 11674, 27867, 17437, 22777, 19551,\n",
       "          350, 17437, 19551, 17437, 23343, 19551,  8656, 19551,  7505, 19551,\n",
       "        19551, 19551,   278, 23033, 22777, 17437, 22777, 23343, 17499, 27619,\n",
       "          350,   350, 17437, 27867, 19551, 17437,   278,   350, 19551, 23343,\n",
       "        23343,   350, 19551, 17437,   278,   278,  7505, 23343,   278, 19551,\n",
       "        27867,   350, 24815, 17437,   278,  4111, 18525,   278, 23343, 23343,\n",
       "        11556, 29325, 23343,   278, 17437, 29325, 23343, 29325, 23343, 23343,\n",
       "        17437, 27867,  2399, 23343, 17437, 23343, 23343, 27867, 23343, 21335,\n",
       "        27867, 27619, 21335, 23343, 13236,   350, 21476, 27867, 19551, 27867,\n",
       "        19551, 19551,  1827, 19551,   278, 23343, 19551,   278, 13872,  1827,\n",
       "         7505, 27867, 23033, 27867, 19551, 13872, 27056, 13872, 19551, 19551,\n",
       "        19551, 19551, 19551, 19551, 23033, 19551, 27867, 23033, 23033, 23033,\n",
       "          350, 27867, 29325, 23343, 27867, 19551, 23033, 13058,   278, 27867,\n",
       "        13872,  8951, 19551, 19551, 17437, 27867,   278,   350,   278, 19551,\n",
       "        23343, 19551, 19551,   278, 17937, 19551, 27867, 19551,   350, 27867,\n",
       "         1241, 23343, 13872, 21476, 27867, 17437, 17437,  1241, 23343, 19551,\n",
       "        29325,  8951, 21476, 19551, 11556,   278, 23343, 17623, 19551, 19551,\n",
       "        19551, 19551, 29325,  1827,  1241, 19551, 19551, 23033,   278, 19551,\n",
       "        29325, 27867, 17437, 13872, 19551, 23343, 19551, 17437, 19551, 23033,\n",
       "        19551, 17437,  4262,  6848,  2991, 23343, 21476, 19551, 19551, 27867,\n",
       "        19551, 23343, 10684, 23033, 27867,  4111, 19551,  1827,  6795, 11556,\n",
       "        19551, 23343, 17437, 23343,  7404, 23343, 21476, 23343, 27867, 19551,\n",
       "        19551, 17437, 29325, 17437, 17437, 27867,   350, 19551, 19551, 23343,\n",
       "        29325, 23343, 23343, 19551, 23343, 19551,  1827, 19551, 19551, 19551,\n",
       "        19551, 23343, 19551, 19548, 17437, 27867, 29325, 27619, 27867, 13872,\n",
       "        17437, 19551, 23343, 23343, 23343, 27867, 23343, 19548,  7404, 17653,\n",
       "        18525, 13872,   278, 26204,   278,  7505,   278, 25944, 29325, 11556])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_out = greedy_decode(\n",
    "    model = model, \n",
    "    source = encoder_input, \n",
    "    source_mask = (encoder_input != pad_token).unsqueeze(0).unsqueeze(0).int(), \n",
    "    tokenizer_src = eng_fil_src_tokenizer, \n",
    "    max_len = config[\"seq_len\"], \n",
    "    device = device\n",
    "    )\n",
    "\n",
    "model_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "85548a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([350])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "78162872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[SOS] pinakamahalaga BY BY interval Copper }.\") kalabang Marahan interval klima Copper Mood Mood bismuth interval bismuth interval bismuth da Copper bismuth bismuth pagkapira Owen interval print 1991 print interval Mood Mood inilarawan interval Copper Mood interval interval interval bismuth interval bismuth Copper Copper interval Mall interval Mood interval interval bismuth BY Mood interval Copper interval interval Copper interval Copper bismuth Copper X5 X5 print bismuth Mood interval Copper bismuth Marahan BY bismuth interval interval of interval bismuth interval interval interval islang interval BY interval iikot bismuth Mood Copper interval print Mood interval Mood X5 interval tutuklasin interval BY interval interval interval of Marahan Copper Mood Copper X5 Raphael Sulitin print print Mood bismuth interval Mood of print interval X5 X5 print interval Mood of of BY X5 of interval bismuth print Kinakabahan Mood of inilarawan imaheng of X5 X5 Congo 024 X5 of Mood 024 X5 024 X5 X5 Mood bismuth sign X5 Mood X5 X5 bismuth X5 Depensa bismuth Sulitin Depensa X5 Tumutugon print Konseho bismuth interval bismuth interval interval kasamahan interval of X5 interval of takutin kasamahan BY bismuth Marahan bismuth interval takutin Iniuugnay takutin interval interval interval interval interval interval Marahan interval bismuth Marahan Marahan Marahan print bismuth 024 X5 bismuth interval Marahan resistensya of bismuth takutin transfer interval interval Mood bismuth of print of interval X5 interval interval of silicone interval bismuth interval print bismuth address X5 takutin Konseho bismuth Mood Mood address X5 interval 024 transfer Konseho interval Congo of X5 delegasyon interval interval interval interval 024 kasamahan address interval interval Marahan of interval 024 bismuth Mood takutin interval X5 interval Mood interval Marahan interval Mood Ibalik S20 direkta X5 Konseho interval interval bismuth interval X5 kalabang Marahan bismuth inilarawan interval kasamahan matindi Congo interval X5 Mood X5 outlet X5 Konseho X5 bismuth interval interval Mood 024 Mood Mood bismuth print interval interval X5 024 X5 X5 interval X5 interval kasamahan interval interval interval interval X5 interval integrated Mood bismuth 024 Sulitin bismuth takutin Mood interval X5 X5 X5 bismuth X5 integrated outlet fee imaheng takutin of promoter of BY of nagmamartsa 024 Congo'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([eng_fil_tgt_tokenizer.id_to_token(id = id) for id in model_out])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b5edad",
   "metadata": {},
   "source": [
    "# **Under the hood**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee967b1",
   "metadata": {},
   "source": [
    "## *Loss Computation*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a37e531",
   "metadata": {},
   "source": [
    "### **using nn.CrossEntropyLoss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac96bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(\n",
    "    ignore_index = eng_fil_src_tokenizer.token_to_id('[PAD]'), \n",
    "    label_smoothing = 0.1\n",
    ").to(\"cpu\")\n",
    "\n",
    "loss = loss_fn(\n",
    "    logits.view(-1, eng_fil_tgt_tokenizer.get_vocab_size()), \n",
    "    label.view(-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "56bc15f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.314189910888672"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e19b60",
   "metadata": {},
   "source": [
    "### **manual computation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8c1626ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2369,  0.1613,  0.3271,  ...,  0.3588,  0.1631,  0.1601],\n",
       "        [ 0.3664,  0.0593,  0.0747,  ...,  0.2508,  0.2975,  0.1092],\n",
       "        [ 0.1905,  0.1513,  0.1399,  ...,  0.3924,  0.1827,  0.0325],\n",
       "        ...,\n",
       "        [ 0.2921,  0.0548,  0.0913,  ...,  0.3638,  0.0856,  0.0445],\n",
       "        [ 0.3252, -0.0749,  0.0987,  ...,  0.3251,  0.0161,  0.1077],\n",
       "        [ 0.1845, -0.0841,  0.0419,  ...,  0.3121, -0.0399,  0.0511]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = logits.view(-1, eng_fil_tgt_tokenizer.get_vocab_size())\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945e1a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(52.3431, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[0].sum() # NOT NORMALIZED YET (as you can see, it sums up to a value greater than 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b9b10051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([350, 30000])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "08e87b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 260,   27,  256,    9, 1028,   66,   27, 4868,  100,    5, 4662, 5827,\n",
       "           7,    3,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = label.view(-1)\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "424d3159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([350])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b01d1de",
   "metadata": {},
   "source": [
    "`logsumexp` is just a **numerically safe way to compute the log of a sum of exponentials**.\n",
    "Without it, `-log P(y)` could **produce NaN or infinity** when logits are extreme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0373f7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-10.0909, -10.1666, -10.0007,  ...,  -9.9691, -10.1648, -10.1678],\n",
       "        [ -9.9609, -10.2680, -10.2527,  ..., -10.0766, -10.0299, -10.2181],\n",
       "        [-10.1372, -10.1764, -10.1878,  ...,  -9.9353, -10.1450, -10.2952],\n",
       "        ...,\n",
       "        [-10.0355, -10.2728, -10.2363,  ...,  -9.9637, -10.2420, -10.2830],\n",
       "        [-10.0016, -10.4017, -10.2280,  ..., -10.0017, -10.3107, -10.2190],\n",
       "        [-10.1421, -10.4107, -10.2847,  ..., -10.0145, -10.3665, -10.2755]],\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs = logits - torch.logsumexp(\n",
    "    input = logits, \n",
    "    dim = 1, \n",
    "    keepdim = True\n",
    ")\n",
    "log_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb701c97",
   "metadata": {},
   "source": [
    "Below is an example **NLL for the first token**. In our label, the `first token ID is 260`. The `logit value at index 260 in our log_probs` is below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "cf72cc98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.2334, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-log_probs[0][label[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2255f677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.2334, 10.3615, 10.2833, 10.1227, 10.3003, 10.4964, 10.2619, 10.2890,\n",
       "        10.3175, 10.5633, 10.3826, 10.2347, 10.2309, 10.3024, 10.3959, 10.4434,\n",
       "        10.3197, 10.3117, 10.3370, 10.2984, 10.3610, 10.4037, 10.2462, 10.2552,\n",
       "        10.2944, 10.2070, 10.2536, 10.2641, 10.3730, 10.2049, 10.2859, 10.3144,\n",
       "        10.2656, 10.2819, 10.2502, 10.1917, 10.5005, 10.2869, 10.2201, 10.4284,\n",
       "        10.3427, 10.3197, 10.3268, 10.2733, 10.2677, 10.3346, 10.2214, 10.2879,\n",
       "        10.2437, 10.3900, 10.1785, 10.3268, 10.3402, 10.3226, 10.3618, 10.3310,\n",
       "        10.2656, 10.3106, 10.2731, 10.3660, 10.3764, 10.3134, 10.3557, 10.3655,\n",
       "        10.2149, 10.3494, 10.2377, 10.3049, 10.3589, 10.3067, 10.1892, 10.2299,\n",
       "        10.3181, 10.2342, 10.3269, 10.2758, 10.3814, 10.2784, 10.1803, 10.2245,\n",
       "        10.2657, 10.3129, 10.2153, 10.2563, 10.3401, 10.2674, 10.3708, 10.2818,\n",
       "        10.4569, 10.3924, 10.3834, 10.3933, 10.2323, 10.4948, 10.3923, 10.2771,\n",
       "        10.2906, 10.3362, 10.3844, 10.4442, 10.4234, 10.2501, 10.3132, 10.2504,\n",
       "        10.3205, 10.3096, 10.4530, 10.2883, 10.3457, 10.3564, 10.3012, 10.2730,\n",
       "        10.3509, 10.3380, 10.2900, 10.3199, 10.2412, 10.2358, 10.3117, 10.3206,\n",
       "        10.4090, 10.3051, 10.2967, 10.3871, 10.2460, 10.2284, 10.3823, 10.3766,\n",
       "        10.3227, 10.3599, 10.3363, 10.3189, 10.3628, 10.3959, 10.3543, 10.3564,\n",
       "        10.3311, 10.2797, 10.3719, 10.2969, 10.1645, 10.2244, 10.2071, 10.3926,\n",
       "        10.1201, 10.2726, 10.2987, 10.2931, 10.3397, 10.3936, 10.2863, 10.3348,\n",
       "        10.3091, 10.2906, 10.3114, 10.2481, 10.3321, 10.3074, 10.3159, 10.2670,\n",
       "        10.3918, 10.2841, 10.4536, 10.3738, 10.3259, 10.4339, 10.4009, 10.2622,\n",
       "        10.3331, 10.4146, 10.4382, 10.3235, 10.3432, 10.2552, 10.2674, 10.2276,\n",
       "        10.2747, 10.3520, 10.2669, 10.2643, 10.2741, 10.1906, 10.2496, 10.1114,\n",
       "        10.3656, 10.2674, 10.2765, 10.2540, 10.4285, 10.3593, 10.2711, 10.2484,\n",
       "        10.2472, 10.4173, 10.3009, 10.2592, 10.2720, 10.1865, 10.2566, 10.3136,\n",
       "        10.3595, 10.3438, 10.4227, 10.3363, 10.3476, 10.2895, 10.3120, 10.2271,\n",
       "        10.4193, 10.3181, 10.3633, 10.3778, 10.3063, 10.2549, 10.2338, 10.3057,\n",
       "        10.3569, 10.4315, 10.3877, 10.4540, 10.4561, 10.4691, 10.3680, 10.3525,\n",
       "        10.3538, 10.4949, 10.3845, 10.3173, 10.3824, 10.3399, 10.3548, 10.2971,\n",
       "        10.3704, 10.3116, 10.2296, 10.2624, 10.2815, 10.3120, 10.2905, 10.3295,\n",
       "        10.3153, 10.2733, 10.2111, 10.3768, 10.3837, 10.3290, 10.3843, 10.3829,\n",
       "        10.1094, 10.4004, 10.4291, 10.3276, 10.3783, 10.3637, 10.2959, 10.2762,\n",
       "        10.2763, 10.3431, 10.3911, 10.4101, 10.1852, 10.3425, 10.2309, 10.3472,\n",
       "        10.2643, 10.3487, 10.2237, 10.2242, 10.2825, 10.1428, 10.3645, 10.3292,\n",
       "        10.2523, 10.2454, 10.1984, 10.3331, 10.3175, 10.2907, 10.1751, 10.2537,\n",
       "        10.3536, 10.3368, 10.3221, 10.4656, 10.3015, 10.3255, 10.3076, 10.3131,\n",
       "        10.3351, 10.2204, 10.3266, 10.3914, 10.2790, 10.2177, 10.3438, 10.4015,\n",
       "        10.3931, 10.3095, 10.4284, 10.2532, 10.3547, 10.4543, 10.3473, 10.4349,\n",
       "        10.4233, 10.3841, 10.3330, 10.4360, 10.3379, 10.2451, 10.2449, 10.2084,\n",
       "        10.2368, 10.2766, 10.2962, 10.3626, 10.2136, 10.2471, 10.2470, 10.3903,\n",
       "        10.2626, 10.3613, 10.2472, 10.3750, 10.3720, 10.2379, 10.3237, 10.3500,\n",
       "        10.3714, 10.4295, 10.3942, 10.3904, 10.4749, 10.3213, 10.3925, 10.3578,\n",
       "        10.3677, 10.4034, 10.4098, 10.3544, 10.3857, 10.3417, 10.4146, 10.2171,\n",
       "        10.2781, 10.4636, 10.3365, 10.2728, 10.4017, 10.4107],\n",
       "       grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_losses = -log_probs[torch.arange(350), label]\n",
    "token_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "30450b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.3190, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = token_losses.mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ad48e0",
   "metadata": {},
   "source": [
    "## *Decoding*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e53b0bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "probability, next_word = torch.max(last_token_logits, \n",
    "                                   dim = 1,\n",
    "                                   keepdim = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3ee24b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([278])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c1d3f124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8016], grad_fn=<MaxBackward0>)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c64f6aa",
   "metadata": {},
   "source": [
    "## *MultiHeadAttentionBlock*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62935c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([[1.0, 0.2],\n",
    "                  [0.8, 0.5],\n",
    "                  [0.1, 0.9]],\n",
    "                  dtype = torch.float64,\n",
    "                  requires_grad = False)\n",
    "\n",
    "q, k, v = x, x, x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951fc871",
   "metadata": {},
   "source": [
    "### **Create MASK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9affa638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 1, 1]], dtype=torch.int32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = 3\n",
    "\n",
    "mask = torch.tril(torch.ones((T, T), dtype = torch.int64)).type(torch.int)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7cb70198",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import MultiHeadAttentionBlock\n",
    "\n",
    "masked_attention_output, masked_attention_weights = multihead_attention = MultiHeadAttentionBlock(\n",
    "    d_model = 2,\n",
    "    h = 2,\n",
    "    dropout = 0.0\n",
    ").attention(\n",
    "    query = q,\n",
    "    key = k,\n",
    "    value = v,\n",
    "    mask = mask,\n",
    "    dropout = nn.Dropout(0.0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7759ade",
   "metadata": {},
   "source": [
    "### **MASKED ATTENTION WEIGHTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "493d3f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000],\n",
       "        [0.5018, 0.4982, 0.0000],\n",
       "        [0.2733, 0.3262, 0.4004]], dtype=torch.float64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0083583",
   "metadata": {},
   "source": [
    "### **MASKED ATTENTION OUTPUT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "366cc5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.2000],\n",
       "        [0.9004, 0.3495],\n",
       "        [0.5744, 0.5782]], dtype=torch.float64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_attention_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50f0215",
   "metadata": {},
   "source": [
    "# **Math behind SELF-ATTENTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace7bcb7",
   "metadata": {},
   "source": [
    "- `Setup:` A sentence with 3 tokens `T = 3`, where each token is a 2D vector (2-dimensional vector) `C = 2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcd664e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([[1.0, 0.2],\n",
    "                  [0.8, 0.5],\n",
    "                  [0.1, 0.9]],\n",
    "                  dtype = torch.float64,\n",
    "                  requires_grad = False)\n",
    "\n",
    "q, k, v = x, x, x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68791207",
   "metadata": {},
   "source": [
    "### **UNSCALED ATTENTION SCORES - Q @ Ktransposed**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000d1e61",
   "metadata": {},
   "source": [
    "- At this point, the values are not normalized yet which means they are not percentages yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bb30bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0400, 0.9000, 0.2800],\n",
       "        [0.9000, 0.8900, 0.5300],\n",
       "        [0.2800, 0.5300, 0.8200]], dtype=torch.float64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unscaled_attention_scores = torch.matmul(q, k.T)\n",
    "unscaled_attention_scores "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bc9ff4",
   "metadata": {},
   "source": [
    "### **SCALED ATTENTION SCORES - Q @ Ktransposed / sqrt(d_k)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7061a2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7354, 0.6364, 0.1980],\n",
       "        [0.6364, 0.6293, 0.3748],\n",
       "        [0.1980, 0.3748, 0.5798]], dtype=torch.float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "d_k = k.size(-1)\n",
    "\n",
    "scaled_attention_scores = unscaled_attention_scores / math.sqrt(d_k)\n",
    "scaled_attention_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac87330",
   "metadata": {},
   "source": [
    "### **ATTENTION WEIGHTS - Softmax((Q @ Ktransposed) / sqrt(d_k))**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f253dd0",
   "metadata": {},
   "source": [
    "- `Attention Weights` is just a term for the normalized scaled attention scores. At this point, the values are now percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba6167ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4016, 0.3638, 0.2346],\n",
       "        [0.3620, 0.3594, 0.2786],\n",
       "        [0.2733, 0.3262, 0.4004]], dtype=torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "attention_weights = F.softmax(scaled_attention_scores, dim = -1)\n",
    "attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278febee",
   "metadata": {},
   "source": [
    "Each row now sums up to 1. For example, ***for Token 2 (row 1)***, it has decided to pay `36.2% attention` to *Token 1*, `35.9% attention` to *itself (Token 2)*, and `27.8%` to *Token 3*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7946c7e",
   "metadata": {},
   "source": [
    "### **ATTENTION OUTPUT - (Softmax((Q @ Ktransposed) / sqrt(d_k))) * V**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089e559c",
   "metadata": {},
   "source": [
    "- At this point, we are now updating the `V` vector using the weights we have obtained. Notice below how the values were updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05cd8a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7161, 0.4734],\n",
       "        [0.6773, 0.5029],\n",
       "        [0.5744, 0.5782]], dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_output = torch.matmul(attention_weights, v)\n",
    "attention_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6757f000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.2000],\n",
       "        [0.8000, 0.5000],\n",
       "        [0.1000, 0.9000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d71e78",
   "metadata": {},
   "source": [
    "### **Create MASK TENSOR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b1829c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0],\n",
       "        [1, 1, 0],\n",
       "        [1, 1, 1]], dtype=torch.int32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = 3\n",
    "\n",
    "mask = torch.tril(torch.ones((T, T), dtype = torch.int64)).type(torch.int)\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd83a8db",
   "metadata": {},
   "source": [
    "### **MASKED SCALED ATTENTION SCORES**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce16f56",
   "metadata": {},
   "source": [
    "- By masking the `scaled attention scores` into `-inf` before softmax, we are preventing the cheat of looking at future tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f6b2a766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7354,   -inf,   -inf],\n",
       "        [0.6364, 0.6293,   -inf],\n",
       "        [0.1980, 0.3748, 0.5798]], dtype=torch.float64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_scaled_attention_scores = scaled_attention_scores.masked_fill(\n",
    "    mask == 0, \n",
    "    float('-inf')\n",
    ")\n",
    "\n",
    "masked_scaled_attention_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4de5e9b",
   "metadata": {},
   "source": [
    "### **MASKED ATTENTION WEIGHTS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf62e310",
   "metadata": {},
   "source": [
    "- Better known as `Causal Weights` is just a term used for masked attention weights were **future tokens**, **past tokens** or **pad tokens** are 0 due to applying softmax to `-inf` values\n",
    "- E.g. for the second row, it is only able to see for Tokens 1 to 2 and not to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a9fc6df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000],\n",
       "        [0.5018, 0.4982, 0.0000],\n",
       "        [0.2733, 0.3262, 0.4004]], dtype=torch.float64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_attention_weights = F.softmax(masked_scaled_attention_scores, dim = -1)\n",
    "masked_attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35712d1",
   "metadata": {},
   "source": [
    "### **MASKED ATTENTION OUTPUT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd110586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.2000],\n",
       "        [0.9004, 0.3495],\n",
       "        [0.5744, 0.5782]], dtype=torch.float64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_attention_output = torch.matmul(masked_attention_weights, v)\n",
    "masked_attention_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d75bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
